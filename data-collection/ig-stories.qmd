---
format: 
  html: default
title: "Instagram Stories"
date: 2023-11-13
author:
  - name: Michael Achmann-Denkler
    id: ma
    orcid: 0000-0002-4754-7842
    email: michael.achmann@informatik.uni-regensburg.de
license: CC BY
notebook-view:
  - notebook: ../notebooks/firebase-interface-notebook.ipynb
    title: "Firebase Interface Notebook"
    url: https://github.com/michaelachmann/social-media-lab/blob/main/notebooks/2023_11_07_Firebase_Interface.ipynb
---
Instagram stories are a special format with ephemeral character. They expire after 24 hours, thus we need to collect them just in time, retrospective data collection is not possible with this format. There are two feasable approaches: Instaloader and Zeeschuimer-F. Additionally, there are commercial tools like [4k Stogram](https://www.4kdownload.com/de/products/stogram-2) available. 

![A screenshot of stories by @tagesschau opened in the firefox browser](/images/stories-screenshot.png)

Overall, the ephemeral chracter of stories requires us to continually monitor and collect data from our profiles of interest. Thus, in order to make sure that we capture **every** story item, I recommend to collect stories twice daily, approximately 12 hours appart. This approach leaves room for inaccurate timing of the data collection, as the time frames overlap. We may collect the material manually or computationally. The manual approach in combination with Zeeschuimer-F is the most acceptable approach as we do not infringe the TOS. For this approach we would install the plugin and visit all stories in our browser twice per day. With Instaloader, on the other hand, we would just start the command and wait for the software to collect all data. Ideally, we would use e.g. [Cron](https://de.wikipedia.org/wiki/Cron) to automate the process. 

## Instaloader
Instaloader for stories works very similar to [collecting Posts](ig-posts.qmd#instaloader). First of all, the package needs to be installed:
```python
!pip -q install instaloader
```

In contrast to the previous tutorial, I recommend to use the command line interface of Instaloader for collection stories. Open a terminal and run the following command: 

```bash
instaloader --login your.profile.name --dirname-pattern ig_stories/{profile} :stories --no-compress-json
```
This command creates a subfolder in `ig_stories` for each user that your profile is following. It downloads the metadata, images and videos for each story. The metadata is contained in a `JSON` file. By default the file is xz compressed, using the `--no-compress-json` switch suppresses the compression. The `JSON` files can then be read into a pandas DataFram using python. 

The process may be automated, e.g. using this `bash` script in combination with `cron`:

```bash
#!/bin/bash

# Generate a random number of seconds between 0 and 3600 (1 hours)
sleep_duration=$(( RANDOM % 3600 ))

# Print the sleep duration
echo "Sleeping for $sleep_duration seconds..."

# Sleep for the random duration
sleep $sleep_duration

# Run Instaloader command to download the latest Instagram stories
instaloader --login your.profile.name --dirname-pattern ~/ig_stories/{profile} :stories  --no-compress-json

# Add more script to check for success and send alerts in case of error
```

Start cron by entering `crontab -e` on your terminal and add a line pointing to the `bash` script, e.g.:

```bash
* 8,20 * * * /path/to/your/script.sh >/dev/null 2>&1
```


<div class="pros-cons-container">

<div class="pros">
### Pros:
<ul class="pro-con-list pro">
<li>Very easy to automate</li>
<li>Collects all data: metadata, images, videos</li>
</ul>
</div>

<div class="cons">
### Cons:
<ul class="pro-con-list con">
<li>Possibly against the TOS</li>
<li>Rate Limits</li>
<li>Blocked Accounts (*very* quickly)</li>
</ul>
</div>

</div>


## Zeeschuimer-F
![](/images/zeeschuimer-f.png)

This approach uses the [Zeeschuimer Firefox Plugin](https://github.com/digitalmethodsinitiative/zeeschuimer) as basis. I modified the original plugin and created Zeeschuimer-F, capable of collecting Instagram stories and connecting to [Zeeschuimer-Firebase-Backend](https://github.com/michaelachmann/zeeschuimer-firebase-backend) for real-time data collection. [Zeeschuimer-F is available on GitHub](https://github.com/michaelachmann/zeeschuimer-firebase-backend), download the latest version using [Firefox](https://www.mozilla.org/de/firefox/new/) and install the plugin. I provide a backend instance for our seminar, take a look at the `README.md` on GitHub for instructions to install your own instance on firebase. **The credentials for our seminar will be provided via GRIPS**. We will follow these steps to download stories using Zeeschuimer-F:

1. Download and install the plugin
2. Create a project on the backend (via Notebook)
3. Configure the plugin
4. Periodically view stories to collect them using Firefox
5. Download the results (via Notebook)

### Plugin Installation
Download the latest release `.xpi` file for the extension form [GitHub](https://github.com/michaelachmann/zeeschuimer-firebase-backend) using Firefox. Next, click on the downloaded file in firefox, confirm the installation of the extension.

![Screenshot of Firefox with open extensions menu](/images/plugins.png)

 Check the right hand menu to confirm the installation of the extension. We will come back to the browser in a moment.

---

### The Firebase Interface Notebook

{{< embed ../notebooks/firebase-interface-notebook.ipynb echo=true >}}


<div class="pros-cons-container">

<div class="pros">
### Pros:
<ul class="pro-con-list pro">
<li>We do not infringe the TOS</li>
<li>Collects all data: metadata, images, videos</li>
<li>The firebase backend handles alert emails</li>
</ul>
</div>

<div class="cons">
### Cons:
<ul class="pro-con-list con">
<li>Current solution relies on the firebase backend</li>
<li>We need to manually browse the stories twice a day (*can* be automated using [Selenium](https://www.selenium.dev/))</li>
<li>Data is collected on firebase storage, we need to export to use it</li>
</ul>
</div>

</div>


## Conclusion

This page provided an overview of two approaches for collecting ephemeral Instagram stories. We collect the stories in real time as they expire after 24 hours. The first approach, [instaloader](#instaloader), does -- in theory -- a great job. As with the posts, however, Instagram accounts using Instaloader get banned really fast. The second approach is less invasive, we capture the data sent to the browser while browsing stories on Instagram and send the metadata to our firebase project. Once a new story is added to the database, the backend starts downloading videos and images for any given story. I have provided a notebook to create projects, a manual to configure the plugin, and some more code to export the captured stories using a Jupyter notebook.


