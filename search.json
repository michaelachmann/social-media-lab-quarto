[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "notebooks/2023_12_01_GPT_Text_Exploration.html",
    "href": "notebooks/2023_12_01_GPT_Text_Exploration.html",
    "title": "Data Import",
    "section": "",
    "text": "Using GPT for Information Extraction\nThe focus of this chapter lies in demonstrating how GPT can be employed in a loop to analyze text documents. This methodology aligns with the principles of topic modeling but extends further by leveraging the advanced capabilities of the language model. Our approach involves the iterative processing of text, where GPT aids in identifying, categorizing, and interpreting the underlying themes and sentiments expressed in social media texts.\nThe GPT application presents a significant difference compared to traditional topic modeling. While topic modeling often aims to automatically uncover hidden thematic structures within a text corpus, our approach with GPT is based on a different assumption: We presuppose that there is already a specific theme or a particular question in mind according to which we want to organize and analyze the documents. This approach allows us to navigate through the vast amounts of text in social media in a targeted and efficient manner, identifying specific insights and patterns that are directly related to our predefined areas of interest.\nThe following workflow outlines how we could use this information extraction process to create a topic list. Using the list we can classify each document.\n\n\n\nAn example for a GPT based “Topic Modeling” approach. I have used this approach in a current research project, the process is not perfect yet.\n\n\n\n!pip install -q openai backoff gpt-cost-estimator\n\n\n\nSetup for the OpenAI API\nWe’re using the new Colab Feature to store keys safely within the Colab Environment. Click on the key on the left to add your API key and enable it for this notebook. Enter the name fpr your API-Key in the api_key_name variable below.\n\nimport openai\nfrom openai import OpenAI\nfrom google.colab import userdata\nimport backoff\nfrom gpt_cost_estimator import CostEstimator\n\napi_key_name = \"openai-lehrstuhl-api\"\napi_key = userdata.get(api_key_name)\n\n\n# Initialize OpenAI using the key\nclient = OpenAI(\n    api_key=api_key\n)\n\n\n\n@CostEstimator()\ndef query_openai(model, temperature, messages, mock=True, completion_tokens=10):\n    return client.chat.completions.create(\n                      model=model,\n                      temperature=temperature,\n                      messages=messages,\n                      max_tokens=600)\n\n# We define the run_request method to wrap it with the @backoff decorator\n@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APIError))\ndef run_request(system_prompt, user_prompt, mock):\n  messages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": user_prompt}\n  ]\n\n  return query_openai(\n          model=\"gpt-3.5-turbo-0613\",\n          temperature=0.0,\n          messages=messages,\n          mock=mock\n        )\n\nNext, we create a system prompt describing what we want to extract. For further examples of prompts and advice on prompt engineering see e.g. the prompting guide and further resources linked at the bottom of the page.\nFor the initial example we use social media content shared by politicans and parties. We know, that some of these texts mention policy issues, let’s try to extract these issues across all documents.\nNote: The extracted issues are not going to be consistent, because each document is sent as a singular request to the API, thus the previous issues are not going to be used as context.\nModify the following system prompt to extract other types of information. What else could you extract?\n\nLocations (based on names)\nNames (of persons or places)\nMentions of Companies\n…\n\nDo not forget the Prompt Archive when experimenting. Share your successfull prompt with us!\n\nsystem_prompt = \"\"\"\nYou are a helpful assistant, an expert for German politics.\n**Objective:** Extract policy issues from German language social media texts. Policy issues refer to specific topics or subjects that are the focus of public or governmental debate, analysis, and decision-making. Elections themselves and party slogans or their performance are no policy issues.\n**Instructions:** Return each policy issues referenced in user message as a comma-seperated list. Return 'None' if no policy issues are referenced.\n**Formatting:** Return a comma-seperated list.\n\"\"\"\n\n\n\nRunning the request.\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI! Make sure ‘run_request’ and ‘system_prompt’ are defined before this block by running the two blocks above!\nSet the following variables:\n\nMOCK: Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nRESET_COST: Do you want to reset the cost estimation when running the query?\nCOLUMN: What’s the column name to save the results of the data extraction task to?\nSAMPLE_SIZE: Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\n\n\nfrom tqdm.auto import tqdm\n\nMOCK = True\nRESET_COST = True \nCOLUMN = 'Policy Issues'\nSAMPLE_SIZE = 0 \n\n# Initializing the empty column\nif COLUMN not in new_df.columns:\n  new_df[COLUMN] = None\n\nif RESET_COST:\n  # Reset Estimates\n  CostEstimator.reset()\n  print(\"Reset Cost Estimation\")\n\nfiltered_df = new_df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df['Policy Issues'])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        response = run_request(system_prompt, row['Text'], MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n\n          # Convert the string 'r' to a list if it's not 'None', otherwise keep it as None\n          if r != 'None':\n              r = r.split(', ')\n          else:\n              r = None\n\n          # Update the 'new_df' DataFrame\n          new_df.at[index, 'Policy Issues'] = r\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\n\n\n\n\n\n\n# Save Results\nnew_df.to_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\nNext we create a set of Policy Issues. Sets are similar to lists in that they are used to store multiple items, but each unique item in a set appears only once, regardless of how many times it is added, as sets inherently enforce uniqueness and do not allow duplicates. Unlike lists, sets are unordered, meaning they do not record element position or order of insertion. This property makes sets highly efficient for checking membership and eliminating repeated entries. We create the list policy_issues to generate a word cloud.\n\nunique_policy_issues = set()\npolicy_issues = []\n\nfor issues in new_df['Policy Issues']:\n    if issues is not None:\n        unique_policy_issues.update(issues)\n\n        for issue in issues:\n            policy_issues.append(issue)\n\nprint(unique_policy_issues)\n\n{'faires Verfahren', 'Straßen', 'EU-Kommission', 'Zusammenhalt unserer Gesellschaft', 'migrationswende', 'bayernliebe', 'Thema Migration nicht unkontrolliert weiterlaufen lassen', 'Sprache', 'FREIHEITfürBayern', 'Freistaat Bayern', 'rezession', 'Hilfe', 'Mehrwertsteuer', 'tv', 'Lügen', 'Bayern stark und stabil bleibt', 'Baumfreiflächen', 'BAföG-Höchstsatz', 'Online Antrag', 'Zurückweisungen an Binnengrenzen', 'Autoverbot', 'wohnungskonzerne enteignen', 'Infrastrukturausbau', 'Reformierbarkeit des öffentlich-rechtlichen Rundfunks', 'bayerische Antidiskriminierungsstelle', 'Baden-Württemberg', 'Strompreiszonen', 'Streit und Chaos', 'linke Inhalte', 'Soldatenberuf', 'bezahlbare Energie', 'Verkaufszahlen bei Heizungssystemen', 'Forschung und Entwicklung', 'Ölheizungen', 'Situation an den Aussengrenzen', 'Leitungen', 'Verbotsorgien', 'Kriminalität', 'CDU/CSU', 'Sprachen und Kultur', 'deutsche Universität', 'bezahlbares Bayern für alle', 'Souveränität', 'wiedervereinigung', 'Landwirte', 'Rechtsstaat', 'moderne Lernumgebung', 'Iran', 'Hebammen', 'Tierschutz', 'Baumwipfelpfad', 'politische Einflüsse', 'bayrisches Brauchtum', 'Mitbestimmung', 'Linksextremisten', 'landtagbayern', 'BayernsOpposition', 'ddr', 'ltw', 'Parteidisziplin', 'Planungs- und Genehmigungsprozesse', 'Wirtschaft fördern', 'Energiepreis', 'Personalschlüssel', 'Bestandsgebäude', 'gleichwertige Lebensverhältnisse', 'Energiepreise', 'Sparen', 'bezahlbarer Wohnraum für alle', 'Jugendzentren', 'Wassersparen', 'niedrigere Standards', 'Sorgen und Nöte', 'Migrationswende', 'junge Männer', 'Haus- und Fachärzte', 'Landwirtschaftspolitik', 'unserezukunft', 'Faschist*innen', 'wegenmorgen', 'konservative Werte', 'innenminister', 'Politik', 'Bundeswehr', 'Startchancen für Kinder', 'Kulturlandschaft', 'umsteuern', 'Klimaschutzziele erreichen', 'Führerscheinrichtlinie', 'Kita-Betreuungsplätze', 'politischer Wechsel', 'Kaufnebenkosten', 'Obergrenze für Bargeldzahlungen', 'heimatliebe', 'Zivilist*innen', 'Glaubwürdigkeit', 'Mehrwertsteuer für die Gastronomie', 'unkontrollierte Zuwanderung', 'LOSvonBerlin', 'Anti-Atom-Ideologie', 'Ausbau der Erneuerbaren Energien', 'Mehr Platz für das Rad und die Öffis', 'Biodiversität', 'linke Medien', 'afdwählen', 'Sozialwohnungen', 'bayerischerlandtag', 'Grenzen', 'Migrationskatastrophe', 'rechtsradikale Parteien', 'Ego-Show', 'Bildungswende', 'Fach- und Ergänzungskräfte', 'Terroristen der Hamas', 'anpackenstattankleben', 'Nachtfahrverbot', 'unsereverantwortung', 'illegale Einwanderung', 'Hotel', 'erfolg', 'Deutschlandticket', 'Unterschleißheim', 'Wirtschafts- und Standortpolitik', 'Startchancen-Programm', 'Personal- und Sachmittel', 'Landtag Bayern', 'Grenzschutz', 'Dampfheizkraftwerk', 'Geflüchtete', 'Bayernpartei', 'Exportwirtschaft', 'Rechte der Bürger', 'Zivilgesellschaft', 'Ernsthaftigkeit', 'BürgerlicheMitte', 'pseudowissenschaftliche Gender-Ideologie', 'sichere Herkunftsstaaten', 'haustürwahlkampf', 'Bayern lebt es sich einfach besser', 'Wahlklatsche', 'Mittelstand', 'Diesel', 'Förderkürzungen', 'Deutschlandpakt', 'Stigmatisierung', 'Befreiung land- und forstwirtschaftlicher Fahrzeuge von der KfZ-Steuer', 'Mobilitätsmix', 'Innere & transnationale Sicherheit', 'LOSvonRom', 'Hetze', '8Oktober', 'MINT-Fächer', 'Stillstand', 'Beteiligung', 'Bevormundung aus Berlin', 'Finanzierungen', 'Technologieoffenheit bewahren', 'illegale Migration', 'islamistischer Terror', 'Auto-Verbot', 'oberfranken', 'Ampel-Regierung', 'GesunderMenschenverstand', 'Perspektiven', 'Arztsitze', 'Terrorangriffe der Hamas auf Israel', 'SPD', 'Bau einer weiteren Betonpiste', 'Bezirksvorsitzender für Unterfranken', 'sommertour', 'Sach- statt Geldleistungen', 'deutschegeschichte', 'ehrenamt', 'Sprachfeststellungstests', 'Klarheit bei Heizungsgesetz', 'opposition', 'bayerischen Steuerzahler entlasten', 'Kinderbetreuung', 'stationäre Versorgung', 'Überforderung', 'LTWBayern', 'Selbstbestimmungsgesetz', 'Interessen', 'landespolitische Fragen', 'Ausländer', 'Unternehmenssteuern', 'CO2-Maut für LKW', 'Öffentlich-rechtlicher Rundfunk', 'Bezirkstage', 'missionunion', 'Abgabe', 'Weltoffenheit', 'Waldbauern', 'Elster Zertifikat', 'Hohenwart', 'Meinungen aus', 'Terrororganisation', 'Aufbaugeneration', 'rechtskonform', 'Meisterausbildung', 'digitale Strategie', 'wichtige Themen', 'energiewende', 'Briefwahl', 'Umweltschutz', 'christlich', 'Kaputt gesparte Kommunen', 'Lebensmittel- und Energiepreise', 'kommende Wahlen', 'Chancengerechtigkeit', 'Entlastung', 'Geldleistungen', 'Bezahlbare Wohnungen und faire Mieten für 7 Mio. Mieter', 'Unterstützung', 'Wirtschaftswachstum', 'Heizungsverbote', 'Haushaltspolitik', 'jüdischer Staat', 'Wasserstoff-Region', 'Flurneuordnung', 'eigene Zukunft', 'Fachkräfte', 'Kontrolle', 'Biomassedeckel', 'Verkehr', 'Mehrwertsteuer auf Grundnahrungsmittel', 'Zuwanderung', 'Zahnsanierungen', 'soziale Leistungen', 'Entwicklungshilfe', 'Benachteiligungen des ländlichen Raums', 'Digitale Bildung', 'Chancenbereitung', 'Abschiebung', 'Einfluss der ideologisierten und politisierten „Klimaforschung“', 'LosvonBerlin', 'Tanz', 'Unterstützung für Familien', 'Weltsicht', 'Kahlschlag in der Krankenhauslandschaft', 'Heizgesetz', 'Klimasparbuch', 'Zahnarzt', 'grundsatzprogramm', 'Städten', 'Steuergeschenke für Konzerne', 'Gesundheitspolitik', 'steuerliche Entlastungen', 'Anpacken', 'Wiedereinzug in den Bayerischen Landtag', 'Teamgeist', 'Numerus Clausus', 'Inklusion', 'Verteidigungspolitik', 'Heimatliebe', 'ausrüsten', 'Ehrenamtlicher Einsatz', 'gefährdungslage', 'Gender', 'Beschränkungen der Bargeldnutzung', 'Stabilität', 'München', 'Dr. Markus Büchler', 'bevormundung', 'selbstbestimmtes Europa', 'Asylbewerberleistungsgesetz', 'wirtschaftspolitik', 'Waldstilllegungen', 'beschränkt gültiger Führerschein ab 60', 'Bayerns Wälder', 'Gräuel', 'Abschieben', 'islamistischer Terror der Hamas', 'Arbeit', 'MWST in der Gastronomie', 'bezahlbar', '8. Oktober', 'Katastrophenschutz', 'Nahverkehrsangebote', 'Mitmach-Aktionen', 'zivilgesellschaftliche Kräfte', 'Fernsehbosse', 'Brenner-Nordzulauf', 'Einigkeit', 'Gewalt', 'Parteiarbeit', 'Abtreibungen', 'Tanken', 'Privateigentumsschutz', 'politische und gesellschaftliche (Fehl-)Entwicklungen', 'Expertenkommission', 'Bayern selbst entscheiden können', 'Ideen', 'aktueller Rechtsruck', 'Asyl-Lobbyisten', 'Biotechnologie', 'starke Stimme', 'Klimaschutz', 'Kontoverbindung', 'bezahlbares Wohnen', 'bürgerliche Koalition', 'Klimawandel', 'Migranten', 'ungewollt schwangere Frauen', 'NGO', 'zeitgemäße Führung', 'gewöhnlicher Aufenthalt', 'Tourismus', 'Bürger', 'Interessen Italiens', 'Terror', 'Mietpreissteigerungen', 'Impfzwang', 'Batteriespeicher', 'Kahlschlag', 'Lärm', 'frühzeitiges Erlernen der deutschen Sprache', 'Bayern liebt', 'internationale Gemeinschaft', 'Maximilianeum', 'EUCH bewegen', 'Ausbildungsreform für die Kinderpflege', 'innovative Bauverfahren', 'Ehrenamt', 'Bildungsoffensive für Deutschland', 'antisemitische Sachverhalte', 'wirtschaft', 'Zusammenarbeit mit dem Regime', 'Pharmazie', 'mittelfranken', 'Abschiebungen', 'Ampel-Chaos', 'gesellschaftliche Unterstützung', 'Frieden in Europa', 'Übernahme nach dem Studium', 'Stimmung gegenüber Geflüchteten', 'Miete', 'Natur erhalten', 'Familien mit Kindern', 'BayernZuerst', 'Bezahlbare Wohnungen und faire Mieten', 'Mitarbeitenden', 'digitale Beantragung', 'Opfer rechter Gewalt', 'Wasserversorgung', 'Pflegegeld', 'Wohnungsoffensive', 'FürDieZukunft', 'Gesetz', 'praktische Übungsstunde', 'Verkehrsträger', 'Ideologiefreiheit an den Hochschulen', 'Jugendparlament', 'neonazistische Gruppen', 'Hessenweiterführen', 'Fahrverbote', 'Sachleistungen', 'Rechtsrutsch', 'Schutz vor Gefahren', 'Landwirtinnen', 'CO2-Bepreisung', 'Modlareuth', 'Bayernwahl', 'Weniger Bürokratie und eine digitale Verwaltung', 'Petition', 'Herausforderungen unserer Zeit', 'deutsche Richterbund', 'ltwby23', 'Klimafreundliches Heizen', 'Kunst', 'zweite Legislatur', 'Gesundheitswesen', 'H2-Heizung', 'Künstliche Intelligenz', 'Universität', 'Migrationsabkommen', 'E-Fuels', 'Politiker', 'bayerische Städtebauförderung', 'Rassismus', 'wählherzstatthetze', 'Länderfinanzausgleich reformieren', 'Medizin', 'Krimbrücke', 'landtagswahl', 'Wasserstoff massiv ausbauen', 'Führerschein für schwere PKWs', 'demokratische Werte', 'politisch Verfolgte', 'Verantwortung', 'Grenzpolizei', 'Leistung', 'Gute Pflege', 'recht', 'Leistungen', 'grüne Klimakonto', 'Ärmsten der Bevölkerung', 'gute Schulen', 'Geflüchtetenpolitik', 'Soldatischer Dienst', 'Stolz', 'Elterngeld', 'regionale Spezialitäten', 'soziale Sicherheit', 'klare Positionen', 'LKW', 'eigenständiges Fahren ab 16 Jahren', 'Bayerns Opposition', 'Klimakollaps', 'Tempolimit', 'einheit', 'CO2-Bilanz', 'heimat', 'friedliches Europa', 'EU-Außengrenzen', 'Grünen', 'Glasindustrie', 'ErbschaftsteuerAbschaffen', 'pro-palästinensische Terrororganisationen', 'Finanzierung', 'Umwelt', 'Schutz von Jüdinnen und Juden', 'Krankenhausreform', 'EU-Eliten', 'Windkraftausbau', 'DIELINKE', 'Bildungs- und Betreuungseinrichtungen', 'Einheimische Bevölkerung', 'steigende Mieten', 'Kostenlosen und ticketfreien ÖPNV', 'kleidung', 'Wochenmarkt', 'Verantwortungsvolle Regierung', 'unabhängige Justiz', 'Solarenergie-Anlage für Balkon oder Dach', 'Pflege', 'Hürden', 'Mehrwertsteuer auf Speisen in der Gastronomie', 'kathaunterwegs', 'Motor für Deutschland und Europa', 'Integration', 'Lehrstühle', 'Wiedervereinigung', 'Männern und Kindern in Israel', 'Asylrecht aushöhlen', 'Bildungsangebote von Verbänden', 'kostenloser Nahverkehr', 'Hürden für den Führerscheinerwerb', 'individuelle Mobilität', 'Halbzeitbilanz der Ampel', 'Gewerbe', 'Planungshoheit der Länder', 'Riedenburg', 'Gebäudeenergiegesetz', 'ökonomie', 'Diskriminierung bei Nichtverwendung der „Gendersprache“', 'Aiwanger', 'Sonderaufnahmeprogramme', 'Landtagswahlen', 'Taurusmarschflugkörper', 'Partei der Mitte', 'frühkindliche Bildung', 'Geiseln', 'Mobilität für alle', 'Vergesellschaftung großer profitorientierter Wohnungskonzerne', 'Apotheke', 'politische Bildung', 'Landräte', 'Wirtschaftlichkeit', 'Absenkung der Mehrwertsteuer', 'Ökomodellregionen', 'Leichenmisshandlung', 'Rückführungsabkommen', 'Unsicherheiten für Studierende', 'Sympathiekundgebungen für den Terror in Israel', 'bayerischerrundfunk', 'Corona-Bußgelder', 'Parteien', 'Dorferneuerung', 'Kernfusion', 'Werte', 'Krankenhausversorgung auf dem Land', 'Sauerlach', 'Bürgerinteresse', 'Bayern wird Wasserstoffland Nummer 1', 'Krankenhäuser', 'mauerfall', 'Genehmigungsprozesse', 'Schwarz-Grün', 'Atomkraftwerken', 'Hofsterben', 'Ausländer-Gewalt', 'Versorgung', 'Drittstaatsangehörige', 'Festung Europa', 'Unterfranken', 'Heimat', 'natürlicher Rohstoff Holz', 'Lösungen', 'Abgabelast pro gefahrenen km', 'gegen grüne Ideologie', 'Gegenpositionen zum herrschenden Zeitgeist', 'Hilfe und Arbeitsmigration', 'Sitzen bleiben', 'Familienbetriebe stärken', 'Landtagskandidat*innen', 'fossile Energieträger', 'europäische Regelung', 'CSU-Versprechen im Wahlkampf', 'palästinensische Terroristen', 'Grüne', 'Klimakonto', 'Menschenrechtsverletzungen', 'Verkehrsbelastung', 'autoritäre Gesundheitspolitik', 'Israel', 'wirtschaftliche Entwicklung des Freistaates', 'staatliche Verwaltung', 'tradition', 'gestiegene Kosten für Heizung', 'Zukunftsvertrag zur Landwirtschaft in Bayern', 'Kürzungshammer', 'Soziale Politik', 'grüne', 'Maghreb-Staaten', 'Förderrunde', 'gesellschaftliches Wohlergehen', 'Bewusstsein', 'Gewinnung von Arbeits- und Fachkräften', 'Bandenkriminalität', 'Stellenabbau', 'Fördergelder', 'Pflegeversorgung in der Heimat sicherstellen', 'Richtungsentscheidung', 'bezahlbare Wohnungen', 'Gelder für Freiwilligendienste', 'bayerische Volkspartei', 'Geburtsstationen', 'landtag', 'Bayerntour', 'konsequente Rückführung krimineller Straftäter', 'Gesundheitsversorgung', 'Bus und Bahn', 'Schweden', 'Regeln', 'kostenlose Kitas', 'Wahl am 8.10.', 'bayerische Grenzpolizei', 'Populistische Politik', 'Klimakleber', 'Leichenschändigung', 'vereint', 'EU-Sanktionen', 'Innere Sicherheit', 'konservative Opposition', 'Breitbandversorgung', 'Lebensqualität', 'Ausbildungskosten', 'bezahlbarkeit', 'Vertrauen in demokratische Institutionen', 'Minderheit im eigenen Land', 'Wasserstoffdrehkreuz', 'CO2-Preis', 'Erdgasheizungen', 'Erbschaftsteuer', 'Abkommen', 'landtagswahlen', 'Mobilfunk', 'Fakten', 'Lebensverhältnisse', 'Bayernliebe', 'DRG-Fallpauschal-Finanzierung abschaffen', 'Parteivorsitzende', 'Demokrat*innen', 'Demonstranten', 'Investition in Ausstattung der Schulen', 'EU stoppen', 'russischer Angriffskrieg gegen die Ukraine', 'politische Gefangene', 'FREIHEITfürBAYERN', 'Wirtschaftspolitik', 'Forschung an KI', 'gebührenfreie Kitas', 'Gesundheit', 'Familienpolitik', 'Ideologie', 'Handeln', 'Jugend', 'Rechtsstaatlichkeit', 'Startchancen', 'sinkender Strompreis', 'kostenfreie Bildung', 'Forschung', 'Gefahrenstellen', 'Schule und Berufsleben', 'Kommunen', 'Haft', 'Schlaganfall-Versorgung', 'straffällig', 'Heizungsgesetz', 'Grenze', 'ltwby', 'Selbstbestimmung', 'Geld', 'tagderdeutscheneinheit', 'ländliche Räume', 'Respekt', 'Bürgerenergie-Genossenschaften', 'Antisemitismus', 'EU-Asylkompromiss', 'Automobilindustrie', 'Markus Söder und die CSU', 'Immobilienhaie', 'Kandidierenden', 'Sanierungsbedarf', 'Kurs', 'Vernichtung', 'Wissenschaft', 'Kitaplätze', 'Wirtschafts- und Sozialpolitik', 'Rente', 'EWERG eG', 'Grüne raus aus der Regierung', 'Strompreise von Umlagen und Steuern', 'Arbeitsvertrag', 'Politik für die eigenen Leute', 'PolitikFürUnsereZukunft', 'Beseitigung von Weltraumschrott', 'Rundfunkrat', 'künftige Generationen', 'GEAS', 'Bezahlung in der Pflege', 'Spaltung', 'Verbeamtung', 'international', 'nürnberg', 'Strompreise', 'faire Bezahlung von Pflegekräften', 'rechte Politik', 'Wirtschaftszweig', 'Kandidatinnen und Kandidaten', 'Satellitendaten', 'Verkehrsentlastung', 'Nationaler Sicherheitsrat', 'begleitetes Fahren', 'starkes und bezahlbares Bayern', 'Migrationspolitik', 'NGOs', 'Umwidmung von Parkplätzen', 'heimische obst- und nahrungsmittel', 'Seenotrettung', 'Betonfundamente', 'CSU', 'Technologie-Offenheit', 'Datenschutz', 'öffentlich-rechtlichen Medien', 'Erhalt der heimischen Lebensmittelproduktion', 'politikmitverstand', 'Landwirtschaft', 'Nationale Raumfahrtstrategie', 'Hightech', 'Arbeitslosenquote', 'Artenvielfalt', 'Kassenleistungen', 'Wirtschaft', 'Wohlstand', 'PIN', 'Zukunftskurs', 'einheitliche Regelungen', 'EU', 'Wohnung', 'staatliche Betriebskostenförderung', 'neoliberale Wirtschafts- und Finanzpolitik', 'antisemitische Einstellungen', 'Lebensmittel', 'Dorfentwicklung', 'Wasserstoff', 'CO2-Bindung', 'Biomasse', 'handlungsfähiger Staat', 'Vergütung', 'starke Bildungspolitik', 'Judenhass', 'Privatsphäre', 'Wasserstoff-Tankstelle', 'Schienen', 'sauberes und bezahlbares Zuhause', 'Geschichte', 'bayerisches Familiengeld', 'Betriebskostenförderung', 'gemeinnützige Arbeit', 'LTWBy', 'Lärmschutz', 'Förderung von Ideen zur Verbesserung von Unterricht und Schule', 'Elektrolyseur', 'Kostenlose Kitas', 'versorgungsrelevant', 'WHO', 'HolDirDeineZukunftZurück', 'Rundfunkbeitrag', 'Photovoltaik', 'Gemeinschaftsschule', 'Mieten', 'Bau- und Wohnwirtschaft', 'Energie', 'Abgase', 'Wissenschaftsfreiheit', 'Terror der Hamas', 'BAföG Reform', 'Gedichte', 'Machen statt Niedermachen', 'Hüterin der Bürgerrechte', 'Chancen', 'Tariftreue-Paket', 'flächendeckende Notfallversorgung', 'Umweltfreundliche Mobilitätsformen stärken', 'Kliniken', 'Bildungssystem', 'Feindbilder', 'Landes-Antidiskriminierungsgesetz', 'Radio', 'Abrechnung der Arztkosten', 'Anmaßungen des EuGH', 'Eigentum', 'Eltern- und Schüler*innenvertretungen', 'Windkraft', 'Senioren', 'Ungleichheit', 'Liberalismus in Europa', 'Ausbau des mobilen Internets', 'Lauterbach', 'Abwehr dieses Terrorangriffs', 'Politik für Leistung und Eigentum', 'teambayern', 'Verbindungsachsen', 'exzellente Ausbildung', 'Demokratie-Dialog', 'Wasserstoffnetz', 'krise', 'Wohnraum', 'politik', 'Energieversorgung', 'Eigentum in Familienbesitz schützen', 'FreistaatBayern', 'praktische Berufe', 'Werkswohnungen', 'Europawahl 2024', 'Quiz-Spiel', 'Nancy Faeser', 'GemeinsamStark', 'Haft für Schutzsuchende', 'Ordnung und Sicherheit', 'Lieferung von schweren Waffen', 'Biotech-Standort', 'Grenzschutzoffensive Bayern', 'sittenwidrig', 'Energiewende', 'Abhängigkeit vom Ausland', 'Arbeit im Rentenalter', 'Engagement für Demokratie', 'queere Menschen', 'Holzwachstum', 'Durchforstungsholz', 'Ingolstadt', 'Pflegekrise', 'Grundnahrungsmittel', 'Versorgungssicherheit', 'attraktive Bedingungen für deutsche Weltraumunternehmen', 'Bildungspolitik', 'Effizienz', 'Straßengroßprojekt', 'Demoskopen', 'Mutter', 'LTW', 'linke', 'Pflegegesellschaft', 'Rechtsterrorismus', 'Hass und Hetze', 'Kartellamt', 'Zwang', 'Rundfunkgebühren abschaffen', 'Arbeitsmarktpolitik', 'Merz', 'Patient', 'Partei', 'Krisen', 'GRÜN', 'heimatmitherz', 'Frieden', 'bürokratischer Mehraufwand', 'Netto', 'bezahlbare Lebensmittel', 'Desinformation', 'Schulen', 'bildungsgerechtigkeit', 'Freilassung aller Geiseln', 'Oberbayern', 'MedizinischeVersorgung', 'Energie-Mix', 'Lebenshaltungskosten', 'Postleitzahl', 'Geothermie', 'Bayern', 'Wirtschaftsfreundlichere Rahmenbedingungen', 'starke Wirtschaft und bezahlbare Energie', 'regierung', 'geschichte', 'Wille', 'Europawahlen', 'ltw2023', 'Anstalten', '2023', 'Lieferkettengesetz', 'Verwaltung', 'Bildung und Forschung', 'sexuelle Gewalt', 'HerzStattHetze', 'Manifest für Freiheit in Europa', 'Fremdbestimmung', 'Steuersenkungen', 'Menschen in Israel', 'Schwaben', 'rechte Gewalt', 'Mietpreisbremse', 'würdevoll', 'EnergiewendeMitVerstand', 'Ländlichen Raum stärken', 'CDUParteitag', 'Zukunftsvertrag für die Landwirtschaft', 'DeineStimmeZählt', 'Gegenwehr gegenüber einer übergriffigen EU-Bürokratie', 'Bruder', 'freistaatbayern', 'Bürgergeldreform', 'Familie', 'ständige Hetze von Söder', 'Förderung innovativer Start-ups', 'demokratie', 'Wärmewende', 'rechte Szene', 'gute Pflege', 'Friedensbewegung', 'Windräder', 'Prinzipien', 'Tätern', 'Verbindungen', 'Sturm', 'Tauruslieferung', 'Kernkraft', 'Kleinkrafträder', 'soziale Gerechtigkeit', 'Hass und Antisemitismus', 'Drogenlegalisierung', 'einigkeit', 'klimaschutz', 'radikale Bewegungen in Österreich und Deutschland', 'wiederverwenden', 'Familien', 'Mangel an Kita- und Pflegeplätzen', 'Kraft der Vernunft', 'faire Mieten', 'Land Israel', 'Region', 'Rundfunk', 'Heizungspolitik', 'Migrationskrise', 'DIE LINKE', 'Sozialepolitik', 'Wohnungsbau', 'Flüchtende', 'Bewirtschaftete Wälder', 'gute Löhne', 'Ganztagsplätze', 'sicherer Strom', 'Grenzen kontrollieren', 'Gegenrechts', 'Chatkontrolle', 'Technologieoffenheit', 'Menschen in Armut', 'Weiden', 'Förderung des Ökolandbaus und der Biologischen Vielfalt', 'Europäische Staaten', 'Innenministerin Faeser', 'Zugangscode', 'Strompreis', 'Forschungspolitik', 'Mullah Regime', 'Verteidigung Israels', 'Situation in den Aufnahmekommunen', 'Klimakrise', 'Opfer', 'Ausbildungsstätte', 'Rechtsmittel', 'Streit', 'Bildungsprotest2023', 'heimatbayern', 'katrinebnersteiner', 'Kraft', 'Forschungsbedingungen', 'Verwaltungsrat', 'EU-Gängelung', 'Impuls', 'Produktionsverlagerung', 'Industrie', 'kriminelle Ausländer', 'Staatswald', 'Nazis', 'sachsenanhalt', 'Babys in Bayern', 'Spitzenkandidat', 'Überlänge von 16,50 m auf 17,40 m zulassen', 'Einwanderungs- und Asylpolitik', 'Spritpreisbremse', 'Fördermittelkürzungen', 'gemeinsame Sprache', 'Immatrikulation', 'U18-Wahl', 'mobilität', 'None', 'Kinder- und Jugendplan', 'Krisenverordnung', 'Pflegekonzepte', 'Bürokratieabbau', 'BayernSPD', 'bildung', 'Tradition', 'oberbayern', 'wählen', 'Zugang zur Justiz', 'Wälder', 'Gericht', 'Beste Bildung und weniger Unterrichtsausfall', 'Visionen', 'Terrorism', 'Asylrecht', 'Lernmittelfreiheit', 'Präventionsangebote', 'schlechter ÖPNV', 'Studis', 'humanitäre Verantwortung', 'Ampelpläne', 'Asylpolitik', 'br', 'Mopedführerschein', 'Abschaffung der ungerechten Erbschaftssteuer', 'Demokratieförderung', 'Landärzte', 'traditionelle Studiengänge', 'Enteignung', 'AfD-Wahlergebnisse', 'Holzöfen', 'Nationale Sicherheit', 'bayerische Bezirkstage', 'Bildungswende jetzt', 'Erbschaftssteuer', 'Volksentscheid', 'Landtags- und Bezirkstagswahl', 'Intoleranz', 'Abschaffung des Asylrechts', 'deutschland', 'ErbschaftssteuerAbschaffen', 'Gerechtigkeit', 'Größenwahn', 'Gewalt und Terror in Israel', 'Familienkasse', 'Atomwaffen', 'Wahl', 'GegenRechts', 'Wochen', 'Rücktritt', 'bayerische Staatsangehörigkeit', 'ehemalige SED-Partei', 'Wohnen', 'Mitgliedsstaaten', 'Kultursommer mit Links', 'arbeitsplätze', 'Kernkraftwerke', 'CSU Parteivorstand', 'Terrorismus', 'Anti-Demokrat*innen', 'Sorgen der Bürger ernst nehmen', 'bayerische Interessen im Bund und in Europa', 'die das Klima schützt', 'soziale Politik für Bayern', 'Tarifbindung', 'Bürger*innen-Energiegenossenschaft', 'Abschaffung der CO2-Steuer', 'linksextremistischen Gruppen', 'bayerische Staatlichkeit', 'EEG-Förderung', 'extremisten', 'Leistung und Eigentum', 'Durchhaltevermögen', 'oberpfalz', 'gerechter Freistaat', 'Verbrechen an unschuldigen Frauen', 'Grundsicherung', 'Verlässlichkeit und Kompetenz statt Beliebigkeit und Populismus', 'Los von Berlin', 'ambulante Anlaufstellen', 'AKW-Verteufelung', 'rechnen', 'Herangehensweisen', 'Bezahlbares Wohnen für 7 Mio. Mieter', 'Existenzrecht des jüdischen Staates Israel', 'staatliche Grundfinanzierung von Universitäten und Hochschulen ohne ideologische Vorgaben', 'Stärke', 'Kraftstoff', 'Wasserstoffinfrastruktur', 'vernünftige Mitte', 'Verträge mit Staaten in Nordafrika und Türkei', 'Landtagswahlen in Hessen und Bayern', 'Tempolimit auf Autobahnen', 'pädagogische Qualität von Kitas', 'Gewerkschaften', 'Polizei', 'Russland', 'FlurNatur-Struktur und Landschaftselemente', 'Arbeitsmigration', 'Verbrennungsmotoren', 'Arbeits- und Fachkräfte', 'Bürokratie', 'Kostenlose Kitas für 780 000 Kinder', 'schlechte Bildung', 'Enteignen', 'Steuersätze', 'soziale Probleme', 'Einreisekontrolle an den EU-Außengrenzen', 'israelische Städte und Dörfer', 'FDP', 'Rechtspopulismus', 'Krieg', 'Steuermodelle', 'Schule', 'alleinerziehend', 'buntes Kinderprogramm', 'VPN', 'Anstand', 'Staatsanwaltschaften', 'Arbeitskräftemangel', 'LandtagBayern', 'Verteilungsfragen', 'Souveränitätsverlust', 'Menschenrechte', 'Oberpfalz', 'Einkommensteuer', 'kostenfreie Kitas', 'lebenswertes Bayern', 'Investitionen in die Zukunft', 'sichere Stromversorgung', 'Staatsräson', 'sozialepolitikfürdich', 'Gute Pflege für 2,7 Mio. Senioren', 'Anerkennung', 'Kinder', 'ingolstadt', 'schlanker und effizienter Staat', 'Förderung', 'ausbau', 'Anpacken für Bayern', 'Persönlichkeitsrechte', 'Zuwanderungspolitik', 'Umweltschützer', 'erneuerbare Energien', 'Krankenhaus', 'Deutsche Stromkunden', 'Lehrer', 'Antragsprozess', 'Italianisierung', 'Gegenrassismus', 'inklusives Bildungssystem', 'Stromversorgung', 'Bundesregierung', 'Krankenhaus-Milliarde', 'MitDir', 'heimatschutz', 'Die Konfrontation', 'Toleranz', 'Freibeträge', 'fernsehen', 'freiberufliche Apotheken', 'Leerstandsabgabe', 'Stromleitungen', 'Zahlen', 'FreiheitfürSüdTirol', 'lpt2023', 'Deutschland-Pakt gegen unkontrollierte Zuwanderung', 'Lehrerinnen', 'Mehrsprachigkeit', 'Digitalministerin', 'Vereine und das Ehrenamt stärken', 'anpacken', 'Bevormundung', 'Identität und Nation', 'Kostenlose Bildung', 'Biotopen', 'Sprit sparen', 'Regierungsform', 'Katharina und Ludwig', 'Versorgungsstraßen', 'ÖPNV', 'Blockabfertigungen', 'Lohnersatzleistungen für pflegende Angehörige', 'Ladenschlussgesetz', 'Einbürgerung', 'sozialpolitik', 'Rathausplatz', 'Belebung von Ortszentren und Dorferneuerung', 'Mietendeckel', 'FREIE WÄHLER', 'Privatversicherte', 'Standort', 'Wiedervereinigung Deutschlands', 'Mindestlohn', 'Rückführung von kriminellen Straftätern', 'Insolvenzen', 'Mehr Personal und bessere Zusammenarbeit und Vernetzung', 'Einstellung von Richtern und Staatsanwälten', 'vereinbarkeit', 'Gendern', 'Erhaltung von Dörfern', 'Kinderzukunftsprogramm', 'Pelletheizung', 'Sicherheitsvorkehrungen', 'gute Bildung', 'Gesellschaft', 'landwirtschaft', 'Einzelleistungsvergütung', 'Verdoppelung Kapazität', 'Habeck', 'Naturpark', 'Übergriffigkeiten der EU-Eliten', 'Druck', 'Hausbesitzer', 'Verkehrspolitik', 'Gastronomie', 'starke Wirtschaft', 'Agieren und Finanzierung palästinensischer und propalästinensischer Terrororganisationen', 'kostenlosem ÖPNV für Kinder und Jugendliche', 'Ganzjahrestourismus', 'Schule für alle', 'Erdbeobachtungen', 'Vergesslichkeit', 'Pessimismus', 'Online Ausweis', 'klimaneutraler Wohnraum', 'Kinder und Jugendliche', 'innovativ', 'Ausbau der Windkraft', 'Landespflegegeld', 'besseres Europa', 'Sozialpolitik', 'Asyl', 'ampel', 'individuelle Förderung', 'BP', 'wahlprogramm', 'Menschen mit Behinderung', 'LINKE', 'internationale Wettbewerbsfähigkeit', 'mangelndem Wohnraum', 'Kinder und Jugendliche mit Migrationshintergrund', 'Wasserstoff-Gipfel', 'flächendeckend', 'junge Grüne Abgeordnete', 'Herausforderungen in der Migrationspolitik', 'Zwangsimpfungen', 'Freiheit für Bayern', 'Förderungen für Holz- und Pellets-Heizungen', 'Kindergrundsicherung', 'bayerische Arbeitsplätze', 'Innovation', 'Naturschutz', 'sozialer Aufstieg', 'aktuelle Lage', 'Mittelmeer', 'Gelder', 'innenministerherrmann', 'CO2-Einsparung im deutschen Strommix', 'grüne AKW-Heuchelei', 'Mobilität egal wo du hin willst', 'Italien', 'Deutschland', 'bayern', 'Berliner Senat', 'Gesundheitsreform', 'kostenloses Mittagessen', 'sauberer Strom', 'progressive', 'Mehrwertsteuer in der Gastronomie', 'Steuererhöhung', 'Finanzierung islamistischer Organisationen', 'Staat Israel', 'Begleitetes Fahren ab 15 Jahren', 'Ignoranz', 'Musik', 'kostenfreier Schulweg', 'Windrad', 'Kapazitäten', 'energie', 'konfrontation', 'Stromerzeugung', 'Studieren', 'wissenschaft', 'Menschen vor Ort', 'Haushaltsmittel zur Kofinanzierung der Gemeinschaftsaufgabe Agrarstruktur und Küstenschutz', 'Jugendhaus', 'Streuobstpakt', 'freiheit', 'staatlich subventionierter Industriestrompreis', 'Freie Wähler', 'Medienbildung', 'Antisemitismus-Beauftragter der Bayerischen Staatsregierung', 'Amberg', 'Bevölkerung', 'Rechtsextremismus', 'Trinkwasserschutz', 'dritter Nationalpark', 'Digitalisierung', 'Fachschüler*innen', 'Asylsystem', 'den Grünen und den linkslastigen Medien', 'Vielfalt', 'Humanität', 'Augsburg', 'neue Stromleitungen', 'Jom Kippur', 'Prost', 'stationäre Grenzkontrollen', 'grünklingelt', 'nachhaltigere Raumfahrt', 'Hackschnitzel', 'kostenloser Meister', 'kostenlosen ÖPNV', 'optimistische zukunftsorientierte Politik', 'Sparerpauschbetrag', 'Bargeldnutzung', 'Soziale Gerechtigkeit', 'Märkte', 'bayerisches Förderprogramm', 'Umgang mit Unternehmen', 'höherer Mindestlohn', 'Lebensgrundlagen', 'Handwerk', 'Kooperationsverträge mit der Bundespolizei', 'Flächenverbrauch', 'gleiche Chancen', 'psychische Gesundheit', 'Steuersenkung', 'Ausbildung', 'Grundwasserschutz', 'Institutionen', 'national strukturierteres Abschiebeverfahren', 'angriff', 'Oberfranken', 'Kommunale Krankenhäuser erhalten', 'Anti-Auto-Haltung', 'Rückführung', 'Wohnungsnot', 'finanzielle Förderung von Grundschulen', 'kostenfreie Meisterausbildung', 'Berlin', 'medizinische Versorgung', 'ökologie', 'Modernität', 'Innenentwicklung und die Vermeidung von Flächenverbrauch', 'brauchtum', 'Propagandafernsehen', 'Zeltlager', 'jungeunion', 'Mobilitätswende', 'Nutzung', 'Sozialdemokratie', 'Bayerischer Landtag', 'Genehmigungen', 'Soziale Politik Für Dich', 'Fachkräftemangel', 'Drogenkonsumräume', 'dezentrale Bevorratung in Bayern und Deutschland', 'unterfranken', 'Geburtshilfe', 'Azubis', 'Fallpauschalensystem', 'gute Pflege für 2,7 Mio. Senioren', 'Kitas', 'Druck auf die Ampel', 'rechtsrutschstoppen', 'Abdeckungs-Offensive', 'Kommerzialisierung', 'Solaranlage', 'rechte Ausschreitungen', 'bezahlbares Bayern', 'Landschaftswasserhaushalt', 'Bildungsorganisationen', 'echte Beteiligung', 'Mauerfall', 'Kampf gegen Rechts', 'Konkurrenz', 'AnpackenFürBayern', 'moedlareuth', 'klimaschädlicher Flugverkehr', 'Finanzen', 'Wahlalter 16', 'wichtige soziale Themen', 'Tempolimit auf deutschen Autobahnen', 'Umweltzerstörungen', 'Vorhaben', 'fachkräftemangel', 'Stellenwert in der Gesellschaft', 'Weltraummanagement', 'Fichtenbestand', 'Veränderungen', 'Dieselfahrverbot', 'Umwelt- und Naturschutz', 'Energie- und Industriepolitik', 'Technik', 'Ticketfreiheit', 'Unterstützung der Schulen bei der Umsetzung von Programmen', 'Chancengleichheit', 'Erhöhung der LKW Maut', 'Europawahlprogramm', 'Schutz der Zivilbevölkerung', 'Schleuserkriminalität', 'selbstverwaltete Justiz', 'EU-Gerichtshof', 'Verbotspolitik', 'LTWby23', 'Antragsberechtigung', 'generationengerechte Politik', 'demokratieverteidigen', 'Todesstrafe', 'Jährlichen Stellenaufbau bis 2029 verlängern', 'Holzheizung', 'klarer Kurs', 'Exekutive', 'Asyl-Migration', 'Schutzgrund', 'Recht', 'Nationalismus', 'Wende in der Migrationspolitik', 'Stromnetzausbau', 'Brauchtum', 'lesen', 'Unterdrückung im Iran', 'Waldschädlinge', 'Technologie', 'Ferienangebote', 'Landes- und Bündnisverteidigung', 'AUSSENGRENZEN', 'Entführungen', 'Tag der Deutschen Einheit', 'Markus Söder', 'herrmann', 'Benzin', 'Bayern-Energie', 'Klimaneutralität', 'Politsystem', 'Autonomie für Süd-Tirol', 'Erzeugerpreise', 'deutsche Staatsbürgerschaft', 'Heizen', 'inneresicherheit', 'Brandmauern', 'Bürgergeld', 'bezahlbare Mieten', 'Arbeitnehmerrechte', 'Bürgerinnen und Bürger', 'CO2', 'Grünen Partei', 'Kinderhaus', 'völkerrechtswidriger Angriff', 'Student', 'Zinsen', 'bezahlbarer Wohnraum', 'Wohnungsmangel', 'Safe Abortion Day', 'Einkommen', 'Diskutieren wir', 'Europäische Kommission', 'freistaat', 'Frieden und Freiheit', 'Kulturkampf', 'Spoken words', 'Produktion ins Ausland', 'Mödlareuth', 'Einheit', 'tvtipp', 'ländlicher Raum', 'angehobene Altersgrenzen', 'Schulsozialarbeit', 'Schutz', 'allestimmengrün', 'zukunft', 'Migration', 'Grünen wollen das ganze Land bevormunden', 'Grundschule', 'zweitehand', 'Massenmigration', 'Anpacken für unsere Bürger', 'organisiertes', 'Bürgerrechte', 'CO2-neutraler Kraftstoff', 'zielgerichtete Leistungen', 'Ampel', 'Life Science Campus', 'Steuerfreibeträge im Monat pro Arbeitnehmer auf 2000 Euro', 'europäische Zukunft', 'schwaben', 'Rückführungen', 'FSJ-Plätze', 'Wasserkraft', 'Grüne in der Landesregierung', 'Rechtsruck', 'Selbstbewusstsein', 'gemeinsames Lernen', 'Dürre', 'Wohnsitz', 'sicherheit', 'Wirtschaftsstrompreis', 'Heimatbewusstsein', 'Bodentruppen', 'DeutscheGeschichte', 'Bus', 'Verbote', 'Abschaffung Erbschaftssteuer', 'Förderung der ländlichen Entwicklung', 'Krankenhausversorgung', 'Legislative', 'Existenzrecht Israels', 'regensburg', 'durchgrüntes Berlin', 'Finanzierung des ÖPNVs', 'Heimatvertriebene', 'chrupalla', 'LTW23', 'Landschaftspfleger', 'Sommer', 'illegale Einreisen', 'heimische Energiewelt', 'Neonazi-Strukturen', 'Demokratiebildung', 'bundesweite Grenzpolizei', 'Deregulierung', 'Inflation', 'Zukunftsfinanzierungsgesetz', 'Herz statt Hetze', 'Bezahlbare Energie', 'gesellschaftliche Teilhabe', 'volle Unterstützung für die Ukraine', 'bayerische Interessen', 'Elternhaus', 'bessere Taktung', 'Abgaben', 'antisemitische Propaganda', 'ländliche Krankenhäuser', 'Grundversorgung', 'Bayerns erneuerbare Energie', 'Entlastungen', 'Auflösung des öffentlich-rechtlichen Rundfunks', 'grüne Dogmen', 'effektiver Grenzschutz', 'Erdgas', 'Kriminelle Straftaten', 'Rendite', 'Regensburg', 'Diskriminierung', 'AfD-Erfolgswelle', 'Mobilität', 'Erneuerbare', 'Windenergie', 'Kernwegenetzbau', 'Energieversorgung in Bayern', 'Vitalität', 'staatliche Wohnheime', 'Kinder und Jugendliche in den Fokus', 'Engagement für die Heimat', 'Löhne', 'Hochschule', 'Revolutionsgarden', 'Weltfriedenstag', 'Covid-Maßnahmen', 'Bildung für Bayern', 'Barrierefreiheit', 'Zwangsgebühren', 'bezahlbare und saubere Energie', 'Baupolitik', 'Wahnsinn des Nationalsozialismus', 'Genuss', 'einseitigen Wärmepumpen-Träume der Ampel', 'Selbstregierung', 'kostenlose Meisterausbildung', 'Hisbollah', 'Menschen mit Fluchtgeschichte', 'Zukunftsvertrag zwischen der Staatsregierung und dem Bayerischen Bauernverband', 'Mittelstand schützen', 'Kernfusions-Kraftwerk', 'Erhalt aller Schulstandorte', 'Landtagswahl', 'legale Zuwanderung', 'Gerichte', 'Länderfinanzausgleich', 'rechts', 'Mut', 'LTWby2023', 'bücher', 'Remigration', 'Bayerische Grenzpolizei', 'Freiheit', 'hohe Energiepreise', 'Klimakatastrophe', 'Existenz- und Altersabsicherung', 'Vernunft statt Ideologie', 'Zusammenleben', 'Asylanträge', 'ortsnahe Versorgung', 'Kontinuität', 'Zahlungen an Palästinenser', 'kostendeckende Schulstarthilfe', 'Aufnahmestopp für junge Männer', 'Inntal', 'Mieterschutz', 'Normalverdiener', 'KEINE dritte Startbahn am Flughafen München', 'gendern', 'bayernsOpposition', 'Ärztemangel', 'Zeitenwende', 'Haltung', 'LTW2023', 'Holzheizungen', 'Hilfe für Betroffene von Terrorismus', 'Sicherheit und Ordnung', 'Übergriffe des italienischen Staates', 'Online-Petition', 'Wirtschaftsminister', 'Theoriestunden', 'Schwangerschaftsabbrüche', 'Erneuerbare Energien', 'Terrorangriff der Hamas', 'Rechenschaft', 'br24wahl', 'Stärkung von Landschaften', 'Studierende', 'Artenschutz', 'Grundwasser', 'Wasserschutz', 'Auflagen', 'Zusammenhalt', 'Situation der Studierenden in Bayern', 'LudwigUntrwegs', 'Türkei', 'Nürnberg', 'Deutsche Einheit', 'Energiewende vor Ort', 'Hitze', 'Wertschätzung für ältere Menschen', 'Bezahlbare Wohnungen', 'Wahlprogramm', 'Bildung für alle unsere Kinder', 'nachhaltigkeit', 'Vorschriften', 'starke Infrastruktur', 'Organisationsbereiche', 'Gazastreifen', 'Steigerwaldzentrum', 'Außenpolitik', 'saubere Energie', 'Renten', 'Keine Grünen in der Regierung', 'duales Studium als Bildungsweg stärken', 'Löhne in Ostdeutschland', 'augsburg', 'Medikamente', 'anfängliche Fehler', 'Bund ID Konto', 'Unternehmen', 'Sicherheit bei Lebensplanung', 'Schnitzel', 'Mitglieder-Anteile', 'Richter', 'Stallbauvorschriften', 'Bildung unabhängig vom Geldbeutel', 'Bayern bleibt', 'Pflegekräfte', 'remigration', 'Klima', 'deutschlandfest', 'Aufgaben unserer Zeit', 'flächendeckende Gesundheitsversorgung', 'Chaos', 'Abschiebe-Zahlen', 'Ethos', 'Kampagne finanziert sich', 'Schutzversprechen für jüdisches Leben in Bayern', 'Energie und Treibstoffe', 'Steuerliche Förderungen', 'Bauern', 'Lehrstühle für „Genderforschung“', 'zukunftsfähiges Bildungssystem', 'Wasserstoff-Land Nummer 1 werden', 'Multimillllionäre', 'sozialpolitische Maßnahmen', 'Wärmepumpe', 'brzahlbares Wohnen', 'Niederbayern', 'Wohnen als Grundrecht', 'Bürgermeister', 'Chancengerechtigkeit in Deutschland', 'Schutz des ungeborenen Lebens', 'Ukraine', 'den Automobilstandort Deutschland stärken', 'Reform des Gesundheitswesens', 'Energiegewinnung', 'Landkreis München', 'ärztliche Versorgung', 'Akutsprechstunden', 'Kürzungspolitik', 'Vertrauen', 'Entlastungen für Sparerinnen und Sparer', 'Wohnungs- und Mietmarkt', 'Misstrauen', 'Erbschaftssteuer abschaffen', 'Steuerpolitik', 'Volksbegehren', 'EEG-Umlage', 'Ausbildungs- oder Studienstart', 'Zusatzleistungen', 'Bavarian Fusion Cluster', 'Investorenbetriebene Medizinische Versorgungszentren (MVZ)', 'Spitzenmedizin', 'Wahlkampf', 'Kirchen', 'Energiekosten', 'Hessen', 'Verbrennerverbot', 'Marktwirtschaft', 'Landtags- und Kommunalwahlen', 'Stil', 'Verwaltungsdirektor', 'deutsche Staatsräson', 'Nationalsozialismus', 'Europa', 'Grundlastfähigkeit', 'saubere und bezahlbare Energie', 'Bus und Bahn ins ganze Land bringen', 'Asylbewerber*innen', 'Hilfe und Fürsorge des Staates und der Gesellschaft', 'Hilfe in sozialen Fragen', 'Elektrolyseur-Förderprogramm', 'Familiengeld', 'Opposition', 'niederbayern', 'Sicherheit des Staates Israel', 'Führungspositionen', 'Wohnungsgemeinnützigkeit', 'Medien', 'soziale Herkunft', 'Fernsehen', 'CDU', 'Anpacken statt Ankündigen', 'GEZ abschaffen', 'Arbeitsplätze', 'soziale Politik', 'Wasserentnahme', 'Kinderarmut', 'Filz', 'saisonalität', 'Gesellschaften', 'staatliche Energieunternehmen', 'Heimatenergie', 'Süden', 'kreislauf', 'Energiepolitik', 'Bildung für alle', 'Finanzminister', 'steigende Preise', 'LOSvonBERLIN', 'Wahlerfolge für Boris Rhein und die CDU Hessen', 'mittelschicht', 'Deckelung der Mieten', 'Mitte-rechts', 'volle Unterstützung für Israel', 'Benachteiligung von Menschen mit psychischen Problemen', 'TeamBayern', 'beste Bildung', 'Altparteien', 'nächste Wahlen', 'günstiger ÖPNV', 'CO2-freier Strom', 'Bezirkstag', 'Hamas-Terror', 'Schienenverkehr ausbauen', 'Heimische Produktion von Arzneimittel stärken', 'Anteile', 'Stärkung der Demokratie', 'Ruhegehalt', 'Vergabeverfahren von Medizin-Studienplätzen', 'DeshalbAfD', 'Energiesparen', 'Holznutzung', 'dezentrale Unterbringungen', 'BayerischerLandtag', 'Verhältnis zur Partei', 'Identität', 'Abwärme', 'Wohnraumförderung', 'Grenzschutzbayern', 'Bildung', 'Freie und selbstbestimmte Entscheidung der Patienten', 'junge Generation', 'politiker', 'klimaneutrales Wirtschaften', 'Auto', 'Arbeitszeitflexibilisierung', 'H2-Tankstellen', 'AfD verspricht', 'umsetzen', 'Allgemeinbildung', 'ltwbayern', 'Bezahlbare und saubere Energie', 'Einkommensunterschiede', 'infostand', 'forschung', 'unserlandzuerst', 'Migrationsstopp', 'Freiheit und weniger Kontrollen für bayerische Landwirte', 'Bundestag', 'Sprachkurse', 'Hessenwahl', 'afd', 'gute Ganztagsbetreuung', 'Stromsteuer', 'Hamas', 'primetime', 'Jugendherberge', 'FREIEWÄHLER', 'Veranstaltung', 'wehrhafte Demokratie', 'Ursula von der Leyen', 'Mehr Kontrolle und Steuerung bei der Migration', 'Freistaat', 'Angriffe', 'Mieterinnen und Mieter', 'Abschottungswahnsinn', 'Medizinische Versorgung', 'Solidarität', 'Borkenkäfer', 'Hightech Agenda Bayern', 'Erhöhung der Steuerfreibeträge im Monat pro Arbeitnehmer auf 2000 Euro', 'Kommunen bei der Aufnahme von Geflüchteten unterstützen', 'Gesetzesvolksentscheid', 'Selbstverteidigung', 'Chancenbudget', 'Transportwege', 'familienfreundlicher', 'Wahlniederlage', 'Bayerischer Härtefallfonds', 'münchen', 'Tempo 90 für Fahranfänger', 'Belastungs-Stopp', 'Stromspeicher', 'Seniorinnen und Senioren', 'Artenschwund', 'AfD', 'strukturschwachen Kommunen', 'Vereine', 'Festanstellung', 'Krankenhausinvestitionen', 'Zukunft', 'Gewalttaten', 'Hausbau', 'schlafen', 'Notendruck', 'afdbayern', 'Energieversorgung der Zukunft', 'Kraftstoffpreis', 'Solidarität mit Israel', 'BAföG', 'Strom und Lebensmittel', 'Cannabis-Legalisierung', 'nächste Landtagswahl', 'Häuser', 'Profite mit unserer Miete', 'Frühe Hilfen', 'Regierungsbildung', 'individuelle Mobilität ermöglichen', 'LandtagswahlBayern', 'Bezahlbare und saubere Energie für Bayern', 'leistungsorientierte Bezahlung von Lehrkräften', 'Kinder eine Zukunft', 'Investitionen', 'Durchforstung', 'Binnengrenzen', 'Radwege', 'Vernichtung von Kultur', 'Verkehrssicherheit', 'Unterschriften Sammeln', 'Wärmenetz', 'Steuererleichterung für Agrardiesel', 'grüne Politik', 'Wartezeiten für Therapieplätze', 'Nahversorgung im ländlichen Raum stärken', 'kompetente Politik', 'Urteile', 'Waffenrecht', 'illegale Zuwanderung', 'mangelnde Mobilität', 'online', 'Stärkung von Regionen', 'Spitzenkandidaten', 'hightech', 'Steuern', 'Außenwirtschaft', 'startups', 'Benutzername & Passwort', 'Mobilität junger Menschen', 'illegaleMigration', 'gute gesundheitliche Versorgung', 'Direktkandidatin für den Bayerischen Landtag', 'mörderischer Angriff auf unseren Bundesvorsitzenden', 'Bauvorschriften', 'Grenzkontrollen', 'Alternative zu Deutschland', 'Bescheid', 'Heizungs-Lotsen', 'Massenzuwanderung', 'Asylbewerber', 'steigende Mietpreise', 'Grenzsicherung', 'Rechtsruck in Bayern', 'kostenlose Kitaplätze', 'Claudia Köhler', 'gesellschaftlicher Zusammenhalt', 'Integrationsfähigkeit', 'Militär', 'selbstbestimmt', 'Demokratie', 'juxcsu', 'bayernwahl', 'Staatssekretär für Inneres', 'Süd-Tirol-Autonomie', 'Landtagswahl in Bayern', 'Verweisung nichtdeutscher Staatsbürger', 'Armut', 'Mittelfranken', 'Studium', 'Hightech Agenda', 'Sicherheitsbehörden', 'politikmitherz', 'Windpark', 'Gesundheitsschutz', 'Wiedereinzug', 'Aktivrente', 'geringes Einkommen', 'ausländische Fachkräfte', 'Landtag', 'Terror stoppen', 'gerechte Politik', 'Erosionsschutz', 'Speicher', 'regionale Wertschöpfung', 'Unterbringung', 'marktwirtschaftliches Gewissen', 'Austausch mit den Bürgerinnen und Bürgern', 'wohnen', 'Umbau zu stabileren Wäldern', 'innenministerium', 'Bahn', 'Gesundheitsvorsorge', 'Entwicklung in Deutschland', 'Gemeinschaftsaufgabe „Verbesserung der Agrarstruktur und des Küstenschutzes“', 'Sicherheit', 'duales Studium verbessern', 'Integrationsgrenze', 'Ganztag', 'Süd-Tiroler Freiheit', 'CO2-Steuer abschaffen', 'Steuerverschwendung', 'Teambayern', 'Einwanderung', 'Kostenlose Kitas für 780.000 Kinder', 'interessierte Bürger', 'terroristischer Überfall', 'Klimapolitik', 'israelisches Volk', 'Dreigliedriges Schulsystem'}\n\n\nLet’s quickly generate a wordcloud to check for patterns. See the Simple Corpus Analysis Notebook for more information.\n\n!pip install -q wordcloud\n\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nimport requests\n\n# Retrieve Stopwords from Github\nr = requests.get('https://github.com/stopwords-iso/stopwords-de/raw/master/stopwords-de.json')\nstop_words = r.json()\n\n# Stopwörter in die WordCloud laden\nSTOPWORDS.update(stop_words)\n\ndef generate_wordcloud(text):\n    text = ' '.join(list(text))\n\n    # Generate a word cloud image\n    wordcloud = WordCloud(background_color=\"white\",width=1920, height=1080).generate(text)\n\n    # Dazugehörige Grafik erstellen\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.figtext(0.5, 0.1, \"Policy Issues\", wrap=True, horizontalalignment='center', fontsize=12)\n    plt.show()\n\ngenerate_wordcloud(policy_issues)\n\n\n\n\nNow we’re ready to pass the list to GPT to extract a manageable amount of topics. Note the list might be too long to fit into the GPT context window. In this case we have to split the list into several shorter lists and iterate over them.\nThis time we are not interested in a specific formatting for the response. We want to print the result for human interpretation.\n\nsystem_prompt = \"\"\"\nYou are a helpful assistant, an expert for German politics. Derive 15 topics of policy issues from this list of keywords provided by the user. Concentrate on overarching topics and avoid overlapping topics. Provide a set of 10 keywords per topic.\n\"\"\"\n\n\nkeyword_string = \", \".join(unique_policy_issues)\nresponse = run_request(system_prompt, row['Text'], False)\n\nCost: $0.0010 | Total: $0.3431\n\n\n\nprint(response.choices[0].message.content)\n\n1. Sicherheit\n- Polizei\n- Kriminalität\n- Terrorismus\n- Überwachung\n- Grenzkontrollen\n\n2. Wirtschaftswachstum\n- Industrie\n- Arbeitsplätze\n- Investitionen\n- Innovation\n- Export\n\n3. Arbeitslosenquote\n- Arbeitsmarkt\n- Arbeitslosengeld\n- Arbeitsvermittlung\n- Qualifikationen\n- Arbeitslosenversicherung\n\n4. Regierung\n- Politik\n- Parteien\n- Regierungsbildung\n- Koalitionen\n- Opposition\n\n5. Bayern-Power\n- Regionalpolitik\n- Infrastruktur\n- Bildung\n- Kultur\n- Tourismus\n\n6. Ampel-Frust\n- Politikverdrossenheit\n- Koalitionsstreitigkeiten\n- Stillstand\n- Kompromisse\n- Unzufriedenheit\n\n7. Familiengeld\n- Familienpolitik\n- Kinderbetreuung\n- Elternzeit\n- Kindergeld\n- Unterstützung\n\n8. Pflegegeld\n- Pflegepolitik\n- Altenpflege\n- Pflegeversicherung\n- Pflegeheim\n- Angehörigenpflege\n\n9. Meisterausbildung\n- Berufsausbildung\n- Fachkräftemangel\n- Handwerk\n- Aufstiegschancen\n- Weiterbildung\n\n10. Briefwahl\n- Wahlrecht\n- Wahlbeteiligung\n- Demokratie\n- Wahlkampf\n- Stimmabgabe"
  },
  {
    "objectID": "notebooks/2023_12_11_GPT_Text_Classification2.html",
    "href": "notebooks/2023_12_11_GPT_Text_Classification2.html",
    "title": "Run the Few-Shot request.",
    "section": "",
    "text": "system_prompt = \"\"\"\nYou are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\n**Examples:**\n\"Wir sind EIN Volk! 🇩🇪 In Leipzig nahm es den Anfang, breitete sich aus wie ein Lauffeuer und ebnete den Weg für die deutsche Einheit. Was damals viel Arbeit war, zahlte sich aus. Was heute noch Arbeit ist, wird sich auszahlen. Ein geeintes Deutschland ist keine Selbstverständlichkeit und wir sind dankbar für die Demokratie, den Rechtsstaat und unsere freiheitliche Gesellschaft. Und wir arbeiten täglich dafür, dass uns diese Werte erhalten bleiben.\": positive\n\"FREIE WÄHLER Wir FREIE WÄHLER kämpfen für eine flächendeckende Gesundheitsversorgung auch auf dem Land. HUBERT AJUANGER\": neutral\n\"Die #Grünen sind mit dafür verantwortlich, dass die #Ampel-Regierung in Berlin meilenweit an der Lebenswirklichkeit der Menschen vorbei regiert. Ausgerechnet unter einem grünen Klimaminister lässt die Akzeptanz für #Klimaschutz in der Gesellschaft nach. Mit uns wird es keine Grünen in der Bayerischen Staatsregierung geben.\": negative\n\"\"\"\n\n\nprompt = \"\"\"\nPlease classify the following social media comment into either ‘negative’, ‘neutral’, or ‘positive’. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase.\nText: [TEXT]\n\"\"\"\n\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI! Make sure run_request and system_prompt are defined before this block by running the two blocks above (see Setup for GPT)!\nFill in the MOCK, RESET_COST, COLUMN, SAMPLE_SIZE, and MODEL variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\n\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n#@markdown What's the column name to save the results of the data extraction task to?\nCOLUMN = 'Sentiment' # @param {type: \"string\"}\n#@markdown Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\nSAMPLE_SIZE = 25 # @param {type: \"number\", min: 0}\n\n#@markdown Which model do you want to use?\nMODEL = \"gpt-3.5-turbo-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n\n\n# Initializing the empty column\nif COLUMN not in df.columns:\n  df[COLUMN] = None\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nfiltered_df = df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df[COLUMN])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        p = prompt.replace('[TEXT]', row['Text'])\n        response = run_request(system_prompt, p, MODEL, MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n\n          # Update the 'new_df' DataFrame\n          df.at[index, COLUMN] = r\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\nCost: $0.0010 | Total: $0.0278\n\n\n\n\n\n\ndf[~pd.isna(df['Sentiment'])].sample(5)\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nSentiment\n\n\n\n\n1833\n1833\nCxunhdYNvw3\ntanten\nOCR\nNaN\nneutral\n\n\n2299\n2299\nCxJAr3Ht7mh\nEIN JAHR FEMINISTISCHE REVOLUTION IM IRAN LASS...\nOCR\nNaN\nneutral\n\n\n369\n369\nCx2gzYdIv5d\nWir gratulieren Sven Schulze, der gestern in M...\nCaption\nNaN\npositive\n\n\n1886\n1886\nCxqbrYztMdC\nBerliner Senat; nachdem er rausgefunden hat, d...\nOCR\nNaN\nnegative\n\n\n290\n290\nCx7ruIdiOXb\n#TagderdeutschenEinheit \\n\\nUnser #Bayern hat ...\nCaption\n['LosvonBerlin', 'Bayernpartei']\nnegative\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Save Results\ndf.to_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\n\nimport matplotlib.pyplot as plt\n\n# Count the occurrences of each sentiment\nsentiment_counts = df['Sentiment'].value_counts()\n\n# Create a bar chart\nsentiment_counts.plot(kind='bar')\n\n# Adding labels and title\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Sentiment Counts')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "notebooks/2024_01_02_Interrater_Embedded.html",
    "href": "notebooks/2024_01_02_Interrater_Embedded.html",
    "title": "Social Media Lab",
    "section": "",
    "text": "pip install krippendorff\n\n\ndef draw_coding_plot_fixed(coder1, coder2):\n    # Determine the number of codings (columns)\n    num_codings = max(len(coder1), len(coder2))\n\n    # Create a figure and axis with a fixed size\n    fig, ax = plt.subplots(figsize=(10, 5))  # Fixed size for better control\n\n    # Remove axis lines and ticks\n    ax.axis('off')\n\n    # Adding labels for Coders\n    ax.text(-1, 2.5, 'Coder 1', fontsize=10, ha='right')\n    ax.text(-1, 1, 'Coder 2', fontsize=10, ha='right')\n    ax.set_aspect('equal')\n\n\n    # Function to draw circles\n    def draw_circles(codes, y_coord):\n        for index, code in enumerate(codes):\n            circle_color = 'black' if code == 1 else 'none'\n            ax.add_patch(plt.Circle((index+0.5, y_coord), 0.4, color=circle_color, ec='black', lw=1))\n\n    # Drawing circles for codings\n    draw_circles(coder1, 2.8)\n    draw_circles(coder2, 1.25)\n\n    # Set plot limits\n    ax.set_xlim(0, num_codings)\n    ax.set_ylim(0.5, 5)\n\n    # Show plot\n    plt.show()\n\n\nimport numpy as np\nimport krippendorff\n\ndef calculate_krippendorffs_alpha(coder1, coder2):\n    \"\"\"Calculate Krippendorff's Alpha.\"\"\"\n    data = np.vstack([coder1, coder2])\n    alpha = krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n    return alpha\n\ndef generate_controlled_coding(n_items, disagreement_rate):\n    # Generate coder1 coding\n    coder1 = np.random.choice([0, 1], size=n_items)\n\n    # Initially set coder2 to be the same as coder1\n    coder2 = np.copy(coder1)\n\n    # Calculate the number of disagreements\n    n_disagreements = int(n_items * (disagreement_rate / 100))\n\n    # Introduce disagreements\n    disagreement_indices = np.random.choice(n_items, n_disagreements, replace=False)\n    for index in disagreement_indices:\n        coder2[index] = 1 - coder2[index]\n\n    return coder1, coder2\n\n# Example usage\nn_items = 65\ndisagreement_rate = 10 # 30% disagreement rate\ncoder1, coder2 = generate_controlled_coding(n_items, disagreement_rate)\n\nprint(f\"n: {n_items}\")\nprint(f\"Disagreement: {disagreement_rate}%\")\nprint(f\"Krippendorff's Alpha: {calculate_krippendorffs_alpha(coder1, coder2)}\")\n\ndraw_coding_plot_fixed(coder1, coder2)\n\nn: 65\nDisagreement: 10%\nKrippendorff's Alpha: 0.8164136622390892"
  },
  {
    "objectID": "notebooks/2023_12_11_GPT_Text_Classification4.html",
    "href": "notebooks/2023_12_11_GPT_Text_Classification4.html",
    "title": "Run the extraction of multiple variables.",
    "section": "",
    "text": "system_prompt = \"\"\"\nYou're an expert in detecting calls-to-action (CTAs) from texts.\n**Objective:**\nDetermine the presence or absence of explicit and implicit CTAs within German-language content sourced from Instagram texts such as posts, stories, video transcriptions, and captions related to political campaigns from the given markdown table.\n**Instructions:**\n1. Examine each user input as follows:\n2. Segment the content into individual sentences.\n3. For each sentence, identify:\n   a. Explicit CTA: Direct requests for an audience to act which are directed at the reader, e.g., \"beide Stimmen CDU!\", \"Am 26. September #FREIEWÄHLER in den #Bundestag wählen.\"\n   b. Explicit CTA: A clear direction on where or how to find additional information, e.g. \"Mehr dazu findet ihr im Wahlprogramm auf fdp.de/vielzutun\", \"Besuche unsere Website für weitere Details.\"\n   c. Implicit CTA: Suggestions or encouragements that subtly propose an action directed at the reader without a direct command, e.g., \"findet ihr unter dem Link in unserer Story.\"\n4. Classify whether an online or offline action is referrenced.\n5. CTAs should be actions that the reader or voter can perform directly, like voting for a party, clicking a link, checking more information, etc. General statements, assertions, or suggestions not directed at the reader should not be classified as CTAs.\n5. Return boolean variables for Implicit CTAs (`Implicit`), Explicit CTAs (`Explicit`), `Online`, and `Offline` as a JSON objet.\n**Formatting:**\nOnly return the JSON object, nothing else. Do not repeat the text input.\n\"\"\"\n\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI!\nNote: This code block adds some logic to deal with multiple variables contained in the JSON object: {\"Implicit\": false, \"Explicit\": false, \"Online\": false, \"Offline\": false}. We add the columns Implicit, Explicit, Online, and Offline accordingly. To classify different variables the code need to be modified accordingly. ChatGPT can help with this task!\nFill in the MOCK, RESET_COST, SAMPLE_SIZE, COLUMNS and MODEL variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\nimport json\n\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n#@markdown Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\nSAMPLE_SIZE = 5 # @param {type: \"number\", min: 0}\n\n#@markdown Which model do you want to use?\nMODEL = \"gpt-3.5-turbo-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n\n#@markdown Which variables did you define in your Prompt?\nCOLUMNS = [\"Implicit\", \"Explicit\", \"Online\", \"Offline\"] # @param {type: \"raw\"}\n\n# This method extracts the four variables from the response.\ndef extract_variables(response_str):\n    # Initialize the dictionary\n    extracted = {}\n\n    for column in COLUMNS:\n      extracted[column] = None\n\n    try:\n        # Parse the JSON string\n        data = json.loads(response_str)\n\n        for column in COLUMNS:\n          # Extract variables\n          extracted[column] = data.get(column, None)\n\n        return extracted\n\n    except json.JSONDecodeError:\n        # Handle JSON decoding error (e.g., malformed JSON)\n        print(\"Error: Response is not a valid JSON string.\")\n        return extracted\n    except KeyError:\n        # Handle cases where a key is missing\n        print(\"Error: One or more keys are missing in the JSON object.\")\n        return extracted\n    except Exception as e:\n        # Handle any other exceptions\n        print(f\"An unexpected error occurred: {e}\")\n        return extracted\n\n\n# Initializing the empty column\nif COLUMN not in df.columns:\n  df[COLUMN] = None\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nfiltered_df = df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df[COLUMN])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        p = row['Text']\n        response = run_request(system_prompt, p, MODEL, MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n          extracted = extract_variables(r)\n\n          for column in COLUMNS:\n            df.at[index, column] = extracted[column]\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\nCost: $0.0191 | Total: $0.0838\n\n\n\n\n\n\ndf[~pd.isna(df['Implicit'])]\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nCall\nImplicit\nExplicit\nOnline\nOffline\n\n\n\n\n442\n442\nCxxXJBtAHhv\nFriedrich Merz ist nicht gerade bekannt für se...\nCaption\n['Asylbewerberleistungsgesetz', 'Zahnsanierung...\nNone\nFalse\nFalse\nFalse\nFalse\n\n\n453\n453\nCxvqTwmtlJK\nDamit es uns nicht so ergeht wie den Indianern...\nCaption\nNaN\nNone\nFalse\nTrue\nFalse\nTrue\n\n\n494\n494\nCxs9ujENMqI\n🔹#Krankenhäuser🔹#Geburtsstationen und 🔹#Hebamm...\nCaption\n['Krankenhäuser', 'Geburtsstationen', 'Hebamme...\nNone\nFalse\nTrue\nFalse\nTrue\n\n\n839\n839\nCxWF0mcqrhg\nUnterwegs im oberbayerischen Moosburg: Herzlic...\nCaption\nNaN\nNone\nFalse\nTrue\nFalse\nTrue\n\n\n1818\n1818\nCxvKsBBos0j\n9801 Bayerische Staatsregierung MISSION 7272 9...\nOCR\nNaN\nNone\nFalse\nFalse\nFalse\nFalse"
  },
  {
    "objectID": "notebooks/literature-review.html",
    "href": "notebooks/literature-review.html",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "This notebook demonstrates how to work with the GPT-API based on a simple use case. First, we are going to import search results of our literature review with Publish or Perish. Next, we are going to explore how we could use python in combination with Publish or Perish to speed up our review process: We will manually code the relevance, using the Jupyter notebook as our labelling interface. Afterwards we are going to add a GPT-API call to extract features from the abstract, the first step towards our assistant guiding our literature review process.\nOverall, this notebooks is a simple implementation demonstrating how prompts work and how easy it is to use GPT in Jupyter notebooks. The notebook is available in the supplement repository, you can clone the notebook to your Colab account with one click."
  },
  {
    "objectID": "notebooks/literature-review.html#setup",
    "href": "notebooks/literature-review.html#setup",
    "title": "GPT Literature Review Assistant",
    "section": "Setup",
    "text": "Setup\nAt first we need to install necessary packages. Hit run and wait.\n\nprint(\"Install Packages\")\n!pip install -q openai crossref-commons"
  },
  {
    "objectID": "notebooks/literature-review.html#import-publish-or-perish-data.",
    "href": "notebooks/literature-review.html#import-publish-or-perish-data.",
    "title": "GPT Literature Review Assistant",
    "section": "Import Publish or Perish Data.",
    "text": "Import Publish or Perish Data.\nIf this is the start of your review process, upload the csv file exported from Publish or Perish in the left-hand Files pane. Enter the filename in publish_or_perish_file_name. Define the output name in file_name. If you want to save the imported file in the google drive add /content/drive/MyDrive/ to the path.  Skip this cell if you want to work with a file that has been imported in the past.\n\n\n\n\n\n\nWarning\n\n\n\nWe delete rows with missing DOIs. Without a DOI our code cannot retrieve abstracts. When importing the Publish or Perish file, the following code will display the number of rows that have been deleted due to missing DOIs. When using this notebook for real-world projects, you should be aware of the missing rows and manually review them!\n\n\n\n#@title Import from Publish or Perish Data.\n#@markdown If this is the start of your review process, upload the `csv` file exported from [Publish or Perish](https://harzing.com/resources/publish-or-perish) in the left-hand *Files* pane. Enter the filename in `publish_or_perish_file_name`. Define the output name in `file_name`. If you want to save the imported file in the google drive add `/content/drive/MyDrive/` to the path. &lt;br/&gt; **Skip this cell if you want to work with a file that has been imported in the past.**\n\nimport pandas as pd\nimport numpy as np\nimport io\n\npublish_or_perish_file_name = \"scholar.csv\" # @param {type: \"string\"}\nfile_name = \"2023-10-31-Literature-Review.csv\" # @param {type: \"string\"}\n\n# Initialize empty DataFrame\nall_data = pd.DataFrame()\n\n\ntry:\n    all_data = pd.read_csv(publish_or_perish_file_name)\n\n    # Remove Duplicates\n    initial_len = len(all_data)\n    all_data = all_data.drop_duplicates(subset='DOI', keep='first')\n    removed_len = initial_len - len(all_data)\n    print(f'Removed {removed_len} duplicates based on DOI.')\n\n    # Remove missing DOIs\n    initial_len = len(all_data)\n    all_data = all_data[~pd.isna(all_data['DOI'])]\n    removed_len = initial_len - len(all_data)\n    print(f'Removed {removed_len} rows without DOI.')\n\n    all_data = all_data.sort_values(by='Cites', ascending=False).reset_index(drop=True)\n\n    print('Sorted Table by Cites.')\n\n    # Create empty columns for Literature Review\n    all_data[\"Relevant\"] = \"\"\n    all_data[\"Notes\"] = \"\"\n    all_data[\"Checked\"] = False\n\n    print('Initialized Columns')\n\n    all_data.to_csv(file_name)\n    print(f\"Success: Saved data to {file_name}\")\n\n    print(f'Success: Data loaded from File \"{file_name}\".')\nexcept Exception as e:\n    print(f\"Error: Failed to load data from File. {str(e)}\")\n\nRemoved 172 duplicates based on DOI.\nRemoved 1 rows without DOI.\nSorted Table by Cites.\nInitializes Columns\nSuccess: Saved data to 2023-10-31-Literature-Review.csv\nSuccess: Data loaded from File \"2023-10-31-Literature-Review.csv\"."
  },
  {
    "objectID": "notebooks/literature-review.html#read-previously-imported-file",
    "href": "notebooks/literature-review.html#read-previously-imported-file",
    "title": "GPT Literature Review Assistant",
    "section": "Read previously imported File",
    "text": "Read previously imported File\nIf you want to keep going with a former review process, we can read an uploaded file / a file from google drive. Only run one cell, this one or the above.\n\n#@title Read previously imported File\n#@markdown If you want to keep going with a former review process, we can read an uploaded file / a file from google drive. **Only run one cell, this one or the above.**\nimport pandas as pd\nimport numpy as np\nimport io\n\nfile_name = \"2023-10-31-Literature-Review.csv\" # @param {type: \"string\"}\n\ntry:\n    all_data = pd.read_csv(file_name)\n\n    print(f'Success: Data loaded from File \"{file_name}\".')\nexcept Exception as e:\n    print(f\"Error: Failed to load data from File. {str(e)}\")\n\nSuccess: Data loaded from File \"2023-10-31-Literature-Review.csv\".\n\n\n\nIn this example we’ve saved the file locally. When working with Colab, the file will be deleted when we disconnect. For colab you should link your google drive (open the files pane on the left, click the Google Drive button). Once connected, save the file in the folder /content/drive/MyDrive/YOUR-FILENAME.csv. It will be accessible through Drive, and Colab is from now on going to connect automatically to drive.\nCheck the imported data. We’re using pandas, the imported data is saved in the all_datavariable. head(2)displays the two top rows of the table. Additionally, we have added three columns: Relevant, Notes, and Checked. We are going to make use of them to keep track of our progress.\n\n# Check the structure (and content) of the file\nall_data.head(2)\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0.2\nUnnamed: 0.1\nUnnamed: 0\nCites\nAuthors\nTitle\nYear\nSource\nPublisher\nArticleURL\n...\nAge\nAbstract\nFullTextURL\nRelatedURL\nbabbage_similarity\nbabbage_search\nsimilarities\nRelevant\nNotes\nChecked\n\n\n\n\n0\n0\n746\n844\n21\nFlorian Arendt\nSuicide on Instagram – Content Analysis of a G...\n2019.0\nCrisis\nHogrefe Publishing Group\nhttp://dx.doi.org/10.1027/0227-5910/a000529\n...\n3.0\nAbstract. Background: Suicide is the second le...\nhttps://econtent.hogrefe.com/doi/pdf/10.1027/0...\nNaN\n[-0.0018475924152880907, 0.022463073953986168,...\n[-0.014954154379665852, 0.026176564395427704, ...\n-1\nNaN\nNaN\nFalse\n\n\n1\n1\n770\n868\n4\nPaloma de H. Sánchez-Cobarro, Francisco-Jose M...\nThe Brand-Generated Content Interaction of Ins...\n2020.0\nJournal of Theoretical and Applied Electronic ...\nMDPI AG\nhttp://dx.doi.org/10.3390/jtaer16030031\n...\n2.0\nThe last decade has seen a considerable increa...\nhttps://www.mdpi.com/0718-1876/16/3/31/pdf\nNaN\n[-0.0029447057750076056, 0.01190990675240755, ...\n[-0.01012819167226553, 0.02539714053273201, -0...\n-1\nNaN\nNaN\nFalse\n\n\n\n\n\n2 rows × 35 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nIn the next step we are going to start our literature review:\n\nWe filter for the first unchecked row, ordered by the cite count.\nWe retrieve the abstract from CrossRef API using the DOI.\nWe display all information\nWe answer whether the paper appear to be relevant by entering y or n for yes or no.\n\nFor our session, the cell only runs through one row and finishes afterwards. For a real world application you’d probably like to add some kind of loop.\n\nfrom crossref_commons.retrieval import get_publication_as_json\nimport json\nimport openai\nimport textwrap\nimport IPython\nimport re\n\n# Get one row: Not checked, highest Citation count.\nhighest_cites_unchecked = all_data[all_data['Checked'] == False].sort_values(by=\"Cites\", ascending=False).iloc[0]\nindex = highest_cites_unchecked.name\n\n# Retrieve Abstract from Crossref\nresponse = get_publication_as_json(highest_cites_unchecked['DOI'])\nabstract = response.get(\"abstract\", \"\")\n\n# Remove XML\nabstract = re.sub(r'&lt;[^&gt;]+&gt;', '', abstract)\nall_data.loc[index, 'Abstract'] = abstract\n\n\n# Display all information\nIPython.display.clear_output(wait=True)\ntitle_disp = IPython.display.HTML(\"&lt;h2&gt;{}&lt;/h2&gt;\".format(highest_cites_unchecked['Title']))\nauthors_disp = IPython.display.HTML(\"&lt;p&gt;{}&lt;/p&gt;\".format(highest_cites_unchecked['Authors']))\ndoi_disp = IPython.display.HTML(\"&lt;p&gt;&lt;a target='_blank' href='https://doi.org/{}'&gt;{}&lt;/a&gt;&lt;/p&gt;\".format(highest_cites_unchecked['DOI'],highest_cites_unchecked['DOI']))\ndisplay(title_disp, authors_disp, doi_disp)\nprint(textwrap.fill(abstract, 80))\nrelevant_input = input('Relevant? (y/n): ').lower().strip() == 'y'\n\n# Save user input\nall_data.loc[index, 'Checked'] = True\nall_data.loc[index, 'Relevant'] = relevant_input\n\nSuicide on Instagram – Content Analysis of a German Suicide-Related Hashtag\n\n\nFlorian Arendt\n\n\n10.1027/0227-5910/a000529\n\n\nAbstract. Background: Suicide is the second leading cause of death among\n15–29-year-olds globally. Unfortunately, the suicide-related content on\nInstagram, a popular social media platform for youth, has not received the\nscholarly attention it deserves. Method: The present study provides a content\nanalysis of posts tagged as #selbstmord, a German suicide-related hashtag. These\nposts were created between July 5 and July 11, 2017. Results: Approximately half\nof all posts included words or visuals related to suicide. Cutting was by far\nthe most prominent method. Although sadness was the dominant emotion, self-hate\nand loneliness also appeared regularly. Importantly, inconsistency – a gap\nbetween one's inner mental state (e.g., sadness) and one's overtly expressed\nbehavior (e.g., smiling) – was also a recurring theme. Conversely, help-seeking,\ndeath wishes, and professional awareness–intervention material were very rare.\nAn explorative analysis revealed that some videos relied on very fast cutting\ntechniques. We provide tentative evidence that users may be exposed to\npurposefully inserted suicide-related subliminal messages (i.e., exposure to\ncontent without the user's conscious awareness). Limitations: We only\ninvestigated the content of posts on one German hashtag, and the sample size was\nrather small. Conclusion: Suicide prevention organizations may consider posting\nmore awareness–intervention materials. Future research should investigate\nsuicide-related subliminal messages in social media video posts. Although\ntentative, this finding should raise a warning flag for suicide prevention\nscholars.\nRelevant? (y/n): y\n\n\nNext, we check whether our input has been saved:\n\n# Check the result\nall_data.iloc[index]\n\nUnnamed: 0.2                                                          0\nUnnamed: 0.1                                                        746\nUnnamed: 0                                                          844\nCites                                                                21\nAuthors                                                  Florian Arendt\nTitle                 Suicide on Instagram – Content Analysis of a G...\nYear                                                             2019.0\nSource                                                           Crisis\nPublisher                                      Hogrefe Publishing Group\nArticleURL                  http://dx.doi.org/10.1027/0227-5910/a000529\nCitesURL                                                            NaN\nGSRank                                                               26\nQueryDate                                           2022-09-08 10:44:44\nType                                                    journal-article\nDOI                                           10.1027/0227-5910/a000529\nISSN                                                          0227-5910\nCitationURL                                                         NaN\nVolume                                                             40.0\nIssue                                                               1.0\nStartPage                                                          36.0\nEndPage                                                            41.0\nECC                                                                  21\nCitesPerYear                                                        7.0\nCitesPerAuthor                                                       21\nAuthorCount                                                           1\nAge                                                                 3.0\nAbstract              Abstract. Background: Suicide is the second le...\nFullTextURL           https://econtent.hogrefe.com/doi/pdf/10.1027/0...\nRelatedURL                                                          NaN\nbabbage_similarity    [-0.0018475924152880907, 0.022463073953986168,...\nbabbage_search        [-0.014954154379665852, 0.026176564395427704, ...\nsimilarities                                                         -1\nRelevant                                                           True\nNotes                                                               NaN\nChecked                                                            True\nName: 0, dtype: object"
  },
  {
    "objectID": "notebooks/literature-review.html#using-gpt-to-extract-information-from-abstracts",
    "href": "notebooks/literature-review.html#using-gpt-to-extract-information-from-abstracts",
    "title": "GPT Literature Review Assistant",
    "section": "Using GPT to extract information from abstracts",
    "text": "Using GPT to extract information from abstracts\nNow for the fun part: Is it possible to use GPT to help us during the review process? We are going to try and extract text features automatically. For the moment we are going to use gpt3.5-turbo.\nNote: Please feel free to test different prompts and questions. The Promptingguide is a good resource to learn more about different prompting techniques. Use the ChatGPT interface to cheaply test prompts prior to using them with the API. Use the OpenAI Playground to optimize your prompts with a visual user interface for different settings and a prompting history (trust me, this can save your life!).\nPrompts: We’re going to use the system prompt for our instructions, and the user prompt to send our content.\n\n\n\n\n\n\nCaution\n\n\n\nA word of warning: You should not trust the quality of the GPT output at this stage. The prompt has not been evaluated, overall LLMs produce output that appears meaningful most of the times. Sometimes, however, it is Hallucinations. Thus, before using prompts and LLMs for production, we have to make sure we can trust their outputs. We will dive deeper into this topic in the classification sessions.\n\n\n\nsystem_prompt = \"\"\"\nYou're an advanced AI research assistant. Your task is to extract **research questions**, **operationalization**, **data sources**, **population**, and **scientific disciplines** from user input. Return \"None\" if you can't find the information in user input.\n\n**Formatting**\nReturn a markdown table, one row for each extracted feature: **research questions**, **operationalization**, **data sources**, **population**, and **scientific disciplines**.\n\"\"\"\n\nPlease enter your API-Code in the next code cell for the openai.api_key variable. We have changed the cell to include the gpt_prompt variable, which sends the title and abstract as a user prompt. We’re using the openai.ChatCompletion.create() method to send our request to the API. We expect the response in api_response['choices'][0]['message']['content'] to be markdown (see prompt above), as such we display the markdown in our notebook.\n\nfrom crossref_commons.retrieval import get_publication_as_json\nimport json\nimport openai\nimport textwrap\nimport IPython\nimport re\n\n# Enter OpenAI API-Code\nopenai.api_key = \"sk-XXXXXXXXX\"\n\n# Get one row: Not checked, highest Citation count.\nhighest_cites_unchecked = all_data[all_data['Checked'] == False].sort_values(by=\"Cites\", ascending=False).iloc[0]\nindex = highest_cites_unchecked.name\n\n# Retrieve Abstract from Crossref\nresponse = get_publication_as_json(highest_cites_unchecked['DOI'])\nabstract = response.get(\"abstract\", \"\")\n\n# Remove XML\nabstract = re.sub(r'&lt;[^&gt;]+&gt;', '', abstract)\n\nall_data.loc[index, 'Abstract'] = abstract\n\n# Display all information (before we send the request to OpenAI)\nIPython.display.clear_output(wait=True)\ntitle_disp = IPython.display.HTML(\"&lt;h2&gt;{}&lt;/h2&gt;\".format(highest_cites_unchecked['Title']))\nauthors_disp = IPython.display.HTML(\"&lt;p&gt;{}&lt;/p&gt;\".format(highest_cites_unchecked['Authors']))\ndoi_disp = IPython.display.HTML(\"&lt;p&gt;&lt;a target='_blank' href='https://doi.org/{}'&gt;{}&lt;/a&gt;&lt;/p&gt;\".format(highest_cites_unchecked['DOI'],highest_cites_unchecked['DOI']))\ndisplay(title_disp, authors_disp, doi_disp)\nprint(textwrap.fill(abstract, 80))\n\ngpt_prompt = f\"\"\"\n**Title**: {highest_cites_unchecked['Title']}\n**Abstract**: {abstract}\n\"\"\"\n\n# Sending request, takes a moment. In the meantime you may read the abstract.\nmessages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": abstract}\n]\n\ntry:\n  api_response = openai.ChatCompletion.create(\n      model=\"gpt-3.5-turbo\",\n      messages=messages,\n      temperature=0,\n      timeout=30\n    )\n\n  gpt_result = api_response['choices'][0]['message']['content']\n\n  # Display the GPT result\n  display(IPython.display.HTML(f\"&lt;h3&gt;GPT Extracted Data&lt;/h3&gt;\"))\n  display(IPython.display.Markdown(gpt_result))\nexcept:\n  print(\"GPT API Error\")\n\nrelevant_input = input('Relevant? (y/n): ').lower().strip() == 'y'\n\n# Save user input\nall_data.loc[index, 'Checked'] = True\nall_data.loc[index, 'Relevant'] = relevant_input\n\nThe Brand-Generated Content Interaction of Instagram Stories and Publications: A Comparison between Retailers and Manufacturers\n\n\nPaloma de H. Sánchez-Cobarro, Francisco-Jose Molina-Castillo, Cristina Alcazar-Caceres\n\n\n10.3390/jtaer16030031\n\n\nThe last decade has seen a considerable increase in entertainment-oriented\ncommunication techniques. Likewise, the rise of social networks has evolved,\noffering different formats such as publication and stories. Hence, there has\nbeen a growing interest in knowing which strategies have the greatest social\nimpact to help position organizations in the mind of the consumer. This research\naims to analyze the different impact that stories and publications can have on\nthe Instagram social network as a tool for generating branded content. To this\nend, it analyses the impact of the different Instagram stories and publications\nin various sectors using a methodology of structural equations with composite\nconstructs. The results obtained, based on 800 stories and publications in four\ndifferent companies (retailers and manufacturers), show that the reach of the\nstory generally explains the interaction with Instagram stories. In contrast, in\nthe case of publications, impressions are of greater importance in explaining\nthe interaction with the publication. Among the main contributions of the work,\nwe find that traditional pull communication techniques have been losing\neffectiveness in front of new formats of brand content generation that have been\noccupying the time in the relationship between users and brands.\nRelevant? (y/n): y\n\n\nGPT Extracted Data\n\n\n\n\n\n\n\n\n\nFeature\nValue\n\n\n\n\nResearch questions\n- What strategies have the greatest social impact on Instagram?- How do stories and publications on Instagram impact the consumer’s perception of brands?- What is the relationship between reach and interaction with Instagram stories?- What is the relationship between impressions and interaction with Instagram publications?\n\n\nOperationalization\n- Analyzing the impact of Instagram stories and publications in various sectors- Using a methodology of structural equations with composite constructs\n\n\nData sources\n- 800 stories and publications on Instagram\n\n\nPopulation\n- Four different companies (retailers and manufacturers)\n\n\nScientific disciplines\n- Marketing- Communication\n\n\n\n\n\n\nThe above output shows a formatted table listing all extracted features. In this short warm-up session on GPT we have seen one use case of the LLM: The extraction of text feautures. In future sessions we are going to dive deeper into this topic.\n\n\n\n\n\n\nNote\n\n\n\nDid you create an excellent prompt? Share it with us! Enter your prompt into this Excel Sheet"
  },
  {
    "objectID": "notebooks/literature-review.html#save-your-progress",
    "href": "notebooks/literature-review.html#save-your-progress",
    "title": "GPT Literature Review Assistant",
    "section": "Save your Progress",
    "text": "Save your Progress\nThe following line saves all progress to file_name. If file_name is a path to Google Drive you will be able to pick up your work later on.\n\nall_data.to_csv(file_name)"
  },
  {
    "objectID": "notebooks/2024_01_12_kMeans.html",
    "href": "notebooks/2024_01_12_kMeans.html",
    "title": "Visual Exploration",
    "section": "",
    "text": "import pandas as pd\n\n# Load the CSV file\nmemespector_file = \"/content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-11-Google-Vision-All.csv\"\ndf = pd.read_csv(memespector_file)\n\ndf = df[['Image_BaseName', 'GV_Label_Descriptions']]\n\n# Splitting the 'GV_Label_Descriptions' into individual labels\nsplit_labels = df['GV_Label_Descriptions'].str.split(';').apply(pd.Series, 1).stack()\nsplit_labels.index = split_labels.index.droplevel(-1)  # to line up with df's index\nsplit_labels.name = 'Label'\n\n# Joining the split labels with the original dataframe\ndf_split = df.join(split_labels)\n\n# Creating a matrix of True/False values for each label per Image_BaseName\nmatrix = pd.pivot_table(df_split, index='Image_BaseName', columns='Label', aggfunc=lambda x: True, fill_value=False)\n\n# Resetting the column headers to be the label names only\nmatrix.columns = [col[1] for col in matrix.columns.values]\n\n# Now 'matrix' has a single level of column headers with only the label names\n\n\nmatrix\n\n\n  \n    \n\n\n\n\n\n\nAdaptation\nAdvertising\nAfterglow\nAgricultural machinery\nAgriculture\nAir travel\nAircraft\nAirliner\nAirplane\nAlloy wheel\n...\nVertebrate\nWater\nWater resources\nWheel\nWhiskers\nWhite\nWindow\nWood\nWorking animal\nWorld\n\n\nImage_BaseName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6750551853789891846.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6750761577349254405.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6751467034741067014.jpg\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6763591353164254469.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6766552734108749062.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7321800737606896928.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321804342179204384.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321804909290999045.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321806774967815457.jpg\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321806890906701089.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n982 rows × 681 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Ensuring that 'Image_BaseName' is not part of the matrix to apply PCA\nimage_base_names = matrix.index  # Saving the image base names for later use\nlabel_matrix = matrix.values  # Convert to numpy array for PCA\n\n# Dimensionality reduction using PCA\n# Considering a variance ratio of 0.95 to determine the number of components\npca = PCA(n_components=0.95)\nmatrix_reduced = pca.fit_transform(label_matrix)\n\n# If needed, you can create a DataFrame from the PCA-reduced matrix and reattach the 'Image_BaseName' column\nmatrix_reduced_df = pd.DataFrame(matrix_reduced, index=image_base_names)\n\n\nmatrix_reduced_df\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n\n\nImage_BaseName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6750551853789891846.jpg\n1.392793\n-0.851573\n-0.225060\n-0.630954\n0.345822\n-0.313126\n0.376667\n0.370456\n-0.012519\n-0.898472\n...\n-0.007803\n0.022912\n-0.002782\n0.019272\n-0.005465\n-0.005129\n0.011833\n0.000200\n0.006499\n0.010995\n\n\n6750761577349254405.jpg\n-1.045212\n0.139963\n-0.396712\n0.505531\n-0.186165\n0.278001\n0.860551\n-0.387782\n-0.041959\n0.146992\n...\n0.020865\n0.027422\n0.064993\n0.046791\n0.042511\n-0.040843\n-0.091713\n-0.064683\n0.043392\n-0.045372\n\n\n6751467034741067014.jpg\n0.364738\n0.089808\n0.603463\n0.717136\n0.084382\n0.130516\n0.835040\n0.056190\n-0.175465\n-0.551632\n...\n-0.009497\n0.144801\n-0.020713\n0.035502\n-0.085562\n-0.169911\n0.083582\n0.045916\n-0.123521\n0.032273\n\n\n6763591353164254469.jpg\n0.657532\n-0.007257\n-0.226448\n-0.142833\n-0.615043\n-0.208217\n-0.082478\n0.181550\n0.899774\n0.462160\n...\n-0.025889\n0.006257\n0.060421\n0.028564\n0.045773\n0.000179\n0.003499\n0.027838\n0.007171\n-0.051516\n\n\n6766552734108749062.jpg\n1.638604\n-0.418596\n-0.178993\n-0.522654\n0.663303\n-0.186928\n1.000894\n-0.307874\n-0.172688\n0.336597\n...\n-0.009052\n-0.002043\n0.007575\n-0.031553\n0.007831\n-0.005779\n-0.023599\n-0.021165\n-0.000496\n-0.006467\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7321800737606896928.jpg\n-0.698156\n0.191274\n-0.529836\n0.047008\n0.862388\n-0.111187\n-0.390502\n-0.089231\n0.144091\n0.326504\n...\n-0.015025\n-0.068188\n-0.023787\n0.009343\n0.004624\n0.001396\n0.097441\n0.145987\n-0.102992\n0.110626\n\n\n7321804342179204384.jpg\n0.032051\n0.048450\n0.454149\n-0.012114\n0.395014\n0.128612\n0.042362\n1.019634\n-0.367217\n1.025644\n...\n-0.002146\n-0.042328\n0.114229\n-0.066740\n-0.051395\n-0.021397\n0.012134\n0.046365\n-0.005712\n0.036329\n\n\n7321804909290999045.jpg\n1.005015\n0.923683\n0.371054\n0.533427\n0.356759\n0.813597\n0.087288\n-0.289707\n0.377865\n1.242866\n...\n0.005721\n0.000672\n0.021087\n0.020260\n0.037709\n0.000290\n0.015725\n0.013237\n0.018040\n-0.002060\n\n\n7321806774967815457.jpg\n-0.597974\n0.855850\n-0.262498\n-0.214283\n-0.731812\n-0.209626\n-0.179683\n0.529353\n-0.239506\n0.048401\n...\n-0.012399\n0.023383\n-0.073488\n0.063523\n0.013320\n0.020351\n-0.033865\n0.029809\n-0.080413\n-0.074329\n\n\n7321806890906701089.jpg\n-0.042383\n-0.138050\n0.075564\n-0.396196\n0.056236\n0.612394\n-0.272538\n-0.230238\n-0.379339\n-0.668773\n...\n-0.106623\n-0.214393\n0.209117\n0.021869\n0.220278\n0.070092\n-0.198979\n0.140981\n-0.004653\n-0.070667\n\n\n\n\n\n982 rows × 242 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Elbow method to determine optimal number of clusters\ninertia = []\nrange_values = range(1, 20)  # Checking for 1 to 10 clusters\n\nfor i in range_values:\n    kmeans = KMeans(n_clusters=i, n_init=10, random_state=0)\n    kmeans.fit(matrix_reduced_df)\n    inertia.append(kmeans.inertia_)\n\n# Plotting the Elbow Curve\nplt.figure(figsize=(10, 6))\nplt.plot(range_values, inertia, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport matplotlib.pyplot as plt\n\n# Define the range of clusters to try\nrange_values = range(2, 20)\n\nsilhouette_scores = []\n\n# Perform k-means clustering and compute silhouette scores\nfor i in range_values:\n    try:\n        kmeans = KMeans(n_clusters=i, n_init=10, random_state=0)\n        kmeans.fit(matrix_reduced_df)\n        score = silhouette_score(matrix_reduced_df, kmeans.labels_)\n        silhouette_scores.append(score)\n    except Exception as e:\n        print(f\"An error occurred with {i} clusters: {e}\")\n\n# Plotting the Silhouette Scores\nwith plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(10, 6))\n    plt.plot(range_values, silhouette_scores, marker='o')\n    plt.title('Silhouette Method')\n    plt.xlabel('Number of clusters')\n    plt.ylabel('Silhouette Score')\n    plt.show()\n\n\n\n\n\n# Final k-means clustering using n clusters\nkmeans_final = KMeans(n_clusters=11, n_init=10, random_state=0)\nclusters = kmeans_final.fit_predict(matrix_reduced)\n\n# Adding the cluster information back to the original dataframe\nmatrix['Cluster'] = clusters\n\n\n# Displaying the first few rows of the dataframe with cluster information\nmatrix.head()\n\n\n  \n    \n\n\n\n\n\n\nAdaptation\nAdvertising\nAfterglow\nAgricultural machinery\nAgriculture\nAir travel\nAircraft\nAirliner\nAirplane\nAlloy wheel\n...\nWater\nWater resources\nWheel\nWhiskers\nWhite\nWindow\nWood\nWorking animal\nWorld\nCluster\n\n\nImage_BaseName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6750551853789891846.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n8\n\n\n6750761577349254405.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n2\n\n\n6751467034741067014.jpg\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n6\n\n\n6763591353164254469.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n0\n\n\n6766552734108749062.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n8\n\n\n\n\n\n5 rows × 682 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n!unzip /content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-09-Images-Clean.zip\n\n\n# Display the result. See linked notebook for code."
  },
  {
    "objectID": "notebooks/corpus-analysis-notebook.html",
    "href": "notebooks/corpus-analysis-notebook.html",
    "title": "Social Media Lab",
    "section": "",
    "text": "Among a variety of possibilities, we can, for example, look at the frequencies of the words contained in the corpus or examine the corpus for recurring themes it contains.\nFirst we need to import all the required libraries once again. The Natural Language Toolkit (NLTK) gives us access to a variety of natural language processing functions (e.g. tokenisation, stop word removal, part-of-speech tagging, …).\n\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport requests\nimport pandas as pd\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n\n\nWhen analysing word frequencies, we can use stop word lists to ignore words that occur frequently but are not relevant to us. We can easily download such a list. However, this can also be individually adapted to the purpose.\n\n# Retrieve Stopwords from Github\nsw_json = requests.get('https://github.com/stopwords-iso/stopwords-de/raw/master/stopwords-de.json')\n\nNow we can tokenise the existing text, remove the stop words or punctuation marks they contain, convert the words to lower case, or use bi-grams in addition to single-word tokens.\nWe then sum up the occurrences of the individual words and make the results available in a DataFrame.\n\ndef word_freq(text, punctuation=False, stop_words = False, lowercasing = False, bigrams = False):\n\n    if punctuation:\n        # Tokenizing, removing punctuation\n        tokens = RegexpTokenizer(r'\\w+').tokenize(text) # https://regexr.com/\n    else:\n        # Tokenizing, w/o removing punctuation\n        # tokens = text.split()\n        tokens = word_tokenize(text)\n\n    if stop_words:\n        # Removing Stopwords\n        tokens = [w for w in tokens if not w.lower() in stop_words]\n\n    if lowercasing:\n        # Lower-Casing\n        tokens = [w.lower() for w in tokens]\n\n    if bigrams:\n        # Converting text tokens into bigrams\n        tokens = nltk.bigrams(tokens)\n\n    # Creating Data Frame\n    freq = nltk.FreqDist(tokens) # display(freq)\n    df = pd.DataFrame.from_dict(freq, orient='index')\n    df.columns = ['Frequency']\n    df.index.name = 'Term'\n\n    # Here we calculate the total number of tokens in our Frequency List\n    total_tokens = sum(freq.values()) # sum([2,3,4,5,6])\n\n    # Here we add a new column `Relative` (*100 for percentage)\n    df['Relative'] = (df['Frequency'] / total_tokens) * 100\n\n    return df\n\n\nfrom pathlib import Path\nimport os\n\n#@markdown Do you want bigrams included?\nbigrams = True #@param {type:\"boolean\"}\n\n#@markdown Should all words get lower cased before counting the occurances?\nlowercasing = True #@param {type:\"boolean\"}\n\n#@markdown Do you want to exclude stopwords in your result list?\nstopwords = True #@param {type:\"boolean\"}\n\n#@markdown Do you want to remove punctuation before counting the occurances?\npunctuation = True #@param {type:\"boolean\"}\n\n\n# Load stopwords file if necessary\nif stopwords:\n    stopwords = sw_json.json()\n\n# Read source file and concat all texts\ntext = ' '.join(list(df[text_column]))\n\n# Call word_freq() with specified parameters\ndf_freq = word_freq(text, punctuation = punctuation, stop_words = stopwords, lowercasing = lowercasing, bigrams = bigrams)\n\n# Sort results for descending values\ndf_freq = df_freq.sort_values(\"Relative\", ascending = False)\n\ndisplay(df_freq[0:10])\n\n\n  \n    \n\n\n\n\n\n\nFrequency\nRelative\n\n\nTerm\n\n\n\n\n\n\n(jüdisches, leben)\n5\n1.259446\n\n\n(allerheiligen, allerseelen)\n4\n1.007557\n\n\n(ilse, aigner)\n3\n0.755668\n\n\n(bayerischer, landtag)\n3\n0.755668\n\n\n(klare, haltung)\n2\n0.503778\n\n\n(wünschen, einfach)\n2\n0.503778\n\n\n(vaters, freundschaftliche)\n2\n0.503778\n\n\n(tod, vaters)\n2\n0.503778\n\n\n(günter, tod)\n2\n0.503778\n\n\n(schwiegervater, günter)\n2\n0.503778\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nWordcloud\nOne way to visualise word frequencies and recurring themes of texts are word clouds. These basically show the most frequently occurring words in the text (similar to the table created earlier), but more frequently occurring words are depicted larger than less frequently occurring words.\nFirst, we have to install the necessary library wordcloud.\n\n!pip install -q wordcloud\n\nThe actual implementation of this approach is relatively simple. We need to combine all the texts into a single text, as we did in the previous step with the frequency analysis, and pass it to the imported library.\n\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef generate_wordcloud(text, path):\n\n    text = ' '.join(list(text))\n\n    # Generate a word cloud image\n    wordcloud = WordCloud(background_color=\"white\",width=1920, height=1080).generate(text)\n\n    # Dazugehörige Grafik erstellen\n    plt.imshow(wordcloud, interpolation=\"bilinear\") # Auflösung/Interpolation der Grafik\n    plt.axis(\"off\")\n    plt.figtext(0.5, 0.1, wordcloud_subcaption, wrap=True, horizontalalignment='center', fontsize=12)\n    plt.savefig(path, dpi=300)\n    plt.show()\n\nOnce again, we have the option of adjusting various parameters. Remember to specify the right file path, file name and column of your text data!\n\n#@markdown Input for additional stopwords; whitespace separated\nstopwords_extension_wc = '' #@param {type: \"string\"}\n\n#@markdown Subcaption for the wordcloud, leave blank to ignore\nwordcloud_subcaption = 'Markus S\\xF6der' #@param {type: \"string\"}\n\nNow all we have to do is load the stop word file, add our own additions and then trigger the creation of the word cloud using the function we created at the beginning.\nThe result image is saved in the defined data_path.\n\nimport matplotlib.pyplot as plt\nimport requests\n\n# Retrieve Stopwords from Github\nr = requests.get('https://github.com/stopwords-iso/stopwords-de/raw/master/stopwords-de.json')\nstop_words = r.json()\n\n# Convert input into list\nstopwords_extension_wc_list = stopwords_extension_wc.split(' ')\nstop_words.extend(stopwords_extension_wc_list)\n\n# Stopwörter in die WordCloud laden\nSTOPWORDS.update(stop_words)\n\n\ngenerate_wordcloud(df[text_column], 'wordcloud.png')"
  },
  {
    "objectID": "notebooks/whisper-notebook.html",
    "href": "notebooks/whisper-notebook.html",
    "title": "Social Media Lab",
    "section": "",
    "text": "Extract Audio from Video File\nAfter loading the metadta and media files from the Google Drive, we extract the audio from each video file to prepare the automated transcription.\n\n!pip install -q moviepy\n\n\nimport os\n\n# Set audio directory path\naudio_path = \"media/audio/\"\n\n# Check if the directory exists\nif not os.path.exists(audio_path):\n    # Create the directory if it does not exist\n    os.makedirs(audio_path)\n\n\nfrom moviepy.editor import *\n\nfor index, row in df.iterrows():\n    if row['video_file'] != \"\":\n        # Load the video file\n        video = VideoFileClip(row['video_file'])\n        filename = row['video_file'].split('/')[-1]\n\n        # Extract the audio from the video file\n        audio = video.audio\n\n        if audio is not None:\n            sampling_rate = audio.fps\n            current_suffix = filename.split(\".\")[-1]\n            new_filename = filename.replace(current_suffix, \"mp3\")\n\n            # Save the audio to a file\n            audio.write_audiofile(\"{}{}\".format(audio_path, new_filename))\n        else:\n            new_filename = \"No Audio\"\n            sampling_rate = -1\n\n        # Update DataFrame inplace\n        df.at[index, 'audio_file'] = new_filename\n        df.at[index, 'duration'] = video.duration\n        df.at[index, 'sampling_rate'] = sampling_rate\n\n        df.at[index, 'video_file'] = row['video_file'].split('/')[-1]\n\n        # Close the video file\n        video.close()\n\nMoviePy - Writing audio in media/audio/CzD93SEIi-E.mp3\nMoviePy - Done.\n\n\n                                                                      \n\n\nWe’ve extracted the audio content of each video file to a mp3 file in the media/audio folder. The files keep the name of the video file. We added new columns to the metadata for audio duration and sampling_rate. In case the video did not include an audio file, smapling_rateis set to -1, which we use to filter the df when transcribing the files.\n\ndf[df['video_file'] != \"\"].head()\n\n\n  \n    \n\n\n\n\n\n\nid\nthread_id\nparent_id\nbody\nauthor\nauthor_fullname\nauthor_avatar_url\ntimestamp\ntype\nurl\n...\nnum_comments\nnum_media\nlocation_name\nlocation_latlong\nlocation_city\nunix_timestamp\nvideo_file\naudio_file\nduration\nsampling_rate\n\n\n\n\n4\nCzD93SEIi-E\nCzD93SEIi-E\nCzD93SEIi-E\nMitzuarbeiten für unser Land, Bayern zu entwic...\nmarkus.soeder\nMarkus Söder\nhttps://scontent-fra3-1.cdninstagram.com/v/t51...\n2023-10-31 12:06:23\nvideo\nhttps://www.instagram.com/p/CzD93SEIi-E\n...\n227\n1\nNaN\nNaN\nNaN\n1698753983\nCzD93SEIi-E.mp4\nCzD93SEIi-E.mp3\n67.89\n44100.0\n\n\n\n\n\n1 rows × 24 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\nLet’s update the ZIPed folder to include the audio files.\n\n!zip -r /content/drive/MyDrive/2023-11-24-4CAT-Images-Clean.zip media\n\nupdating: media/ (stored 0%)\nupdating: media/videos/ (stored 0%)\nupdating: media/videos/CzD93SEIi-E.mp4 (deflated 0%)\n  adding: media/audio/ (stored 0%)\n  adding: media/audio/CzD93SEIi-E.mp3 (deflated 1%)\n\n\nAnd save the updated metadata file. Change filename when importing stories here!\n\ndf.to_csv(four_cat_file_path)\n\nTranscriptions using Whisper\n\nThe Whisper model was proposed in Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.\n\n\nThe abstract from the paper is the following:\n\n\n\nWe study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zeroshot transfer setting without the need for any finetuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.\n\n\n– https://huggingface.co/docs/transformers/model_doc/whisper\n\n!pip install -q transformers\n\nThe next code snippet initializes the Whisper model. The transcribe_aduio method is applied to each row of the dataframe where sampling_rate &gt; 0, thus only to those lines with referencees to audio files. Each audio file is transcribed using Whisper, the result, one text string, is saved to the transcript column.\nAdjust the language variable according to your needs! The model is also capable of automated translation, e.g. setting language to english when processing German content results in an English translation of the speech. (Additionally, the task variable accepts translate).\n\nimport torch\nfrom transformers import pipeline, WhisperProcessor, WhisperForConditionalGeneration\nimport librosa\n\n# Set device to GPU if available, else use CPU\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize the Whisper model pipeline for automatic speech recognition\npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=\"openai/whisper-large\",\n    chunk_length_s=30,\n    device=device,\n)\n\n# Load model and processor for multilingual support\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n\n# Function to read, transcribe, and handle longer audio files in different languages\ndef transcribe_audio(filename, language='german'):\n    try:\n        # Load and resample audio file\n        audio_path = f\"{audio_folder}/{filename}\"\n        waveform, original_sample_rate = librosa.load(audio_path, sr=None, mono=True)\n        waveform_resampled = librosa.resample(waveform, orig_sr=original_sample_rate, target_sr=16000)\n\n        # Get forced decoder IDs for the specified language\n        forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=\"transcribe\")\n\n        # Process the audio file in chunks and transcribe\n        transcription = \"\"\n        for i in range(0, len(waveform_resampled), 16000 * 30):  # 30 seconds chunks\n            chunk = waveform_resampled[i:i + 16000 * 30]\n            input_features = processor(chunk, sampling_rate=16000, return_tensors=\"pt\").input_features\n            predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n            chunk_transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n            transcription += \" \" + chunk_transcription\n\n        return transcription.strip()\n    except Exception as e:\n        print(f\"Error processing file {filename}: {e}\")\n        return \"\"\n\n\n# Filter the DataFrame (sampling_rates &lt; 0 identify items without audio)\nfiltered_index = df['sampling_rate'] &gt; 0\n\n# Apply the transcription function to each row in the filtered DataFrame\ndf.loc[filtered_index, 'transcript'] = df.loc[filtered_index, 'audio_file'].apply(transcribe_audio)\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\n\ndf[df['video_file'] != \"\"].head()\n\n\n  \n    \n\n\n\n\n\n\nid\nthread_id\nparent_id\nbody\nauthor\nauthor_fullname\nauthor_avatar_url\ntimestamp\ntype\nurl\n...\nnum_media\nlocation_name\nlocation_latlong\nlocation_city\nunix_timestamp\nvideo_file\naudio_file\nduration\nsampling_rate\ntranscript\n\n\n\n\n4\nCzD93SEIi-E\nCzD93SEIi-E\nCzD93SEIi-E\nMitzuarbeiten für unser Land, Bayern zu entwic...\nmarkus.soeder\nMarkus Söder\nhttps://scontent-fra3-1.cdninstagram.com/v/t51...\n2023-10-31 12:06:23\nvideo\nhttps://www.instagram.com/p/CzD93SEIi-E\n...\n1\nNaN\nNaN\nNaN\n1698753983\nCzD93SEIi-E.mp4\nCzD93SEIi-E.mp3\n67.89\n44100.0\nIch bitte auf den abgelagerten Vortrag der Maa...\n\n\n\n\n\n1 rows × 25 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\n\ndf.loc[4, 'transcript']\n\n'Ich bitte auf den abgelagerten Vortrag der Maaßen-Söder-Entfühlen ein.  Erfüllung meiner Amtspflichten, so wahr mir Gott helfe. Ich schwöre Treue der Verfassung des Freistaates Bayern, Gehorsam den Gesetzen und gewissenhafte Erfüllung meiner Amtspflichten, so wahr mir Gott helfe. Herr Ministerpräsident, ich darf Ihnen im Namen des ganzen Hauses ganz persönlich die herzlichsten Glückwünsche aussprechen und wünsche Ihnen viel Erfolg und gute Nerven auch bei Ihrer Aufgabe. Herzlichen Dank.  Applaus'\n\n\nOverall, the transcriptions work well. The first sentence above, however, shows that we still can expect misinterpretations."
  },
  {
    "objectID": "notebooks/ig-instaloader.html",
    "href": "notebooks/ig-instaloader.html",
    "title": "Instagram Posts",
    "section": "",
    "text": "In order to download posts and stories from Instagram, we use the package instaloader. You can install package for python using pip install &lt;package&gt;, the command -q minimizes the output.\n!pip -q install instaloader\n\n     |████████████████████████████████| 60 kB 3.0 MB/s eta 0:00:011\n  Building wheel for instaloader (setup.py) ... done\nOnce you install instaloader we log in using your username and password. Session information (not your credentials!) is stored in Google Drive to minimize the need for signing in.\nIn order to minimize the risk for your account to be disabled we suggest creating a new account on your phone before proceeding!\nusername = 'your.username'\n\n# We save the sessionfile to the following directory. Default is the new folder `.instaloader` in your google drive. (This is optional)\nsession_directory = '/content/drive/MyDrive/.instaloader/'\n\nimport instaloader\nfrom os.path import exists\nfrom pathlib import Path\n\n# Creating session directory, if it does not exists yet\nPath(session_directory).mkdir(parents=True, exist_ok=True)\n\nfilename = \"{}session-{}\".format(session_directory, username)\nsessionfile = Path(filename)\n\n\n# Get instance\nL = instaloader.Instaloader(compress_json=False)\n\n# Check if sessionfile exists. If so load session,\n# else login interactively\nif exists(sessionfile):\n  L.load_session_from_file(username, sessionfile)\n\nelse:\n  L.interactive_login(username)\n  L.save_session_to_file(sessionfile)\n\nLoaded session from /content/drive/MyDrive/.instaloader/session-mi_sm_lab05."
  },
  {
    "objectID": "notebooks/ig-instaloader.html#downloading-first-posts",
    "href": "notebooks/ig-instaloader.html#downloading-first-posts",
    "title": "Instagram Posts",
    "section": "Downloading first Posts",
    "text": "Downloading first Posts\nNext, we try to download all posts of a profile. Provide a username and folder:\n\ndest_username = 'some.profile' \ndest_dir = '/content/drive/MyDrive/insta-posts/' # Once more we save the files to Google Drive. Replace this with a local directory if necessary.\n\nt = Path(\"{}{}\".format(dest_dir, dest_username))\nt.mkdir(parents=True, exist_ok=True)\n\nprofile = instaloader.Profile.from_username(L.context, dest_username)\nfor post in profile.get_posts():\n    L.download_post(post, target=t)\n\nWell, you just downloaded your first posts! Open Google Drive and check the folder insta-posts/ (or whatever folder you chose above)! There should be three files for each post, the image, a .json file and a .txt file. The .txt includes the image caption, the .json lots of metadata about the post.\n\nDiving into the metadata\nThe next cell reads all .json files of the downloaded posts. Then we browse through some interesting data.\n\n# Reading the paths of all JSON files from dest_dir\nimport os\n\njson_files = []\n\nfor subdir, dirs, files in os.walk(t):\n    for file in files:\n        fullpath = os.path.join(subdir, file)\n        filename, file_extension = os.path.splitext(fullpath)\n        if file_extension == \".json\":\n          json_files.append(fullpath)\n\n\n# Reading all JSON files\nfrom tqdm.notebook import tqdm\nimport json\n\njson_data = []\n\nfor file in tqdm(json_files):\n  with open(file, 'r') as f:\n    data = json.load(f)\n    json_data.append(data)\n\n\n\n\nOk, now all metadata for all posts is saved to the variable json_data. Run the next line and copy its output to http://jsonviewer.stack.hu/. Your output should look similar, go ahead and play around to explore your data! What information can you extract?\n\nprint(json.dumps(json_data[0]))\n\n\n\nMetadata Preprocessing\nPosts contain plenty of data, like time and location of the post, the authoring user, a caption, tagged users and more. The following cells demonstrate how to normalize the data into a table format, which is useful when working with pandas. Nevertheless, this is optional!\n\n# Use booleans (True / False) values to select what type of data you'd like to analyse. \nusername = True #@param {type:\"boolean\"}\ntimestamp = True #@param {type:\"boolean\"}\ncaption = True #@param {type:\"boolean\"}\nlocation = True #@param {type:\"boolean\"}\nshortcode = True #@param {type:\"boolean\"}\nid = True #@param {type:\"boolean\"}\ntagged_users = True #@param {type:\"boolean\"}\n\nNext we loop through the data and create a new pandas DataFrame. The DataFrame will have one column for each variable selected above and one row for each downloaded posts.\nIf you are not yet familiar with the concept of dataframes have a look at YouTube, there’s plenty of introductory videos available.\n\nimport pandas as pd\n\nposts = []  # Initializing an empty list for all posts\nfor post in tqdm(json_data):\n  row = {} # Initializing an empty row for the post\n\n  node = post.get(\"node\")\n\n  if username:\n    owner = node.get(\"owner\")\n    row['username'] = owner.get(\"username\")\n\n  if timestamp:\n    row['timestamp'] = node.get(\"taken_at_timestamp\")\n\n  if location:\n    l = node.get(\"location\", None)\n    if l:\n      row['location'] = l.get(\"name\")\n\n  if shortcode:\n    row['shortcode'] = node.get(\"shortcode\")\n\n  if id:\n    row['id'] = node.get(\"id\")\n  \n  if tagged_users:\n    pass\n\n  if caption:\n    c = \"\"\n    emtc = node.get(\"edge_media_to_caption\")\n    edges = emtc.get(\"edges\")\n    for element in edges:\n      caption_node = element.get(\"node\")\n      c = c + caption_node.get(\"text\")\n    row['caption'] = c\n\n  # Finally add row to posts\n  posts.append(row)\n\n# After looping through all posts create data frame from list\nposts_df = pd.DataFrame.from_dict(posts)\n\nNow all information selected above is saved to the dataframe posts_df. Run the next cell and it will return a nicely formatted table. If your data is quite long, output will be cropped. Click the wand and after a few seconds you are able to browse through the data or filter by columns\n\nposts_df\n\nIn order to get a first impression of dataframes, the head() method is also useful. Run the next cell to see the result\n\nposts_df.head()\n\nThe dataframe is only saved in memory, thus when disconnecting and deleting the runtime, the dataframe is lost. Running the next cell saves the table to a CSV-file on your drive.\nNow the processed data may be recovered or used in another notebook.\n\nposts_df.to_csv('{}{}.csv'.format(dest_dir, username))"
  },
  {
    "objectID": "evaluation/index.html",
    "href": "evaluation/index.html",
    "title": "Human Annotations",
    "section": "",
    "text": "In computational social media analysis, validation is crucial for ensuring the accuracy and reliability of text analysis methods. As highlighted by Birkenmaier, Lechner, and Wagner (2023), validation entails both internal and external processes. Internal validation assess a model’s plausibility and quality within the data context and tends to rely researchers’ judgment, whereas external validation compares model outputs with external benchmarks, such as human-annotated labels. Baden et al. (2022) further emphasize the significance of continuous evaluation and transparent reporting of validation steps and results. Additionally, they criticize the the frequent oversight in evaluating the validity of the actual measures. This problem arises when researchers focus more on the technical performance of their models, neglecting to verify whether these models accurately represent the intended social phenomena. This gap can lead to results that are statistically sound but lack real-world relevance.\nIn context of our research projects we’ll focus on external validation through non-expert annotations using LabelStudio, a practical aspect of the validation approach. Our focus will be on generating gold standard data for an external validation. This is crucial because external validation, through methods like crowd annotation, directly assesses how well computational models perform against real-world data. The setup of LabelStudio projects and the creation of annotation manuals are key steps in this process, ensuring that the data used for validation is accurately and consistently labeled, providing a solid foundation for assessing model performance. Although the evaluation of the actual measures is important (Baden et al. 2022), our discussion will concentrate on these practical aspects of external validation.\nHaving humans coders annotate your social media content is the first part of generating a gold standard dataset. The second step will the the evaluation of the annotations, to validate their quality. We will use the interrater agreement as measurement for the coherence of our annotations. We will focus on this topic in the next session."
  },
  {
    "objectID": "evaluation/index.html#creating-an-annotation-manual",
    "href": "evaluation/index.html#creating-an-annotation-manual",
    "title": "Human Annotations",
    "section": "Creating an Annotation Manual",
    "text": "Creating an Annotation Manual\nDeveloping an annotation manual for social media text data is an iterative process. We start with a theoretical understanding of the phenomenon to be annotated, and describe it for easy application by annotators, minimizing ambiguity. The process optimally involves multiple rounds of annotation, each refining the guidelines through discussions of disagreements and revisions. Pilot annotations should be done by those familiar with the theory, focusing on major disagreements to refine categories and examples. As guidelines evolve, both the guidelines and annotators improve, while we need to make sure that the guidelines that are understandable even to less trained individuals (Reiter, Willand, and Gius 2019; Reiter, n.d.). In this section I will provide some examples for annotation manuals and some practical adivce to create effective annotation guidelines for social media analysis.\n\n\n\nExample of an annotation workflow with multiple iterations Source\n\n\nPractically speaking, get started by creating a document which can be shared online, e.g. on Google Docs or CodiMD. I suggest to structure you document as follows:\n.\n├── Introduction\n│   ├── Outline the research project:\n│   │   ├── What is your goal?\n│   │   └── Why do you need the help of annotators?\n│   ├── What can annotators expect?\n│   └── How are they being reimbursed? \n├── Overview of all steps, e.g.\n│   ├── How and where to register\n│   └── When to act\n├── Software Manual (LabelStudio HowTo)\n│   ├── Annotation Interface\n│   └── Keyboard Shortcuts\n├── Introduction to Variables\n│   ├── Definition for each variable / Values\n│   └── Instructions for each variable / Values\n└── Examples for each Variable\n    ├── Positive Examples\n    └── Negative Examples\nMake use of tables, images and formatting to guide the attention of the readers to the right places. Put emphasize on the most important parts of the annotation manual to gain good quality annotations. I have created several annotation projects in the past. The quality of the manuals started evolving as well. Take a look at the examples for a better understanding of good formatting and how to present examples to your annotators:\n\nCoding categories for images (German)\nCoding policy issues for text (German)\nCoding multiple content variables for text (German)\n\nBased on my personal experience I would recommend to:\n\nFocus on few variables per annotation project, due to two reasons: On the one hand it is easiert to read a short annotation manual for one or few variables and then keep annotating. We do not need to keep switching between tasks and thus to look up the definition of the one or the other variable again and again. On the other hand the software which we are going to use (LabelStudio) has a neat keyboard shortcut feature: This enables annotators to quickle select values by pressing buttons on their keyboard. The less options, the better shortcuts can be used (and remembered).\nGenerally speaking: Less is more. Keep the amount of variables low. Stick to one modality at a time. Keep the total amount of annotations per annotator at a manageable level (e.g. 2-3 hours of work) and ask the participants to take breaks when coding!\nThrough my annotations B.A. Students reached consistently lower annotation quality than M.A. / M.Sc. students.\nTo improve the quality I have experimented with Google Forms and generated a quiz. We can provide the correct solutions to questions, ask future annotators to take the quiz and they will receive some feedback on a test round of coding before starting the actual project.\nIn another approach to improve the quality I asked to participants first code a small subsets and take a qualitative look at the results. I gave feedback and resolved conflicts before adding the annotators to my actual project.\n\n\n\n\n\nA negative example: This annotation interface, based on Haßler, Kümpel, and Keller (2021), slows the annotation process down: Keyboard shortcuts cannot be used efficiently."
  },
  {
    "objectID": "evaluation/index.html#setup-an-annotation-project",
    "href": "evaluation/index.html#setup-an-annotation-project",
    "title": "Human Annotations",
    "section": "Setup an annotation project",
    "text": "Setup an annotation project\nWe are going to use Label Studio as an annotation interface. While we do not need to use a specialized software, Label Studio makes the process of setting up annotation projects, inviting and organizing annotators, and the actual annotation a lot easier. A low resource alternative to specialized annotation software is Excel: Convert your text DataFrame to an Excel sheet, delete all but the text columns, add columns for your variables, and write a detailed annotation manual for your coders how to fill in your Excel sheet. These steps are easy to reproduce and quick to implement, yet the specialized software makes sure that annotator input follows your standard as you may define a detailed interface, it shuffles the order of annotations, and it offers keyboard shortcuts to speed up annotations. Additionally (when using the Enterprise version which is free for researchers), it tracks time spent on annotations and calculates first scores to estimate interrater reliability. My Medium story “How to Accelerate your Annotation Process for Visual Social Media Analysis with Label Studio” goes into more detail.\nFor our seminar, we are going to use a self-hosted version of Label Studio. The biggest draw back is the limitation of one annotation per document. We can, however, overcome this limitation by setting up the same project three times and calculating interrater agreement measures ourselves (we are, of course, going to use standardized measures like Cohen’s \\(\\kappa\\), see Agreement & Evaluation).\n\nSetup a Label Studio project\nThe Label Studio Text Evaluation Notebook guides you step by step through the automated creation of a labelstudio project:\n\nInstall the label-studio-sdk package for programmatic control of Label Studio:\n\n!pip -q install label-studio-sdk\n\nNext, let’s read the text master from the previous sessions\n\nimport pandas as pd\n\ndf = pd.read_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\nIn my video on GPT text classification I mentioned the problem of the unique identifier, as we also need a unique identifier for the annotations. Use the code below in our text classification notebook when working with multidocument classifications!\n\ndf['identifier'] = df.apply(lambda x: f\"{x['shortcode']}-{x['Text Type']}\", axis=1)\n\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nidentifier\n\n\n\n\n0\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\n['1. Political parties:\\n- FREIEWÄHLER\\n- Aiwa...\nCyMAe_tufcR-Caption\n\n\n1\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\n['Landtagswahl']\nCyL975vouHU-Caption\n\n\n2\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\n['1. Wahlkampf und Wahlergebnis:\\n- Wahlkampf\\...\nCyL8GWWJmci-Caption\n\n\n3\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\n['Israel', 'Terrorismus', 'Hamas', 'Entwicklun...\nCyL7wyJtTV5-Caption\n\n\n4\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\n['1. Wahlsieg und Parlamentseinstieg\\n- Wahlsi...\nCyLxwHuvR4Y-Caption\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nLabelStudio Setup\nPlease specify the the URL and API-Key for you LabelStudio Instance.\n\nimport json\nfrom google.colab import userdata\n\nlabelstudio_key_name = \"label2-key\"\nlabelstudio_key = userdata.get(labelstudio_key_name)\nlabelstudio_url = \"https://label2.digitalhumanities.io\"\n\n\n\nCreate LabelStudio Interface\nBefore creating the LabelStudio project you will need to define your labelling interface. Once the project is set up you will only be able to edit the interface in LabelStudio.\n\ninterface = \"\"\"\n&lt;View style=\"display:flex;\"&gt;\n  &lt;View style=\"flex:33%\"&gt;\n    &lt;Text name=\"Text\" value=\"$Text\"/&gt;\n  &lt;/View&gt;\n  &lt;View style=\"flex:66%\"&gt;\n\"\"\"\n\n\n\nAdd a simple coding interface\nDo you want add codes (Classification) to the images? Please name your coding instance and add options.  By running this cell multiple times you’re able to add multiple variables (not recommended)\nAdd the variable name to coding_name, the checkbox labels in coding_values, and define whether to expect single choice or multiple choice input for this variable in coding_choice.\n\ncoding_name = \"Sentiment\"\ncoding_values = \"Positive,Neutral,Negative\"\ncoding_choice = \"single\"\n\ncoding_interface = '&lt;Header value=\"{}\" /&gt;&lt;Choices name=\"{}\" choice=\"{}\" toName=\"Text\"&gt;'.format(coding_name, coding_name,coding_choice)\n\nfor value in coding_values.split(\",\"):\n  value = value.strip()\n  coding_interface += '&lt;Choice value=\"{}\" /&gt;'.format(value)\n\ncoding_interface += \"&lt;/Choices&gt;\"\n\ninterface += coding_interface\n\nprint(\"Added {}\".format(coding_name))\n\nFinally run the next line to close the XML of the annotation interface. Run this line even if you do not want to add any variables at the moment!\n\ninterface += \"\"\"\n        &lt;/View&gt;\n    &lt;/View&gt;\n    \"\"\"\n\n\n\nProject Upload\nThis final step creates a LabelStudio project and configures the interface. Define a project_name, select the text_column, and identifier_column. Additionally, you may define a sample_percentage for sampling, we start with \\(30\\%\\). When working with the Open Source version of Label Studio we need to create on project per annotator, enter the number of annotators in num_copies to create multiple copies at once.\n\nfrom label_studio_sdk import Client\nimport contextlib\nimport io\n\nproject_name = \"vSMA Test 1\" \ntext_column = \"Text\" \nidentifier_column = \"identifier\" \nsample_percentage = 30  \nnum_copies = 1 \n\nsample_size = round(len(df) * (sample_percentage / 100))\n\nls = Client(url=labelstudio_url, api_key=labelstudio_key)\n\ndf_tasks = df[[identifier_column, text_column]]\ndf_tasks = df_tasks.sample(sample_size)\ndf_tasks = df_tasks.fillna(\"\")\n\nfor i in range(0, num_copies):\n  project_name = f\"{project_name} #{i}\"\n  # Create the project\n  project = ls.start_project(\n      title=project_name,\n      label_config=interface,\n      sampling=\"Uniform sampling\"\n  )\n\n  with contextlib.redirect_stdout(io.StringIO()):\n    project.import_tasks(\n          df_tasks.to_dict('records')\n        )\n\n  print(f\"All done, created project #{i}! Visit {labelstudio_url}/projects/{project.id}/ and get started labelling!\")\n\nAll done, created project #0! Visit https://label2.digitalhumanities.io/projects/61/ and get started labelling!\n\n\n\nSource: Create Label Studio Project\n\n\nDesigning an Interface\nWhile the above notebook contains some logic to algorithmically generate a simple annotation interface, I recommend to customize your interface using the Interface XML Tags and CSS. In order to change the interface, open your project and click on Settings.\n\n\n\nThe Settings button in the top-right corner of annotation projects.\n\n\nNext, select the Labeling Interface section and switch to code view. Here we can modify the interface using the custom Label Studio XML in a manner similar to HTML pages.\n\n\n\nThe Labeling Interface in the project settings\n\n\nWhen workig with Text the next tag is essential:\n&lt;Text name=\"Text\" value=\"$Text\"/&gt;\nHere we define a Text tag with the name Text, prefilled with the content of the Text column of the previously uploaded DataFrame, through the $Text placeholder. If you wanted to e.g. fill the tag with the identifier column set value=\"$identifier\".\nHere is an example of a clear and simple coding interface that I used in a past project:\n\n\n\nAn example of a labeling interface for political communication.\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote the Unsure option: It is good practice to offer annotators a fallback option in case of uncertainty. These uncertainties can, at a later stage, be resolved, e.g. through an expert review.\n\n\nAnd the XML / CSS code for the interface:\n&lt;View&gt;\n   &lt;Style&gt; .caption { background: white; padding: 10px; border-radius: 5px; font-size:medium; max-width:728px; margin:auto;}&lt;/Style&gt;\n  &lt;Style&gt; .interface {padding: 20px; margin: auto;}&lt;/Style&gt;\n  &lt;View className=\"caption\"&gt;\n   &lt;Text name=\"Text\" value=\"$Text\"/&gt;\n  &lt;/View&gt;\n  &lt;View style=\"display:flex; box-shadow: 2px 2px 5px #999; padding: 5px; border-radius: 5px; max-width:680px; margin: auto; margin-top: 2em;\"&gt;\n    &lt;View className=\"interface\"&gt;\n&lt;Header value=\"Positioning\" /&gt;&lt;Choices name=\"Positioning\" choice=\"single\" toName=\"Text\"&gt;&lt;Choice value=\"True\" /&gt;&lt;Choice value=\"False\" selected=\"true\" /&gt;&lt;Choice value=\"Unsure\" /&gt;&lt;/Choices&gt;\n    &lt;/View&gt;\n    &lt;View className=\"interface\"&gt;\n      &lt;Header value=\"Call to Action\" /&gt;&lt;Choices name=\"Call to Action\" showInline=\"false\" choice=\"single\" toName=\"Text\"&gt;&lt;Choice value=\"True\" /&gt;&lt;Choice value=\"False\" selected=\"true\"  /&gt;&lt;Choice value=\"Unsure\" /&gt;&lt;/Choices&gt;\n    &lt;/View&gt;\n    &lt;View className=\"interface\"&gt;\n      &lt;Header value=\"Documenation\" /&gt;&lt;Choices name=\"Documentation\" showInline=\"false\" choice=\"single\" toName=\"Text\"&gt;&lt;Choice value=\"True\" /&gt;&lt;Choice value=\"False\" selected=\"true\"  /&gt;&lt;Choice value=\"Unsure\" /&gt;&lt;/Choices&gt;\n    &lt;/View&gt;\n    &lt;View className=\"interface\"&gt;\n      &lt;Header value=\"Unleserlich\" /&gt;&lt;Choices name=\"OCR\" showInline=\"false\" choice=\"single\" toName=\"Text\"&gt;&lt;Choice value=\"True\" /&gt;&lt;Choice value=\"False\" selected=\"true\"  /&gt;&lt;Choice value=\"Unsure\" selected=\"false\" style=\"visibility:hidden;\"/&gt;&lt;/Choices&gt;\n    &lt;/View&gt;\n  &lt;/View&gt;\n    &lt;/View&gt;\n\n\n\n\n\n\nTip\n\n\n\nGive it a try to design an interface with the help of ChatGPT! Beware, the linked chat generated a mediocre solution: Some style tags are not being applied, yet the interface is fully functional and looks better than the standard interface. Generating an optimal interface takes time, both in conversation with ChatGPT, and from scratch.\n\n\nOverall, the provided notebook and examples offer various options to export your social media data to label studio and to create a custom interface for your annotation project. It is, as outlined in the creating an annotation manual, important to test the annotation manual and the annotation interface through multiple iterations. Make use of your project teams here!"
  },
  {
    "objectID": "evaluation/index.html#collect-annotations",
    "href": "evaluation/index.html#collect-annotations",
    "title": "Human Annotations",
    "section": "Collect Annotations",
    "text": "Collect Annotations\nThe annotation manual is written, the data has been added to a label studio project, the manual and interface have both been tested and improved through several iterations: Now you are ready to invite annotators to your project! In context of our research seminar we aim at non-expert annotators. We may make use of our “Versuchspersonenstunden” (participant hours) system, thus we may hire students as annotators. For each hour of participation, their receive one participant hours. An ideal annotation project in this context should not exceed two hours! The uni website offers all information on participant hours. Additionally, members from each group are welcome to participate in the other’s annotation projects, allowing for mutual exchange of participation."
  },
  {
    "objectID": "evaluation/index.html#conclusion",
    "href": "evaluation/index.html#conclusion",
    "title": "Human Annotations",
    "section": "Conclusion",
    "text": "Conclusion\nBaden et al. (2022) and Birkenmaier, Lechner, and Wagner (2023) provide sound arguments for the need of validation when working with methods of computational text analysis. This chapter outlined the first practical steps towards an external validation of computational classifications: Creating an annotation manual, and setting up an annotation project. In the next session, we will take a look at the actual evaluation of computational classifications: First we are going to evaluate the quality of our human annotations through interrater agreement measurements. In an intermediary step we will derive ground truth data through majority decisions (following a common practiceto improve the quality of the final dataset (Davani, Dı́az, and Prabhakaran 2022)), before calculating the evaluation metrics (accuracy, refall, F1-scores) for our model comparing the gold standard dataset with the computational annotations."
  },
  {
    "objectID": "evaluation/index.html#further-reading",
    "href": "evaluation/index.html#further-reading",
    "title": "Human Annotations",
    "section": "Further Reading",
    "text": "Further Reading\n\nStudies in Communication and Media: Special Issue on Content Analysis"
  },
  {
    "objectID": "getting-started/index.html",
    "href": "getting-started/index.html",
    "title": "About the Seminar",
    "section": "",
    "text": "The research seminar Computational Analysis of Visual Social Media consists of project-centred work in groups, lectures on theory and practical sessions. Each group will follow their own research interests and datasets. Groups will be formed in the third session, together with preliminary topics. We have participants from different fields, the topics will mirror this interdisciplinarity, roughly drawn from the interesctions of media studies, political science, and communication science. The seminar aims at master students with first knowledge of at least one programming language.\n\n\nBy the end of the semester you should know more about:\n\nThe state of Social Media Research,\ninteresting questions to answer with social media data,\nethical and legal restrictions,\ndevelop operationalizations for visual and textual data,\n\n\n\n\nBy the end of the semester you will be able to:\n\nCollect Instagram stories, posts and TikTok videos,\napply OCR and automatically transcribe videos,\ncomputationally classify text and images using GPT and CLIP,\nevaluate and optimize your classifications using human annotations,\npresent your results.\n\n\n\n\nThe following expectations and criteria must be met to pass the course:\n\nIndependent familiarization with your own scientific topic: Literature research, formulation of research questions, and operationalization.\nWillingness to master new tools (supported by practical units and some provided Jupyter Notebooks).\nActive and regular team collaboration on the individual project.\nContinuous documentation of current progress through a project wiki.\nWriting a project report at the end of the semester.\n\n\n\n\n\nWe will openly document our project progress, incorporating a strong Open Science stance.\nThe project report template is a good starting point for your report and continuous documentation.\nThrough the semester we will come back to the draft and extend it towards the final report.\nThe goal is to publish the report on social-media-lab.net.\n\n\n\n\n\nThe project report will be handed in collaboratively,\nconsists of app. 20 pages,\nfollows the IMRAD1 principle,\nuses APA citation style,\nneeds to be handed in no later than 31.03.2024.\n\n\n\n\n\nSuggest your own project\nPossible Projects:\n\nLandtagswahl BY 2023\n\nIG Stories & Posts\nTikTok\nJugendorganisationen\n\nPolitische Influencer auf TikTok\nWar in Sozialen Medien:\n\nUkraine Invasion\nHamas Angriff auf Israel\n\nFalschinformationen & KI-Generierte Inhalte\n\n\n\n\n\n\nMost course material will be available on social-media-lab.net.\nAdditional material will be provided via GRIPS.\nWe will work collaboratively on the website through the semester.\nThe content is edited using Quarto and Markdown, you will need a GitHub Account.\nPlease provide your GitHub username to get access to the repository.\nAll content will be published under GPL-3."
  },
  {
    "objectID": "getting-started/index.html#what-to-expect-theoretical-skills",
    "href": "getting-started/index.html#what-to-expect-theoretical-skills",
    "title": "About the Seminar",
    "section": "",
    "text": "By the end of the semester you should know more about:\n\nThe state of Social Media Research,\ninteresting questions to answer with social media data,\nethical and legal restrictions,\ndevelop operationalizations for visual and textual data,"
  },
  {
    "objectID": "getting-started/index.html#what-to-expect-practical-skills",
    "href": "getting-started/index.html#what-to-expect-practical-skills",
    "title": "About the Seminar",
    "section": "",
    "text": "By the end of the semester you will be able to:\n\nCollect Instagram stories, posts and TikTok videos,\napply OCR and automatically transcribe videos,\ncomputationally classify text and images using GPT and CLIP,\nevaluate and optimize your classifications using human annotations,\npresent your results."
  },
  {
    "objectID": "getting-started/index.html#class-requirements",
    "href": "getting-started/index.html#class-requirements",
    "title": "About the Seminar",
    "section": "",
    "text": "The following expectations and criteria must be met to pass the course:\n\nIndependent familiarization with your own scientific topic: Literature research, formulation of research questions, and operationalization.\nWillingness to master new tools (supported by practical units and some provided Jupyter Notebooks).\nActive and regular team collaboration on the individual project.\nContinuous documentation of current progress through a project wiki.\nWriting a project report at the end of the semester."
  },
  {
    "objectID": "getting-started/index.html#project-documentation",
    "href": "getting-started/index.html#project-documentation",
    "title": "About the Seminar",
    "section": "",
    "text": "We will openly document our project progress, incorporating a strong Open Science stance.\nThe project report template is a good starting point for your report and continuous documentation.\nThrough the semester we will come back to the draft and extend it towards the final report.\nThe goal is to publish the report on social-media-lab.net."
  },
  {
    "objectID": "getting-started/index.html#project-report",
    "href": "getting-started/index.html#project-report",
    "title": "About the Seminar",
    "section": "",
    "text": "The project report will be handed in collaboratively,\nconsists of app. 20 pages,\nfollows the IMRAD1 principle,\nuses APA citation style,\nneeds to be handed in no later than 31.03.2024."
  },
  {
    "objectID": "getting-started/index.html#project-ideas",
    "href": "getting-started/index.html#project-ideas",
    "title": "About the Seminar",
    "section": "",
    "text": "Suggest your own project\nPossible Projects:\n\nLandtagswahl BY 2023\n\nIG Stories & Posts\nTikTok\nJugendorganisationen\n\nPolitische Influencer auf TikTok\nWar in Sozialen Medien:\n\nUkraine Invasion\nHamas Angriff auf Israel\n\nFalschinformationen & KI-Generierte Inhalte"
  },
  {
    "objectID": "getting-started/index.html#social-media-lab",
    "href": "getting-started/index.html#social-media-lab",
    "title": "About the Seminar",
    "section": "",
    "text": "Most course material will be available on social-media-lab.net.\nAdditional material will be provided via GRIPS.\nWe will work collaboratively on the website through the semester.\nThe content is edited using Quarto and Markdown, you will need a GitHub Account.\nPlease provide your GitHub username to get access to the repository.\nAll content will be published under GPL-3."
  },
  {
    "objectID": "getting-started/index.html#introduction-to-social-media-analysis",
    "href": "getting-started/index.html#introduction-to-social-media-analysis",
    "title": "About the Seminar",
    "section": "Introduction to Social Media Analysis",
    "text": "Introduction to Social Media Analysis\n\nOverview of social media studies\n\nWhich academic disciplines are interested in plattforms like Instagram?\nWhat is their interest, how do they study the user generated content?\nSpecial focus: Political Communication on Instagram\n\nHow to conduct your own literature review\nTheory: Digital Methods & Cultural Analytics\nA short word about ethics & laws"
  },
  {
    "objectID": "getting-started/index.html#getting-started-tools",
    "href": "getting-started/index.html#getting-started-tools",
    "title": "About the Seminar",
    "section": "Getting Started: Tools",
    "text": "Getting Started: Tools\n\nInstallation & Configuration of different tools.\n\nGoogle Colab / Jupyter Notebooks\nQuarto & Markdown for project documentation\nGit & GitHub\nFirefox Plugins\nFigma\nand more"
  },
  {
    "objectID": "getting-started/index.html#data-collection-ig-posts-stories",
    "href": "getting-started/index.html#data-collection-ig-posts-stories",
    "title": "About the Seminar",
    "section": "Data Collection: IG Posts & Stories",
    "text": "Data Collection: IG Posts & Stories\n\nPost types and platform affordances of Instagram\nHow to use Instaloader\nHow to use CrowdTangle2\nCollecting Stories using Zeeschuimer-F and the firebase backend.\nCollecting Posts using Zeeschuimer and 4CAT\n\n\n\n\nScreenshot of the CrowdTangle interface."
  },
  {
    "objectID": "getting-started/index.html#data-collection-tiktok",
    "href": "getting-started/index.html#data-collection-tiktok",
    "title": "About the Seminar",
    "section": "Data Collection: TikTok",
    "text": "Data Collection: TikTok\n\nPost types and platform affordances of TikTok\nCollecting TikToks using Zeeschuimer and 4CAT\n\n\n\n\nScreenshot of the Firebase Backend and Zeeschuimer-F."
  },
  {
    "objectID": "getting-started/index.html#data-preprocessing",
    "href": "getting-started/index.html#data-preprocessing",
    "title": "About the Seminar",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\n\nOCR\nWe are going to use easyocr to detect and recognize text embedded in images, such as posts and stories.\nWe will export the first frame of videos for OCR and further analyses.\nAutomated Transcription\n\nWe will extract any audio from collected videos.\nWe will use whisper to transcribe the audio content of videos"
  },
  {
    "objectID": "getting-started/index.html#textual-exploration",
    "href": "getting-started/index.html#textual-exploration",
    "title": "About the Seminar",
    "section": "Textual Exploration",
    "text": "Textual Exploration\n\nWe will first take a look at the textual data using simple frequency analyses and wordclouds.\nWe will use the GPT-API to explore the textual content of our data.\nOptional we might use BERTopic to explore our textual data."
  },
  {
    "objectID": "getting-started/index.html#operationalization-i",
    "href": "getting-started/index.html#operationalization-i",
    "title": "About the Seminar",
    "section": "Operationalization I",
    "text": "Operationalization I\n\nThis session depends on your own research: By december you should have developed an initial research request and explored related work in order to develop the first operationalization for content analysis.\nWe will learn more about content analysis in this session.\nBased on your research, and the explorations of the previous sesssion, we will develop the first annotation guide.\nThrough the session we will explore how to (efficiently) use GPT for text data annotation."
  },
  {
    "objectID": "getting-started/index.html#data-annotation",
    "href": "getting-started/index.html#data-annotation",
    "title": "About the Seminar",
    "section": "Data Annotation",
    "text": "Data Annotation\n\nIn this session we will import our data into LabelStudio and develop a final annotation manual.\nUsing the manuals and LabelStudio projects we will annotate the data.\nWe will shuffle annotators: Everyone will annotate for another group."
  },
  {
    "objectID": "getting-started/index.html#evaluation-i",
    "href": "getting-started/index.html#evaluation-i",
    "title": "About the Seminar",
    "section": "Evaluation I",
    "text": "Evaluation I\n\nUsing the human annotations we will evaluate the performance of our computational text annotations / information extractions.\nWe can fine-tune our prompts using the annotation data to improve the annotation quality.\nWe will learn how to present and visualize the quality of the model."
  },
  {
    "objectID": "getting-started/index.html#exploration-of-visual-data",
    "href": "getting-started/index.html#exploration-of-visual-data",
    "title": "About the Seminar",
    "section": "Exploration of Visual Data",
    "text": "Exploration of Visual Data\n\nWe will explore different tools to visualize images:\nImageJ\nPixPlot\nMemespector and Gephi3\nThe visualization forms the basis for image classification: In this stage we want to find similarities and differences.\n\n\n\n\nExample of image exploration using PixPlot."
  },
  {
    "objectID": "getting-started/index.html#operationalization-ii",
    "href": "getting-started/index.html#operationalization-ii",
    "title": "About the Seminar",
    "section": "Operationalization II",
    "text": "Operationalization II\n\nOnce more a dive in the literature: This time on visual content analysis.\nCombining the results of our exploration, reserach interest and related work with content analysis, we will develop an annotation manual for the images.\nWe will learn how to use CLIP for image classification\nBased on your previous experience you will create human annotations.\nWe will shuffle annotators: Everyone will annotate for another group.\n\n\n\n\nDecomposition of different layers in a Story by @gruenebayern during the 2023 Bavarian state elections."
  },
  {
    "objectID": "getting-started/index.html#evaluation-ii",
    "href": "getting-started/index.html#evaluation-ii",
    "title": "About the Seminar",
    "section": "Evaluation II",
    "text": "Evaluation II\n\nOnce more we will evaluate the quality of our model,\nand fine-tune our prompts.\nWork in Progress: We might organize this session differently on short notice, depending on the outcomes of my current research project.\nWaiting in Progress: In case of visual GPT being published we might have to adapt.\n\n\n\n\nExample of a visual inspection of classification results: Intermediary results of image types classifications using CLIP for the 2021 federal election. Two out of five stories posted by differnt parties have been misclassified."
  },
  {
    "objectID": "getting-started/index.html#data-wrangling-as-a-conversation",
    "href": "getting-started/index.html#data-wrangling-as-a-conversation",
    "title": "About the Seminar",
    "section": "Data Wrangling as a Conversation",
    "text": "Data Wrangling as a Conversation\n\nThe Advanced Data Analysis mode of ChatGPT is a powerful tool to (quickly) analyze metadata (and more) of social media data.\nWe will give it a shot with some simple analyses, like trends over time.\nExperimental in case we have enough time left, we might try to create a workflow with LangChain and LlamaIndex to chat with our data."
  },
  {
    "objectID": "getting-started/index.html#visual-presentation-of-your-data",
    "href": "getting-started/index.html#visual-presentation-of-your-data",
    "title": "About the Seminar",
    "section": "Visual Presentation of your Data",
    "text": "Visual Presentation of your Data\n\nOur last session of the semester will be all about telling a story with your data.\nWe will use Python (Jupyter Notebooks) to transform our data in CSV files.\nWe will import the data into RAWGraphs to create convincing plots\nWe will use Figma to collaboratively sketch the layout of your project report website."
  },
  {
    "objectID": "getting-started/index.html#footnotes",
    "href": "getting-started/index.html#footnotes",
    "title": "About the Seminar",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIntroduction, Method, Result, Analaysis, Discussion↩︎\nI will not be able to provide access to the tool. We can, however, export data for our projects from the platform and you will learn how to use the exported data.↩︎\nfollowing Omena’s concept for cloud vision labels, see related work.↩︎"
  },
  {
    "objectID": "getting-started/tools.html",
    "href": "getting-started/tools.html",
    "title": "Tools and Software",
    "section": "",
    "text": "This page provides an overview of useful tools – not just for the visual social media analysis. In our tools session (October 30th) we will take a look at Colab and git / GitHub. As the semester progresses we will learn more tools, which gradually will be added to this page. A first list of software for the future sessions is linked at the bottom of the page."
  },
  {
    "objectID": "getting-started/tools.html#colab",
    "href": "getting-started/tools.html#colab",
    "title": "Tools and Software",
    "section": "Colab",
    "text": "Colab\nColab is a platform created by Google for collaborative work and research. It offers a preconfigured Python development environment with access to popular libraries and tools. It is based on Jupyter notebooks, which allows users to create and share documents that contain live code, equations, visualizations, and narrative text. Throughout the semester I am going to provide code for different applications as Jupyter notebooks, which can easily be accessed and run on Colab.\n\n\n\nA screenshot of Colab\n\n\nColab can be used for free, but it also offers a paid subscription plan called Colab Pro. The pro version offers, among other features, access to GPUs, which are often used for machine learning. We are probably going to use APIs and GPT throughout the semester, if we need to access GPUs we may use schlaubox."
  },
  {
    "objectID": "getting-started/tools.html#obsidian",
    "href": "getting-started/tools.html#obsidian",
    "title": "Tools and Software",
    "section": "Obsidian",
    "text": "Obsidian\nObsidian and Notion are excellent tools for note-taking. My personal recommendation is Obsidian, as it is free for personal use and notes are saved in markdown format on your harddrive. Thus, the software does not require any subscriptions. Use Dropbox, iCloud or Nextcloud to backup your files! Obsidian is a note-taking app based on the concept of interconnected notes.\n\n\n\nA screenshot of Obsidian\n\n\nThe app allows to easily link between notes, it is a flexible and powerful tool with a wide range of plugins available. Thanks to this large amount of plugins, it is also possible to extend its use. I recommend the dataloom plugin to organize excel-like lists, the textgenerator plugin to use GPT within Obsidian, and the Kanban plugin to organize your tasks. Additionally, use Day Planner to create daily todo lists, the citations plugin to organize your literature notes, and the admonition plugin to add visually outstanding text blocks. Use obsidian-git to collaborate using GitHub."
  },
  {
    "objectID": "getting-started/tools.html#open-research-quarto-for-project-documentation",
    "href": "getting-started/tools.html#open-research-quarto-for-project-documentation",
    "title": "Tools and Software",
    "section": "Open Research: Quarto for Project Documentation",
    "text": "Open Research: Quarto for Project Documentation\nQuarto is an innovative open-source scientific and technical publishing system. We can draft our research and projects using Jupyter notebooks or with plain text markdown in our chosen editors. What’s more, we’re able to craft dynamic content using Python, and other languages. When it comes to publishing our findings, we can produce reproducible, top-quality articles, presentations, websites, blogs, and books in various formats, including HTML, PDF, MS Word, and ePub. Writing is made easy with Pandoc markdown, letting us include equations, citations, cross-references, figure panels, callouts, and advanced layouts. The source for this website is available on GitHub. When working on your projects you will be able to share milestones using Quarto, telling a story with your data.\n\n\n\nA screenshot of this website opened in Visual Studio Code with quarto running in the terminal\n\n\nYou may clone the repository with git clone git@github.com:michaelachmann/social-media-lab-quarto.git. Add a folder for your projects in the projects folder and create a cover page called index.qmd. See the README for more information on how to commit and push your changes for publication. Everything will be reviewed before publication!"
  },
  {
    "objectID": "getting-started/tools.html#git-github",
    "href": "getting-started/tools.html#git-github",
    "title": "Tools and Software",
    "section": "Git & GitHub",
    "text": "Git & GitHub\nGit is a distributed version control system that enables us to track changes in our codebase, allowing multiple team members to work simultaneously without overwriting each other’s contributions. By creating and switching between different branches, we can experiment with new features or bug fixes without disturbing the main code. When we’re ready, merging these changes back into the main branch is straightforward. Moreover, Git’s history tracking feature ensures that we can always trace back our steps, understand the evolution of our code, and even revert to previous versions if necessary.\n\n\n\nA screenshot of commiting and pushing changes to the repository of this website.\n\n\n\nGitHub, Inc. (/ˈɡɪthʌb/[a]) is a platform and cloud-based service for software development and version control using Git, allowing developers to store and manage their code. It provides the distributed version control of Git plus access control, bug tracking, software feature requests, task management, continuous integration, and wikis for every project.[6] Headquartered in California, it has been a subsidiary of Microsoft since 2018. Wikipedia\n\nUsing GitHub, we can manage our projects, collaborate on coding tasks, and track changes seamlessly using Git. The platform can also be used to host research data and can connected to OSF, to provide code and data anonymously to reviewers. Using Zenodo we can create DOIs and provide citable software packages."
  },
  {
    "objectID": "getting-started/tools.html#future-sessions-outlook",
    "href": "getting-started/tools.html#future-sessions-outlook",
    "title": "Tools and Software",
    "section": "Future Sessions – Outlook",
    "text": "Future Sessions – Outlook\nVisual Exploration\n\nImageJ\nPixPlot\n\nImage Feature Extraction using APIs\n\nMemespector\n\nData Visualization\n\nFigma\nRawgraphs"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Michael Achmann  Universitätsstr. 31  93053 Regensburg  Email: michael.achmann@informatik.uni-regensburg.de  Phone: 0941 / 943 5098"
  },
  {
    "objectID": "about.html#website-owner",
    "href": "about.html#website-owner",
    "title": "About",
    "section": "",
    "text": "Michael Achmann  Universitätsstr. 31  93053 Regensburg  Email: michael.achmann@informatik.uni-regensburg.de  Phone: 0941 / 943 5098"
  },
  {
    "objectID": "about.html#copyright-information",
    "href": "about.html#copyright-information",
    "title": "About",
    "section": "Copyright Information",
    "text": "Copyright Information\nCopyright © Michael Achmann 2023. The text-content and supplement materials are licensed unter GNU GPL 3.0.\n\nCitation\nCiting information for the website will follow soon."
  },
  {
    "objectID": "about.html#disclaimer",
    "href": "about.html#disclaimer",
    "title": "About",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe information contained on this website is for general informational purposes only. While we make every effort to keep the information up to date and accurate, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability, or availability concerning the website or the information, products, services, or related graphics contained on the website for any purpose. Any reliance you place on such information is strictly at your own risk."
  },
  {
    "objectID": "about.html#links-to-third-party-websites",
    "href": "about.html#links-to-third-party-websites",
    "title": "About",
    "section": "Links to Third-Party Websites",
    "text": "Links to Third-Party Websites\nThis website may contain links to third-party websites. These links are provided solely for your convenience and do not imply any endorsement, sponsorship, or recommendation by us. We have no control over the content of these websites and assume no responsibility for their accuracy, legality, or content."
  },
  {
    "objectID": "about.html#data-protection",
    "href": "about.html#data-protection",
    "title": "About",
    "section": "Data Protection",
    "text": "Data Protection\nThis Quarto website is hosted on GitHub. While this website does not use any analytics software, GitHub may store cookies on your device. You can change the cookie preferences at any time."
  },
  {
    "objectID": "about.html#trademark-notice",
    "href": "about.html#trademark-notice",
    "title": "About",
    "section": "Trademark Notice",
    "text": "Trademark Notice\nAll trademarks and logos used on this website are the property of their respective owners."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\nIf you have any questions or concerns regarding this impressum or our website, please contact us using the contact information provided above."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Starting in 2022, several student projects and bachelor and master theses have been exploring Social Media Analysis under my supervision. Each project approached the field with a unique research interest and questions, influenced by interdisciplinary questions and perspectives. On this page I keep track of past and current projects."
  },
  {
    "objectID": "projects/index.html#publications",
    "href": "projects/index.html#publications",
    "title": "Projects",
    "section": "Publications",
    "text": "Publications\n\nAchmann, M., & Wolff, C. (2023). Computergestützte Bildtypenanalyse durch Zero-Shot Klassifikation mit CLIP. In INFORMATIK 2023 - Designing Futures: Zukünfte gestalten, 821–830. Gesellschaft für Informatik e.V. https://doi.org/10.18420/inf2023_92\nAchmann, M., & Wolff, C. (2023). Policy issues vs. Documentation: Using BERTopic to gain insight in the political communication in Instagram stories and posts during the 2021 German Federal election campaign. Digital Humanities in the Nordic and Baltic Countries Publications, 5(1), 11–28. https://doi.org/10.5617/dhnbpub.10647\nAchmann, M., Hampel, L., Asabidi, R., & Wolff, C. (2022). Studying the ephemeral, cultures of digital oblivion Identifying patterns in Instagram Stories. In M. Geierhos, P. Trilcke, I. Börner, S. Seifert, A. Busch, & P. Helling (Eds.), DHd 2022 Kulturen des digitalen Gedächtnisses. 8. Tagung des Verbands “Digital Humanities im deutschsprachigen Raum” (DHd 2022). https://doi.org/10.5281/zenodo.6327901\nKnierim, A., Achmann, M., & Wolff, C. (2022). Zeitgeschichte untersuchen - Topic Modeling von #blackouttuesday-Inhalten auf Instagram. In M. Geierhos, P. Trilcke, I. Börner, S. Seifert, A. Busch, & P. Helling (Eds.), DHd 2022 Kulturen des digitalen Gedächtnisses. 8. Tagung des Verbands “Digital Humanities im deutschsprachigen Raum” (DHd 2022). https://doi.org/10.5281/zenodo.6322516"
  },
  {
    "objectID": "projects/index.html#semester-projects",
    "href": "projects/index.html#semester-projects",
    "title": "Projects",
    "section": "Semester Projects",
    "text": "Semester Projects\n\nDigital Humanities – Winter 2022/2023\n\n“Trends in Visual Features of NFT Art from the Most Economically Successful Artists on OpenSea” (Ferah Noor, Mari McCarville)\n“Body Positivity auf Instagram – Eine qualitative Inhaltsanalyse” (Anna Ignjatovic, Adela Myslikova, Ronny Retschmeier)\n“Aktivismus oder Klimaterror? Die Kommentierung der Klimabewegung auf Twitter in der Analyse” (Marie Ederer, Sebastian Daniel)\n“Die Relevanz des Ukraine-Kriegs im nationalen Kontext BILD, SZ und Tagesschau im Vergleich” (Milena Bach, Tobias Ederer, Sebastian Mißler)\n“Die Verwendung naturverbundener Farben anhand ausgewählter Food-Influencerinnen” (Anna Zagel, Mona Meier-to-Krax, Chiara Rahe)\n“Instagram Beiträge zum Thema Ukraine von Nachrichtenkanälen aus verschiedenen Ländern (vor und während des Krieges im Vergleich)” (Philipp Pielmeier, Katharina Kampa, Johanna Grünler)\n“Die Vermarktung von ESN-Fitnessprodukten in den Stories auf der Plattform Instagram” (Kessler Julia, Nett Ellena, Ousseni Océane, Traßl-Wilterius Annika, Umbreit Janosch)\n“Politisches Posten im Rahmen des Krieges in der Ukraine” (Jakob Berg)\n\n\n\nComputational Analysis of Visual Social Media – Winter 2023/2024\nWork in Progress: We will form groups with a final set of topics on October, 30th. We organize our groups and topics on mural."
  },
  {
    "objectID": "projects/index.html#theses",
    "href": "projects/index.html#theses",
    "title": "Projects",
    "section": "Theses",
    "text": "Theses\n\nBachelor\n\n\n\n\n\n\n\n\n\nTitle\nAuthor\nStatus\nYear\n\n\n\n\nSocial Media Analyse von Instagram Stories am Beispiel politischer Akteure während der Bundestagswahl 2021\nLisa Hampel\nCompleted\n2021\n\n\nSammlung und Auswertung eines Social-Media-Korpus durch Entwicklung eines Browser-Plugins zur Annotation von Instagram Stories\nRuslan Asabidi\nCompleted\n2021\n\n\nClassification of Multimodal Social Media Crisis Data – Evaluation and Comparison of two Multimodal Machine Learning Models\nMarkus Weinberger\nCompleted\n2023\n\n\nReaktionen politischer Akteure auf den russischen Angriffskrieg in Instagram Stories & Videos\nFranka Heinlein\nCompleted\n2023\n\n\nPolitical stories – improving face recognition performance for political Instagram story analysis\nPhilip Pirkl\nCompleted\n2023\n\n\nData Donations and Ephemeral Content: Obtaining Instagram-Stories\nTobias Lanzl\nWork in Progress\n2023\n\n\nXu Hướng: An Analysis of Trending TikTok Videos in Vietnam\nThuy-Linh Nguyen\nWork in Progress\n2023\n\n\nEntwicklung eines interaktiven Dashboards zur Echtzeitauswertung der politischen Kommunikation auf Instagram im Landtagswahlkampf 2023\nJonas Ernst\nWork in Progress\n2023\n\n\n\n\n\nMaster\n\n\n\nTitle\nAuthor\nStatus\nYear\n\n\n\n\nUntersuchung der Telegram-Kanäle der “Querdenker”-Bewegung\nTheresa Strohmeier\nCompleted\n2022\n\n\nInvestigating African American Writing and Thought by comparison of two corpora via Distant Reading\nAenne Knierim\nCompleted\n2022\n\n\nSelbstoptimierung vs. Selbstliebe? Eine vergleichende Inhaltsanalyse von Fitspiration- und Bodypositivity-Bildern auf Instagram mit Methoden der automatischen Bildklassifikation\nJulia Glas\nCompleted\n2022\n\n\nAnalyse visueller und textueller Kommunikationsaspekte von deutschen Lifestyle-Influencern auf Instagram und deren Einfluss auf das User Engagement\nNina Dillinger\nCompleted\n2023"
  },
  {
    "objectID": "processing/classification.html",
    "href": "processing/classification.html",
    "title": "Text Classification",
    "section": "",
    "text": "The text as data taught us that text is unstructured data, which needs some processing to convert its content into measurable structured data useful for quantitative analyses. This process is for many analyses the operationalization step, where we translate theoretical concepts into measurable quantities (Nguyen et al. 2020). Content analysis, a research method used in social science and other disciplines, provides a well-established framework for all necessary steps towards operationalization, classification (labelling or coding), and evaluation. Content analysis can be conducted qualitatively and quantitatively. Döring and Bortz (2016) define the two as:\nLast session’s text exploration approaches might be useful in context of qualitative document analyses. For the quantitative approach, however, we need to operationalize our concept of interest (from the theory, or we use operationalization from the literature), and classify our text according to the operationalization. Additionally, we want to evaluate the computational classification, which will be next session’s topic. For today’s session, we work with two operationalizations, or measurements, from the literature: 1) Mobilization (Wurst, Pohl, and Haßler 2023; Haßler, Kümpel, and Keller 2021), and 2) Sentiment (Møller et al. 2023; Schmidt et al. 2022)."
  },
  {
    "objectID": "processing/classification.html#classification-using-gpt",
    "href": "processing/classification.html#classification-using-gpt",
    "title": "Text Classification",
    "section": "Classification using GPT",
    "text": "Classification using GPT\nWe are going to practice text classification using GPT based on operationalization from the literature. As outlined above, we are going to measure sentiment and mobilization. Each variable has different values and applications:\nSentiment analysis, also known as Opinion Mining, is a field within natural language processing (NLP) and linguistics that focuses on identifying and analyzing people’s opinions, sentiments, evaluations, appraisals, attitudes, and emotions expressed towards various entities like products, services, organizations, individuals, events, and topics (B. Liu 2022). Generally, we can conduct polarity-based and emotion-based sentiment analyses. In today’s session we are interested in polarity: Schmidt et al. (2022) distinguish between Positive, Negative, Neutral, and Mixed tweets, Møller et al. (2023) use the categories Positive, Negative, and Neutral.\nMobilization, on the other hand, refers to the efforts made by political parties to encourage and activate citizens to participate in the political process. This can include activities such as voting, supporting a campaign, seeking political information, liking and sharing posts on social media, and other forms of civic engagement (Wurst, Pohl, and Haßler 2023). The authors distinguish between three types of calls to participate: calls to inform, calls to interact, and calls to support. They also subcategorized offline and online forms of each type of call.\n\nPrompt Engineering\nPrompt engineering is a new technique in machine learning that has grown alongside the development of large pre-trained models, such as foundation models or large language models (LLMs). This method emerged when it was realized that these models work better with well-designed inputs. Prompt engineering is about creating or changing a question or input so the model can more easily find the right information (Gu et al. 2023). It is based on the understanding that different questions can produce more or less accurate results, so adjusting the format and examples of the prompt is key to getting the best results (Zhao et al. 2021). The field of prompt engineering involves different ways of making these prompts. One can decide to create prompts manually or use automated methods (P. Liu et al. 2023). The growth and use of prompt engineering signify a major change in machine learning, deeply linked to the flexibility and wide range of applications of foundation models (Gu et al. 2023)."
  },
  {
    "objectID": "processing/classification.html#zero-shot-classification",
    "href": "processing/classification.html#zero-shot-classification",
    "title": "Text Classification",
    "section": "Zero-Shot Classification",
    "text": "Zero-Shot Classification\nZero-shot prompting is a method where a model receives only a natural language instruction to perform a task, without any prior examples or demonstrations, which mirrors the way humans often approach tasks, using only textual instructions. This approach emphasizes convenience and the potential for robustness, minimizing the risk of learning spurious correlations that may be present in the training data. However, this method presents significant challenges, as it can be hard even for humans to understand the task requirements without examples (Brown et al. 2020).\n\n\nDesigning the Prompt\nThe literature provides several prompts for sentiment analysis using GPT-models. Let’s take this example:\n\nSystem prompt: You are an advanced classifying AI. You are tasked with classifying the sentiment of a text. Sentiment can be either positive , negative or neutral.\nPrompt: Classify the following social media comment into either ‘negative’, ‘neutral’ or ‘positive’. Your answer MUST be either one of [‘negative’, ‘neutral’, ‘positive’]. Your answer must be lowercase.\n– Møller et al. (2023) (via Borra (n.d.)).\n\nTesting new prompts within the ChatGPT interface turned out as a good practice through my experiments: Without an additional cost we receive a first understanding of the efficacy of the prompt. The following screenshot shows the sentiment analysis prompt used with some random Amazon reviews:\n\n\n\nThe Sentiment Prompt used with a Positive Review (GPT-4.0)\n\n\n\n\n\nThe Sentiment Prompt used with a Negative Review (GPT-4.0)\n\n\nUsing the ChatGPT interface, we can also interact with the model asking for updates:\n\n\n\nUpdating the Prompt using ChatGPT.\n\n\n\nSystem Prompt: You are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\nFormatting: After processing the text, the response should be formatted in JSON like this:\n{ \n  \"sentiment\": \"positive\" // or \"negative\" or \"neutral\"`\n}\nPlease classify the following social media comment into either ‘negative’, ‘neutral’, or ‘positive’. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase within a JSON format.\nText: [Insert the text here]\n\nNext, let’s use our improved prompt in the playground to test the differntiation between system prompt and user prompt:\n\n\n\n\n\n\nTip\n\n\n\nSet the temperature variable to 0 for more consistent model output.\n\n\n\n\n\nTesting the Sentiment Analysis in the Playground\n\n\n\n\nImplementing the Prompt using Python\n\n\nLet’s read last week’s Text DataFrame\n\nimport pandas as pd\n\ndf = pd.read_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\n\n\n\n\n0\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\n['1. Political parties:\\n- FREIEWÄHLER\\n- Aiwa...\n\n\n1\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\n['Landtagswahl']\n\n\n2\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\n['1. Wahlkampf und Wahlergebnis:\\n- Wahlkampf\\...\n\n\n3\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\n['Israel', 'Terrorismus', 'Hamas', 'Entwicklun...\n\n\n4\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\n['1. Wahlsieg und Parlamentseinstieg\\n- Wahlsi...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nSetup for GPT\n\n!pip install -q openai backoff gpt-cost-estimator\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 221.4/221.4 kB 3.2 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.0/75.0 kB 7.9 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 12.1 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.9/76.9 kB 7.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 6.2 MB/s eta 0:00:00\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllmx 0.0.15a0 requires cohere, which is not installed.\n\n\nWe’re using the new Colab Feature to store keys safely within the Colab Environment. Click on the key on the left to add your API key and enable it for this notebook. Enter the name of your API-Key in the api_key_name variable.\n\nimport openai\nfrom openai import OpenAI\nfrom google.colab import userdata\nimport backoff\nfrom gpt_cost_estimator import CostEstimator\n\napi_key_name = \"openai-lehrstuhl-api\"\napi_key = userdata.get(api_key_name)\n\n# Initialize OpenAI using the key\nclient = OpenAI(\n    api_key=api_key\n)\n\n@CostEstimator()\ndef query_openai(model, temperature, messages, mock=True, completion_tokens=10):\n    return client.chat.completions.create(\n                      model=model,\n                      temperature=temperature,\n                      messages=messages,\n                      max_tokens=600)\n\n# We define the run_request method to wrap it with the @backoff decorator\n@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APIError))\ndef run_request(system_prompt, user_prompt, model, mock):\n  messages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": user_prompt}\n  ]\n\n  return query_openai(\n          model=model,\n          temperature=0.0,\n          messages=messages,\n          mock=mock\n        )\n\nNext, we create a system prompt describing what we want to classify. For further examples of prompts and advice on prompt engineering see e.g. the prompting guide and further resources linked at the bottom of the page.\nFor the moment we are going to use the prompt from the literature.\nDo not forget the Prompt Archive when experimenting. Share your successfull prompt with us!\n\nsystem_prompt = \"\"\"\nYou are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\n\"\"\"\n\n\nprompt = \"\"\"\nPlease classify the following social media comment into either ‘negative’, ‘neutral’, or ‘positive’. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase.\nText: [TEXT]\n\"\"\"\n\n\n\nRunning the request.\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI! Make sure run_request and system_prompt (see Setup for GPT) are defined before this block by running the two blocks above!\nFill in the MOCK, RESET_COST, COLUMN, SAMPLE_SIZE, and MODEL variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\n\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n#@markdown What's the column name to save the results of the data extraction task to?\nCOLUMN = 'Sentiment' # @param {type: \"string\"}\n#@markdown Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\nSAMPLE_SIZE = 25 # @param {type: \"number\", min: 0}\n\n#@markdown Which model do you want to use?\nMODEL = \"gpt-3.5-turbo-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n\n\n# Initializing the empty column\nif COLUMN not in df.columns:\n  df[COLUMN] = None\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nfiltered_df = df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df[COLUMN])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        p = prompt.replace('[TEXT]', row['Text'])\n        response = run_request(system_prompt, p, MODEL, MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n\n          # Update the 'new_df' DataFrame\n          df.at[index, COLUMN] = r\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\nCost: $0.0002 | Total: $0.0069\n\n\n\n\n\n\ndf[~pd.isna(df['Sentiment'])].head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nSentiment\n\n\n\n\n6\n6\nCyLt56wtNgV\nViele gemischte Gefühle waren das gestern Aben...\nCaption\n['Demokratie']\nnegative\n\n\n27\n27\nCyKwo3Ft6tp\nSwipe dich rückwärts durch die Kampagne ✨\\n\\n🤯...\nCaption\n['Soziale Gerechtigkeit']\npositive\n\n\n29\n29\nCyKwBKcqi31\n#FREIEWÄHLER jetzt zweite Kraft in Bayern! Gro...\nCaption\n['Stärkung der Demokratie', 'Sorgen der Bürger...\npositive\n\n\n66\n66\nCyIjC3QogWT\nIn einer gemeinsamen Erklärung der Parteivorsi...\nCaption\n['Israel']\npositive\n\n\n212\n212\nCyAmHU7qlVc\n#FREIEWÄHLER #Aiwanger\nCaption\nNaN\nneutral\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Save Results\ndf.to_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\nLet’s plot the result for a first big picture\n\n\nimport matplotlib.pyplot as plt\n\n# Count the occurrences of each sentiment\nsentiment_counts = df['Sentiment'].value_counts()\n\n# Create a bar chart\nsentiment_counts.plot(kind='bar')\n\n# Adding labels and title\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Sentiment Counts')\n\n# Show the plot\nplt.show()\n\n\n\n\n\nSource: GPT Text Classification"
  },
  {
    "objectID": "processing/classification.html#zero-shot-multiclass",
    "href": "processing/classification.html#zero-shot-multiclass",
    "title": "Text Classification",
    "section": "Zero-Shot Multiclass",
    "text": "Zero-Shot Multiclass\nSo far we have been using one request for exactly one classification. Additionally, our classification has been a categorical variable (sentiment). Since GPT natively speaks JSON as well as other file formats, we can easily request our responses to be formated in JSON. As such, we can request the model to return not just one classification at a time, but multiple classifications simultaneously. Above I introduced two theoretically motivated operationalizations. The second example, mobilization, can be measured e.g. as direct vs. indirect calls to action, or online or offline calls. We could model this question as two categorical classification tasks (direct/indirect/NA, online/offline/NA). My example below makes use of so-called dummy variables, where the presence or absence of each value is coded using 1 or 0 (True or False), as a boolean variable. The dummy variables simplifies the prompt and allow cases, where multiple types of calls to action are used in one text.\nPrompting for multiclass classification works well when defining the output format to adhere strict formatting rules, for more complex use-cases I recommend the guardrails package. The second step is to intpret the GPT response in the right, in our case, to use the json package. This is an error-prone process (image the model to retun None instead of {})! Make use of python errors and exceptions to guard your loop against runtime errors. The example below expects all values in the COLUMNS variable to be part of the JSON object returned from the model and saves the result in df’s column of the same name. Python’s dynamic typing usually takes care of casting the model result to boolean, further down the stream we might have to cast the columns manually (i.e. after saving and loading the df from csv.)\n\n\nsystem_prompt = \"\"\"\nYou're an expert in detecting calls-to-action (CTAs) from texts.\n**Objective:**\nDetermine the presence or absence of explicit and implicit CTAs within German-language content sourced from Instagram texts such as posts, stories, video transcriptions, and captions related to political campaigns from the given markdown table.\n**Instructions:**\n1. Examine each user input as follows:\n2. Segment the content into individual sentences.\n3. For each sentence, identify:\n   a. Explicit CTA: Direct requests for an audience to act which are directed at the reader, e.g., \"beide Stimmen CDU!\", \"Am 26. September #FREIEWÄHLER in den #Bundestag wählen.\"\n   b. Explicit CTA: A clear direction on where or how to find additional information, e.g. \"Mehr dazu findet ihr im Wahlprogramm auf fdp.de/vielzutun\", \"Besuche unsere Website für weitere Details.\"\n   c. Implicit CTA: Suggestions or encouragements that subtly propose an action directed at the reader without a direct command, e.g., \"findet ihr unter dem Link in unserer Story.\"\n4. Classify whether an online or offline action is referrenced.\n5. CTAs should be actions that the reader or voter can perform directly, like voting for a party, clicking a link, checking more information, etc. General statements, assertions, or suggestions not directed at the reader should not be classified as CTAs.\n5. Return boolean variables for Implicit CTAs (`Implicit`), Explicit CTAs (`Explicit`), `Online`, and `Offline` as a JSON objet.\n**Formatting:**\nOnly return the JSON object, nothing else. Do not repeat the text input.\n\"\"\"\n\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI!\nNote: This code block adds some logic to deal with multiple variables contained in the JSON object: {\"Implicit\": false, \"Explicit\": false, \"Online\": false, \"Offline\": false}. We add the columns Implicit, Explicit, Online, and Offline accordingly. To classify different variables the code need to be modified accordingly. ChatGPT can help with this task!\nFill in the MOCK, RESET_COST, SAMPLE_SIZE, COLUMNS and MODEL variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\nimport json\n\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n#@markdown Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\nSAMPLE_SIZE = 5 # @param {type: \"number\", min: 0}\n\n#@markdown Which model do you want to use?\nMODEL = \"gpt-3.5-turbo-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n\n#@markdown Which variables did you define in your Prompt?\nCOLUMNS = [\"Implicit\", \"Explicit\", \"Online\", \"Offline\"] # @param {type: \"raw\"}\n\n# This method extracts the four variables from the response.\ndef extract_variables(response_str):\n    # Initialize the dictionary\n    extracted = {}\n\n    for column in COLUMNS:\n      extracted[column] = None\n\n    try:\n        # Parse the JSON string\n        data = json.loads(response_str)\n\n        for column in COLUMNS:\n          # Extract variables\n          extracted[column] = data.get(column, None)\n\n        return extracted\n\n    except json.JSONDecodeError:\n        # Handle JSON decoding error (e.g., malformed JSON)\n        print(\"Error: Response is not a valid JSON string.\")\n        return extracted\n    except KeyError:\n        # Handle cases where a key is missing\n        print(\"Error: One or more keys are missing in the JSON object.\")\n        return extracted\n    except Exception as e:\n        # Handle any other exceptions\n        print(f\"An unexpected error occurred: {e}\")\n        return extracted\n\n\n# Initializing the empty column\nif COLUMN not in df.columns:\n  df[COLUMN] = None\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nfiltered_df = df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df[COLUMN])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        p = row['Text']\n        response = run_request(system_prompt, p, MODEL, MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n          extracted = extract_variables(r)\n\n          for column in COLUMNS:\n            df.at[index, column] = extracted[column]\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\nCost: $0.0191 | Total: $0.0838\n\n\n\n\n\n\ndf[~pd.isna(df['Implicit'])]\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nCall\nImplicit\nExplicit\nOnline\nOffline\n\n\n\n\n442\n442\nCxxXJBtAHhv\nFriedrich Merz ist nicht gerade bekannt für se...\nCaption\n['Asylbewerberleistungsgesetz', 'Zahnsanierung...\nNone\nFalse\nFalse\nFalse\nFalse\n\n\n453\n453\nCxvqTwmtlJK\nDamit es uns nicht so ergeht wie den Indianern...\nCaption\nNaN\nNone\nFalse\nTrue\nFalse\nTrue\n\n\n494\n494\nCxs9ujENMqI\n🔹#Krankenhäuser🔹#Geburtsstationen und 🔹#Hebamm...\nCaption\n['Krankenhäuser', 'Geburtsstationen', 'Hebamme...\nNone\nFalse\nTrue\nFalse\nTrue\n\n\n839\n839\nCxWF0mcqrhg\nUnterwegs im oberbayerischen Moosburg: Herzlic...\nCaption\nNaN\nNone\nFalse\nTrue\nFalse\nTrue\n\n\n1818\n1818\nCxvKsBBos0j\n9801 Bayerische Staatsregierung MISSION 7272 9...\nOCR\nNaN\nNone\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nSource: GPT Text Classification"
  },
  {
    "objectID": "processing/classification.html#few-shot-classification",
    "href": "processing/classification.html#few-shot-classification",
    "title": "Text Classification",
    "section": "Few-Shot Classification",
    "text": "Few-Shot Classification\nFew-shot learning, involves presenting a model with a small number of task demonstrations at inference time. The number of examples is constrained by the model’s context window capacity. The primary advantage of few-shot learning is the significant reduction in the need for task-specific data, alongside minimizing the risk of learning a narrow distribution from a large, but limited, fine-tuning dataset. However, this method has shown inferior performance compared to state-of-the-art fine-tuned models and still requires a minimal amount of task-specific data (Brown et al. 2020).\n\n\nsystem_prompt = \"\"\"\nYou are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\n**Examples:**\n\"Wir sind EIN Volk! 🇩🇪 In Leipzig nahm es den Anfang, breitete sich aus wie ein Lauffeuer und ebnete den Weg für die deutsche Einheit. Was damals viel Arbeit war, zahlte sich aus. Was heute noch Arbeit ist, wird sich auszahlen. Ein geeintes Deutschland ist keine Selbstverständlichkeit und wir sind dankbar für die Demokratie, den Rechtsstaat und unsere freiheitliche Gesellschaft. Und wir arbeiten täglich dafür, dass uns diese Werte erhalten bleiben.\": positive\n\"FREIE WÄHLER Wir FREIE WÄHLER kämpfen für eine flächendeckende Gesundheitsversorgung auch auf dem Land. HUBERT AJUANGER\": neutral\n\"Die #Grünen sind mit dafür verantwortlich, dass die #Ampel-Regierung in Berlin meilenweit an der Lebenswirklichkeit der Menschen vorbei regiert. Ausgerechnet unter einem grünen Klimaminister lässt die Akzeptanz für #Klimaschutz in der Gesellschaft nach. Mit uns wird es keine Grünen in der Bayerischen Staatsregierung geben.\": negative\n\"\"\"\n\n\nprompt = \"\"\"\nPlease classify the following social media comment into either ‘negative’, ‘neutral’, or ‘positive’. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase.\nText: [TEXT]\n\"\"\"\n\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI! Make sure run_request and system_prompt are defined before this block by running the two blocks above (see Setup for GPT)!\nFill in the MOCK, RESET_COST, COLUMN, SAMPLE_SIZE, and MODEL variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\n\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n#@markdown What's the column name to save the results of the data extraction task to?\nCOLUMN = 'Sentiment' # @param {type: \"string\"}\n#@markdown Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\nSAMPLE_SIZE = 25 # @param {type: \"number\", min: 0}\n\n#@markdown Which model do you want to use?\nMODEL = \"gpt-3.5-turbo-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n\n\n# Initializing the empty column\nif COLUMN not in df.columns:\n  df[COLUMN] = None\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nfiltered_df = df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df[COLUMN])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        p = prompt.replace('[TEXT]', row['Text'])\n        response = run_request(system_prompt, p, MODEL, MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n\n          # Update the 'new_df' DataFrame\n          df.at[index, COLUMN] = r\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\nCost: $0.0010 | Total: $0.0278\n\n\n\n\n\n\ndf[~pd.isna(df['Sentiment'])].sample(5)\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nSentiment\n\n\n\n\n1833\n1833\nCxunhdYNvw3\ntanten\nOCR\nNaN\nneutral\n\n\n2299\n2299\nCxJAr3Ht7mh\nEIN JAHR FEMINISTISCHE REVOLUTION IM IRAN LASS...\nOCR\nNaN\nneutral\n\n\n369\n369\nCx2gzYdIv5d\nWir gratulieren Sven Schulze, der gestern in M...\nCaption\nNaN\npositive\n\n\n1886\n1886\nCxqbrYztMdC\nBerliner Senat; nachdem er rausgefunden hat, d...\nOCR\nNaN\nnegative\n\n\n290\n290\nCx7ruIdiOXb\n#TagderdeutschenEinheit \\n\\nUnser #Bayern hat ...\nCaption\n['LosvonBerlin', 'Bayernpartei']\nnegative\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Save Results\ndf.to_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\n\nimport matplotlib.pyplot as plt\n\n# Count the occurrences of each sentiment\nsentiment_counts = df['Sentiment'].value_counts()\n\n# Create a bar chart\nsentiment_counts.plot(kind='bar')\n\n# Adding labels and title\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Sentiment Counts')\n\n# Show the plot\nplt.show()\n\n\n\n\nSource: GPT Text Classification"
  },
  {
    "objectID": "processing/classification.html#saving-money-multidocument-classification",
    "href": "processing/classification.html#saving-money-multidocument-classification",
    "title": "Text Classification",
    "section": "Saving Money – Multidocument Classification",
    "text": "Saving Money – Multidocument Classification\nWhen using GPT for text classification using the above prompts, we send one request per text document in our df. Each time, we send the system_prompt and prompt, repeating the same text over and over again. With the code below we try another approach: We send a table with multiple documents at once, thus we just need to send the system_prompt and prompt once every n documents, saving tokens and therefore saving money. Classifications using gpt-3.5 are relatively cheap, and the multidocument classification resulted in small quality drops through my experiments, for gpt-4, however, it cut my expenses drastically. gpt-4-turbo lies inbetween the two, it is still 10 times more expansive than gpt-3.5, yet input tokens are 1/3 of gpt-4 prices. See: https://openai.com/pricing\nVerdict: Always run the mock requests first to estimate cost. For gpt-3.5 sending one document per request is often the best option. For gpt-4 the multidocument approach is often the better option: Cheaper than single-document gpt-4, higher quality than gpt-3.5. (According to my experiments, which have limitations!).\n\nNew System Prompt\nLet’s get started by creating a new system prompt that incoporates command for the new approach. We need to define the prompt, as we need to calculate the tokens before splitting the textdocuments in tables.\n\n\nsystem_prompt = \"\"\"\nYou are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\n**Instructions**\n  1. Examine each row in the table under the 'Text' column.\n  2. For each row consisting of social media comments, classify the content into either ‘negative’, ‘neutral’, or ‘positive’.\n  3. Fill the 'Classification' column for the corresponding 'Text' row with your answer. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase.\n**Formatting**\nReturn a markdown table with the columns \"shortcode\" and \"Classification\"\n\"\"\"\n\n\nFrom Documents to Markdown Tables\nWe use the tabulate python package to create markdown tables for as many tables as we manage to send within the model’s context window. Currently, the result_table token length (the mockup response) is calculated using the length of False. Replace the value if you expect longer classifications in this line:\ncurrent_result_table = tabulate(batched_data + [(row[meta], False)], headers=[meta, \"Classification\"], tablefmt=\"pipe\")\n\nfrom tabulate import tabulate\nfrom datetime import datetime\nfrom gpt_cost_estimator import num_tokens_from_messages\n\ndef batch_rows_for_tables(df, system_prompt, column, meta, model=\"gpt-3.5-turbo-0613\", **kwargs):\n    max_rows = kwargs.get(\"max_rows\", 999)\n    if model == \"gpt-4-0613\":\n      max_tokens = 8192\n\n    if model == \"gpt-4-1106-preview\":\n      max_tokens = 128000 # This model has not been tested with the multidocument approach. It is only capable of 4096 tokens output, therefore we might run into trouble\n\n    if model == \"gpt-3.5-turbo-0613\":\n      max_tokens = 4096\n\n    \"\"\"Batch rows from the dataframe to fit within token limits and return as a list of markdown tables.\"\"\"\n    tables = []\n\n    df[column] = df[column].astype(str)\n\n    pbar = tqdm(total=len(df))\n\n\n    while not df.empty:\n        current_tokens = 0\n        batched_data = []\n        batched_results = []\n\n        i = 0\n        for index, row in df.iterrows():\n            # Remove newline characters from the specific column\n            cleaned_data = row[column].replace('\\n', ' ')\n\n            # Construct the table for the current batch\n            current_table = tabulate(batched_data + [(row[meta], cleaned_data)], headers=[meta, \"Text\"], tablefmt=\"pipe\")\n            current_result_table = tabulate(batched_data + [(row[meta], False)], headers=[meta, \"Classification\"], tablefmt=\"pipe\")\n\n            message = [\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": current_table},\n                {\"role\": \"assistant\", \"content\": current_result_table}\n                ]\n\n            tokens_needed = num_tokens_from_messages(message, model=model)\n\n            if tokens_needed &lt;= max_tokens and i &lt; max_rows:\n                current_tokens = tokens_needed\n                batched_data.append((row[meta], cleaned_data))\n                batched_results.append((row[meta], False))\n                df.drop(index, inplace=True)\n                i += 1\n            else:\n                # Stop when you've reached close to the max token count\n                pbar.update(len(batched_data))\n                break\n\n        # Convert batched rows to a markdown table and store in tables list\n        markdown_table = tabulate(batched_data, headers=[meta, \"Text\"], tablefmt=\"pipe\")\n        tables.append(markdown_table)\n\n    pbar.close()\n\n    return tables\n\nThe next command uses the above function to generate all necessary markdown tables. The column parameter of batch_rows_for_tables expects the name of the text column, the meta parameter expects the name of the identifier column. Additionally, we pass the dataframe, system_prompt, and MODEL to the function. Fill in the TEXT_COLUMN, IDENTIFIER, MODEL, and MAX_ROWS variables as needed. See the comments above each variable for more information.\n\n#@markdown What's the column name of the text column?\nTEXT_COLUMN = 'Text' # @param {type: \"string\"}\n#@markdown What's the column name of the text column?\nIDENTIFIER = 'shortcode' # @param {type: \"string\"}\n#@markdown Which model do you want to use?\nMODEL = \"gpt-4-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n#@markdown Is there a maximum length of rows? (**Set a very high number, like 999, to disable this feature**)\nMAX_ROWS = 999 # @param {type: \"number\", min:0}\n\n# Create a copy of your df. This is important! The batching process removes processed rows from the df.\ndf_batch_copy = df.copy()\n\n# Batching the tables, takes a few seconds (~1 Minute)\ntables = batch_rows_for_tables(df_batch_copy, system_prompt, TEXT_COLUMN, IDENTIFIER, MODEL, max_rows=MAX_ROWS)\n\n\n\n\nLet’s inspect the table. This is one of many tables that will be sent to the model. (I set the MAX_ROWS to 5 to keep the example short. When working with this approach I usually use MAX_ROWS=999.)\n\nprint(tables[0])\n\n| shortcode   | Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|:------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| CyMAe_tufcR | #Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Danke #Landtagswahl                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| CyL975vouHU | Die Landtagswahl war für uns als Liberale hart. Wir haben alles gegeben, um die FDP wieder in den Landtag zu bringen, aber leider hat es nicht gereicht. Danke für euren Einsatz, egal ob beim Plakatieren, Flyern oder am Infostand. 💛  Wir Julis stehen für unsere Überzeugungen ein, auch wenn es gerade nicht gut läuft. Das macht uns aus! Das haben wir in diesem Wahlkampf gezeigt und das werden wir auch in der außerparlamentarischen Opposition zeigen. 💪  Du bist auch davon überzeugt, dass Freiheit und Eigenverantwortung eine Stimme in der Politik brauchen? Dann steh auch du jetzt für diese Überzeugung ein. Unter www.julis.de/mitglied-werden/ kannst du noch heute Mitglied der besten Jugendorganisation der Welt werden. 🚀  #freistart23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n| CyL8GWWJmci | Nach einem starken Wahlkampf ein verdientes Ergebnis! 💪 Herzlichen Glückwunsch an die CSU und unsere bayrischen JUler, die in der nächsten Legislaturperiode für ein sicheres und stabiles Bayern arbeiten werden. Wir wünschen euch viel Erfolg und alles Gute für das Landtagsmandat (v.l.n.r.): Manuel Knoll, Konrad Baur, Daniel Artmann, Kristan von Waldenfels.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| CyL7wyJtTV5 | So viele Menschen am Odeonsplatz heute mit einer klaren Botschaft: Wir stehen an der Seite Israels.   Die massiven und brutalen Angriffe der Terrororganisation Hamas sind abscheuliche Verbrechen an unschuldigen Männern, Frauen und Kindern. Die Bilder und Videos der barbarischen Morde zerreißen einem das Herz.   Der Terror der Hamas ist durch nichts zu rechtfertigen und muss sofort gestoppt werden. Israel hat ein völkerrechtlich verbrieftes Recht auf Selbstverteidigung.  Wir Gedenken den Toten. Wir trauern mit den Familien und Angehörigen. Und wir bangen und hoffen mit den verschleppten Israelis.   Es ist gut, dass die Bundesregierung die Entwicklungshilfe für die palestinensischen Gebiete eingefroren hat. Das ist richtig.   Nicht richtig ist, dass Menschen in Deutschland die Angriffe der Hamas auf Jüdinnen und Juden feiern. Das ist mit nichts zu rechtfertigen und wir verurteilen es aufs schärfste.   Wir hier in Deutschland und Bayern haben noch viel zu tun: Antisemitismus und auch israelbezogener Antisemitismus ist in der Mitte unserer Gesellschaft vorhanden. Es ist die Aufgabe des frisch gewählten Bayerischen Landtags noch mehr gegen Judenhass zu tun.   📸 @andreasgregor   #standwithisrael #israel #münchen #bayern |\n| CyLxwHuvR4Y | Herzlichen Glückwunsch zu diesem grandiosen Wahlsieg!  Mit allen 12 JU-Direktkandidaten seid ihr in den hessischen Landtag gezogen 🎉 Wir gratulieren euch und wünschen euch viel Erfolg für den Start und die nächsten fünf Jahre im Parlament (v.l.n.r.): Kim-Sarah Speer, Frederik Bouffier, Sebastian Sommer, Lucas Schmitz, Sebastian Müller, Christin Ziegler, Marie-Sophie Künkel, Maximilian Schimmel, Christoph Mikuschek, Patrick Appel, Maximilian Bathon und Dominik Leyh!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n\n\nWe can also inspect them using Markdown formatting in the notebooks:\n\nfrom IPython.display import Markdown, display\n\ndisplay(Markdown(tables[0]))\n\n\n\n\n\n\n\n\nshortcode\nText\n\n\n\n\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Danke #Landtagswahl\n\n\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart. Wir haben alles gegeben, um die FDP wieder in den Landtag zu bringen, aber leider hat es nicht gereicht. Danke für euren Einsatz, egal ob beim Plakatieren, Flyern oder am Infostand. 💛 Wir Julis stehen für unsere Überzeugungen ein, auch wenn es gerade nicht gut läuft. Das macht uns aus! Das haben wir in diesem Wahlkampf gezeigt und das werden wir auch in der außerparlamentarischen Opposition zeigen. 💪 Du bist auch davon überzeugt, dass Freiheit und Eigenverantwortung eine Stimme in der Politik brauchen? Dann steh auch du jetzt für diese Überzeugung ein. Unter www.julis.de/mitglied-werden/ kannst du noch heute Mitglied der besten Jugendorganisation der Welt werden. 🚀 #freistart23\n\n\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Ergebnis! 💪 Herzlichen Glückwunsch an die CSU und unsere bayrischen JUler, die in der nächsten Legislaturperiode für ein sicheres und stabiles Bayern arbeiten werden. Wir wünschen euch viel Erfolg und alles Gute für das Landtagsmandat (v.l.n.r.): Manuel Knoll, Konrad Baur, Daniel Artmann, Kristan von Waldenfels.\n\n\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit einer klaren Botschaft: Wir stehen an der Seite Israels. Die massiven und brutalen Angriffe der Terrororganisation Hamas sind abscheuliche Verbrechen an unschuldigen Männern, Frauen und Kindern. Die Bilder und Videos der barbarischen Morde zerreißen einem das Herz. Der Terror der Hamas ist durch nichts zu rechtfertigen und muss sofort gestoppt werden. Israel hat ein völkerrechtlich verbrieftes Recht auf Selbstverteidigung. Wir Gedenken den Toten. Wir trauern mit den Familien und Angehörigen. Und wir bangen und hoffen mit den verschleppten Israelis. Es ist gut, dass die Bundesregierung die Entwicklungshilfe für die palestinensischen Gebiete eingefroren hat. Das ist richtig. Nicht richtig ist, dass Menschen in Deutschland die Angriffe der Hamas auf Jüdinnen und Juden feiern. Das ist mit nichts zu rechtfertigen und wir verurteilen es aufs schärfste. Wir hier in Deutschland und Bayern haben noch viel zu tun: Antisemitismus und auch israelbezogener Antisemitismus ist in der Mitte unserer Gesellschaft vorhanden. Es ist die Aufgabe des frisch gewählten Bayerischen Landtags noch mehr gegen Judenhass zu tun. 📸 (andreasgregor?) #standwithisrael #israel #münchen #bayern\n\n\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wahlsieg! Mit allen 12 JU-Direktkandidaten seid ihr in den hessischen Landtag gezogen 🎉 Wir gratulieren euch und wünschen euch viel Erfolg für den Start und die nächsten fünf Jahre im Parlament (v.l.n.r.): Kim-Sarah Speer, Frederik Bouffier, Sebastian Sommer, Lucas Schmitz, Sebastian Müller, Christin Ziegler, Marie-Sophie Künkel, Maximilian Schimmel, Christoph Mikuschek, Patrick Appel, Maximilian Bathon und Dominik Leyh!\n\n\n\n\n\n\n\nRun the Multidocument Request\nhe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI!\nFill in the MOCK, RESET_COST, SAMPLE_SIZE, CLASS_NAME, and FILE_NAME variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\nimport json\nimport ast\nfrom datetime import datetime\nfrom io import StringIO\n\n#@title Run the Multidocument Request\n#@markdown T\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n\n#@markdown How many **tables** do you want to send? Enter $0$ for all.\nSAMPLE_SIZE = 1 # @param {type: \"number\", min: 0}\n\n#@markdown Filename for the **new** table that only contains sentiments.\nFILE_NAME = '/content/drive/MyDrive/2023-12-08-Posts-LTW-Sentiment' # @param {type: \"string\"}\n\n#@markdown Name for the classification column\nCLASS_NAME = 'Sentiment' # @param {type: \"string\"}\n\n\ndef safe_literal_eval(value):\n    if isinstance(value, (str, bytes)):\n        try:\n            return ast.literal_eval(value)\n        except ValueError:\n            return value  # or handle the error in another way if you want\n    return value\n\ndef parse_response(response):\n    # Determine if the response is a list or markdown table\n    if ':' in response.split('\\n')[0]:\n        # List\n        lines = [line.strip() for line in response.strip().split('\\n')]\n        data = [(int(line.split(': ')[0]), line.split(': ')[1]) for line in lines]\n        # Convert the parsed data into a DataFrame\n        result_df = pd.DataFrame(data, columns=['uuid', 'Positioning'])\n    else:\n        # Markdown Table\n        csv_data = '\\n'.join([','.join(line.split('|')[1:-1]) for line in response.split('\\n') if line.strip() and not line.startswith('|:')])\n        result_df = pd.read_csv(StringIO(csv_data.strip()), sep=\",\", skipinitialspace=True)\n\n\n    # Striping Whitespaces\n    result_df.columns = [col.strip() for col in result_df.columns]\n    if 'Classification' in result_df.columns:\n        # Renaming the column to fit the rest of the project.\n        result_df = result_df.rename(columns={\"Classification\": CLASS_NAME})\n\n    result_df = result_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\n    return result_df\n\n\ntry:\n    # Attempt to read the CSV file into a DataFrame\n    new_df = pd.read_csv(FILE_NAME)\nexcept FileNotFoundError:\n    # If the file is not found, create an empty DataFrame with the specified columns\n    new_df = pd.DataFrame(columns=[IDENTIFIER, CLASS_NAME])\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nif 0 &lt; SAMPLE_SIZE &lt;= len(tables):\n    filtered_tables = tables[:SAMPLE_SIZE]\nelse:\n    filtered_tables = tables\n\nfor table in tqdm(filtered_tables):\n    result = run_request(system_prompt, table, MODEL, MOCK)\n    if result and not MOCK:\n      # Parsing the data\n      result_df = parse_response(result.choices[0].message.content)\n\n      # Append it to master_df\n      new_df = pd.concat([new_df, result_df], ignore_index=True)\n\n      # Save Progress\n      new_df.to_csv(FILE_NAME, index=False)\n\nprint()\n\nif not MOCK:\n  print(f\"Saved {FILE_NAME}.\")\n\n  new_df = new_df.dropna(subset=[IDENTIFIER])\n  new_df[CLASS_NAME] = new_df[CLASS_NAME].apply(safe_literal_eval)\n  uuid_to_classification = new_df.set_index(IDENTIFIER)[CLASS_NAME].to_dict()\n  mask = df[IDENTIFIER].isin(uuid_to_classification.keys())\n  df.loc[mask, CLASS_NAME] = df.loc[mask, IDENTIFIER].replace(uuid_to_classification)\n\nprint()\n\nReset Cost Estimation\nCost: $0.1408 | Total: $0.1408\nSaved /content/drive/MyDrive/2023-12-08-Posts-LTW-Sentiment.\n\n\n\n\n\n\n\nnew_df.head()\n\n\n  \n    \n\n\n\n\n\n\nshortcode\nSentiment\n\n\n\n\n0\nCyMAe_tufcR\npositive\n\n\n1\nCyL975vouHU\nneutral\n\n\n2\nCyL8GWWJmci\npositive\n\n\n3\nCyL7wyJtTV5\nnegative\n\n\n4\nCyLxwHuvR4Y\npositive\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nThe code above expects the GPT-API to return results in a markdown formatted table (see above). We keep appending the API responses to a new_df where we temporarily store the classifications. For each loop (i.e. each time received a classification), we store the results on Google Drive as a backup, since each result has a price tag. In case of error we can resume the operation later without the need to start all over again. The code above does not provide the necessary logic for that, but you should be able to quickly add it.\nOnce the loop finished, we use the shortcode column from the API response and join the classification data with df:\n\nAnd finally our df looks as follows. As outlined at the start of the text exploration chapter, we want to fill one dataframe piece by piece with more and more classifications.\n\ndf[mask][['shortcode', 'Text', 'Text Type', 'Sentiment']].head()\n\n\n  \n    \n\n\n\n\n\n\nshortcode\nText\nText Type\nSentiment\n\n\n\n\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\npositive\n\n\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\nneutral\n\n\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\npositive\n\n\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\nnegative\n\n\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\npositive\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nSource: GPT Text Classification"
  },
  {
    "objectID": "processing/classification.html#conclusion",
    "href": "processing/classification.html#conclusion",
    "title": "Text Classification",
    "section": "Conclusion",
    "text": "Conclusion\nWe have scratched the surface of (textual) content analysis as a foundation for our text classification tasks. Starting our journey with the idea of text as data and following the exploration of textual content, we just added a new instrument to our toolbox for computational social media analysis: text classification. We focused solely on prompting and GPT for the classification tasks. There exist several other approaches (e.g. using BERT and other trasnformer models), and several providers offer cloud services and APIs for classification tasks (e.g. in the Google Cloud). For sentiment analysis there are dedicated models (see Schmidt et al. (2022) for the application of such a model), and even more services and APIs (e.g. on Microsoft Azure).\nAt the same time, the first papers show interesting results when using GPT for text classification (e.g. Brown et al. 2020), with prompt design being accessible for researcher with zero to few experience with machine learning. There is currently a lot of opportunity to experiment with prompts, and to test and evaluate Large Language Models and prompts against fine-tuned and existing models. We are currently missing one last step to setup a complete experiment: The evaluation, which is the next topic of our seminar. While there exists literature about prompting and prompt engineering (see top and further reading), some of the literature has a more technical motivation and is short of practical advice. Through this session I have presented the practical knowledge that I gathered through my last research project (currently under review), which still is experimental. I presented the Zero-Shot and Few-Shot approach, as well as a Zero-Shot Multiclass approach and a Multidocument approach to save money / requests while working with expensive models."
  },
  {
    "objectID": "processing/classification.html#further-reading",
    "href": "processing/classification.html#further-reading",
    "title": "Text Classification",
    "section": "Further Reading",
    "text": "Further Reading\n\nWhite et al. (2023): A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT\nZamfirescu-Pereira et al. (2023): Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts\nCollection of Projects and (Preprint) Papers on Prompt Engineering\nGPT3 Subreddit"
  },
  {
    "objectID": "image-analysis/gephi.html",
    "href": "image-analysis/gephi.html",
    "title": "Image Exploration with Gephi",
    "section": "",
    "text": "This page lists the remaining step for creating an image network based on labels from commercial computer vision APIs. The process is rather complex, the steps below omit some intermediary steps, e.g. for filtering and adjusting the text labels for nodes and edges.\n\n\n\n\n\n\nImportant\n\n\n\nThese steps are based on Omena et al. (2021)’s approach. The first steps are located in the exploration chapter.\n\n\n\n\n\nWe cannot see any changes in the graph yet. We need to change the appearance. Select Nodes &gt; Partition, and select “Modularity Class”. Hit Apply and your black network should turn into several colours.\n\n\n\n\n\nAn example for a network coloured by modularity class.\n\n\n\n\n\nNext, move to the Data Lab tab. On the bottom of the window, use the Duplicate Column button, to copy the values from Label to a new column named image. The name image is important!\n\n\n\n\n\nMake sure to have the Image Preview Plugin installed. The plugin is not compatible with the latest Gephi version!\n\n\n\n\n\nFinally, move to the tab Preview. Scroll in the left pane to the bottom and cofigure your image folder. Hit Refresh to render the network including the images. In my experience it is best to export the final network to PDF and use a PDF reader for the actual exploration of the images.\n\n\n\n\n\n\nThis is an example of such a network. I added some additional configuration here to display the labels. Gephi has many advanced features, I recommend a web- and YouTube search for more ideas how to explore your graph and how to render the data nicely.\n\n\n\n\n\n\nAt the end of the process we can take a look at the modularity classes (clusters). Zooming into each of the clusters we can name them based on their content. In my example the images in the displayed cluster all show streets or city-views, thus glimpses of the farmers’ demonstrations with from a wide-angle perspective.\n\n\n\n\n\n\nReferences\n\nOmena, Janna Joceli, Pilipets Elena, Beatrice Gobbo, and Chao Jason. 2021. “The Potentials of Google Vision API-based Networks to Study Natively Digital Images.” Diseña, no. 19 (September): 1–1. https://doi.org/10.7764/disena.19.Article.1.\n\nReusehttps://creativecommons.org/licenses/by/4.0/"
  },
  {
    "objectID": "image-analysis/exploration.html",
    "href": "image-analysis/exploration.html",
    "title": "Visual Exploration",
    "section": "",
    "text": "The previous chapter outlines some literature on images as data, emphasizing them importance of evaluation and contextualisation of computer vision applications due to biases inherent to our looking at images. This chapter introduces several tools and approaches for exploring visual material. These unsupervised approaches are useful for exploring image datasets. The first approaches, PixPlot and PicArrange are ready-made tools, they are easy to use and display results quickly. On the downside they offer limited options to manipulate the clustering of images (i.e. what features we are interested in). Therefore we take a look at commercial computer vision APIs as middle ground between setting up your own notebook for using object detection models, and the fully automated approaches above. We approach the labels using two clustering approaches in this chapter: Using network analysis and the modularity algorithm in Gephi finding communities, or using k-means to find k-clusters in our own notebook. The network analysis is based on Omena et al. (2021)’s manuals and publications. This approach is complex to reproduce for the sheer interest in image exploration (in contrast to Omena et al.’s interests in studying the web entity networks and their evolutions). The k-means approach offers an easier solution for clustering images based on labels provided by a vision API, while being compatible with Memespector, a GUI tool for multiple vision APIs. Finally we will explore BERTopic’s multimodal functionality: Using the vit-gpt2-image-captioning model, we generate captions for each image and use them for topic modeling. This captioning approach is one option, we will explore more options in union with image classification in the next session."
  },
  {
    "objectID": "image-analysis/exploration.html#pixplot",
    "href": "image-analysis/exploration.html#pixplot",
    "title": "Visual Exploration",
    "section": "PixPlot",
    "text": "PixPlot\nPixPlot is a visualization tool designed for clustering large numbers of images into a coherent projection. The tool uses Tensorflow’s Inception model to analyze image content and employs a custom WebGL viewer for visualization. This approach allows for the grouping of similar images, aiding in the identification of patterns and relationships within large image datasets.\n\n\n\nOnce installed, PixPlot can be invoked using the command line. We can also pass metadata, like timestamps, see the documentation.\n\n\nPixPlot requires a Python 3.7 environment, which can be set up using Anaconda. After setting up the environment, PixPlot can be installed via pip. For visualizing the results, a WebGL-enabled browser is necessary. The process involves running a simple command to process a directory of images, and then starting a web server to view the visualization. Take a look at the GitHub repository for instructions. The software is known for causing problems with newer MacBooks (based on the new M-Chips).\n\n\n\nThe result can be viewed in a webbrowser: A 2D mapping of images clustered by their content.\n\n\nPixPlot has similarities with the k-means approach introduced in the next section. Both methods aim to categorize and cluster images based on their content. However, PixPlot automates this process by using an Inception model for image analysis and UMAP for dimensionality reduction, leading to the formation of clusters. For the approach below we first use the Google Vision API to retrieve a set of labels describing each images, and cluster afterwards. The manual approach is more difficult to start with, but possibly pays off as we progress towards image classification and the potential reuse of the labels retrieved from the API."
  },
  {
    "objectID": "image-analysis/exploration.html#picarrange",
    "href": "image-analysis/exploration.html#picarrange",
    "title": "Visual Exploration",
    "section": "PicArrange",
    "text": "PicArrange\n\n\n\nA screenshot of PicArrange displaying an overview of my Instagram Story corpus. Note how the visual sorting arranged images with large embedded text close to one another, followed by text-centric screenshots of Twitter.\n\n\n\nPicArrange helps to find images on your Mac computer much easier than ever before. Opposed to the Finder app, PicArrange can sort images not only by name or date, but also by content and color. This visual sorting mode allows to inspect and search large amounts of images much faster. You can also view visually sorted images from several directories at the same time, making it easy to find duplicate images.\nBesides the visual sorting PicArrange offers a similarity search, thus allowing to find images similar to one or more example images. Image files can be deleted, copied or opened with Preview directly with PicArrange\n\nAvailable at visual-computing.com, for macOS only."
  },
  {
    "objectID": "image-analysis/exploration.html#commercial-computer-vision-apis",
    "href": "image-analysis/exploration.html#commercial-computer-vision-apis",
    "title": "Visual Exploration",
    "section": "Commercial Computer Vision APIs",
    "text": "Commercial Computer Vision APIs\nCommercial services such as the Google Vision API and Microsoft Azure Vision provide an excellent starting point for exploring large visual datasets. This recipe is based on Omena’s work with labels and web entities from the Google Vision API (Omena et al. 2021). Utilizing tools like Memespector (Chao 2023), Table2Net, and Gephi, we can analyze image graphs without any programming knowledge. Subsequently, we apply the same labels in a matrix-based approach, clustering images using the k-means algorithm.\n\n\n\n\n\n\nWarning: Black Boxes\n\n\n\nWhen using commercial services like Google Vision API or Microsoft Azure Vision, it’s crucial to be aware of the “black box” nature of these tools. These services utilize proprietary algorithms whose internal workings and decision-making processes are not transparent to the users. This lack of transparency can lead to uncertainties about how and why certain results are generated, potentially affecting the reliability and interpretability of your analysis.\nDespite their ease of use, remember that these tools might not fully align with every research need, especially when interpretability and transparency are critical. As an alternative, open-source models are available, which, while more complex to set up and use, offer greater transparency and flexibility. These models allow for a deeper understanding and customization of the analysis process, aligning more closely with research principles that prioritize openness and reproducibility.\n\n\nIn the matrix-based approach, each image is treated as a collection of features (labels), with algorithms like k-means clustering images by comparing these features. This method effectively identifies images with similar labels. Conversely, the network-based approach considers images and labels as interconnected nodes. Applying algorithms such as the modularity algorithm in Gephi, we can find communities where images are more closely linked through shared labels. This method provides insights into complex relationships and the overarching context of these images. While the matrix-based technique is straightforward and excels in direct feature comparison, the network-based approach offers deeper analysis of the dataset’s intricate connections. Each method has unique advantages, enhancing your understanding of data analysis in social science.\nBoth methods begin with Memespector (Chao 2023). The software employs commercial APIs like Google Vision AI to classify images with features such as labels or web entities. I recommend selecting Labels and Text initially. The results are stored in two files: a JSON file (which can be quite large) and a CSV file (used in subsequent steps). The CSV format employs a one row per image structure, with multiple labels per image recorded as semicolon-separated values in a single cell. Further details about obtaining a credential file will be provided in class.\n\n\n\nA screenshot of Memespector, a graphical user interface for multiple computer vision APIs.\n\n\n\n\n\nEach computer vision provides offers multiple models. For image explorations I suggest to invoke the labels. Additionally we can invoke the text (OCR) model for the later processing of embedded text.\n\n\nOnce the API calls succeeded, we can go on and create an image-label-network, or cluster the images based on their labels using k-means."
  },
  {
    "objectID": "image-analysis/exploration.html#visual-network-analysis",
    "href": "image-analysis/exploration.html#visual-network-analysis",
    "title": "Visual Exploration",
    "section": "Visual Network Analysis",
    "text": "Visual Network Analysis\n\n\n\n\nAn example of a label-image-network. This example show images from TikTok collected during the farmers’ demonstrations, the node colour signifies the modularity classes, communities within the network. Note: The resolution of the image is low on purpose, as the original image contains images of individuals.\n\n\n\nFollow the next steps in order to create your own label-image-network. Gephi is a powerful and complex tool, I omitted a few steps for clarity. Take a look at YouTube tutorials and web tutorials, for more information.\n\n\n\nFirst select the bipartite network.\n\n\n\n\n\nNext, select Image_BaseName as the X Node. Additionally, let’s add Image_BaseName again as an attribute, we will use this attribute to display images in Gephi.\n\n\n\n\n\nAdd the GV_Label_Descriptions column as the second (Y) nodes. Select Semicolon Seperated to split the values in the cell into seperate labels.\n\n\n\n\n\nFinally hit Build.\n\n\nAt this stage, after a few seconds of processing, the website should triger the download of a gefxfile. Use Gephi to open this file. Follow these steps:\n\n\n\nOpen / Import the project. Click OK.\n\n\n\n\n\nAfter the import Gephi should look like this. The graph structure is random, no clusters are visible. If you cannot see any network, check whether you’re in the Overview tab.\n\n\n\n\n\nTake a look at the left-hand of the window. Under Layout select ForceAtlas2. For the moment we can keep the defaults and hit Start. The nodes should move into distinct directions.\n\n\n\n\n\nAt this stage your graph might look like that.\n\n\n\n\n\nTake a look at the right part of the window. Select Statistics, and there Modularity. Hit Start, keep the defaults. The algorithm should cluster you graph into distinc modularity classes.\n\n\n\n\n\nAt this point I suggest to export the clustered data. Enter the data laboratory tab and select “Export Table”. Save the CSV file in your desired location and make it available for your Jupyter / Colab environment, e.g. by uploading the file to your Google Drive. Follow the next steps in python. Alternatively: Follow the link below to the rest of the Gephi recipe.\n\n\nThe whole process towards a proper label-image-network contains even more steps, I outsourced them into a document on its own, click here for the missing steps. It’s important to note that working with Gephi, especially when dealing with images, can be demanding in terms of memory usage, and the resulting PDFs are sometimes challenging to handle. To address these issues, I’ve developed a Python script that simplifies the exploration of modularity classes. This script uses a CSV file exported from Gephi to display a selection of images from each class. While this method offers a more manageable way to quickly review samples within each modularity class and assess if we’re on the right track, it’s crucial to acknowledge that we lose certain details in this process. Specifically, this approach doesn’t show the relationships between images and labels, nor does it reveal the spatial distribution of these images within the original network. It’s a trade-off between ease of exploration and the depth of network information,\n\n\n\nThis image showcases the objective of using Gephi and networks: Labels and images are aranged spatially, zooming into each of the clusters we can name them based on their content. In my example the images in the displayed cluster all show streets or city-views, thus glimpses of the farmers’ demonstrations with from a wide-angle perspective.\n\n\nFollow the next steps to visualize samples from your modularity classes:\n\nUnzip the image files, e.g. from your Drive.\n\n!zip -r /content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-09-Images-Clean.zip media\n\nImport the CSV-File exported from Gephi. Set sample_size to your desired number, I recommend a low number, e.g. 5.\n\nimport pandas as pd\n\ngephi_file = \"/content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-11-Google-Vision-Graph-w-modclasses.csv\"  #@param {type:\"string\"}\nsample_size = 5 \ngephi_df = pd.read_csv(gephi_file)\n\nRender the Sample: Hit run for the next cell to create an HTML view of image classifications. The HTML will also be saved to file, check the files in the left pane for a file named {formatted_date}-Gephi-Mod-Classes-Visualisation.html to download the document to your computer. The file includes the base64 encoded images.\n\n# See linked notebook for code.\n\nSource: Quickly Visualize Mod Classes\n\n\n\nA screenshot of the same modularity class as above showing a sample of five images."
  },
  {
    "objectID": "image-analysis/exploration.html#clustering-with-k-means",
    "href": "image-analysis/exploration.html#clustering-with-k-means",
    "title": "Visual Exploration",
    "section": "Clustering with k-Means",
    "text": "Clustering with k-Means\nExploring image corpora using labels or web-entities is just one way of using commercial APIs. Several providers offer models for text detection (OCR), face detection, and more. Below we will take a look at auto-generated image captions – which coincidentally produce text, a data format compatible for exploration and classification using methods established in past sessions. For the k-means approach, we use the image labels and create a matrix with dummy variables: Each labels occupies a column, each image a row, and each cell in the matrix is marked as either True or False. Using this matrix we try to find k-clusters of similar images using the k-means algorithm. First of all I recommend the video below by one of my favorite YouTube channels, for an understanding of the k-means algorithm. Then we take a look at a practical implementation of the algorithm for our visual corpus.\n\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nThe following notebook is fully functional. It is, however, hardly commented. I will update the notebook and page shortly.\n\n\n\nHands-on k-means\n\n\nimport pandas as pd\n\n# Load the CSV file\nmemespector_file = \"/content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-11-Google-Vision-All.csv\"\ndf = pd.read_csv(memespector_file)\n\ndf = df[['Image_BaseName', 'GV_Label_Descriptions']]\n\n# Splitting the 'GV_Label_Descriptions' into individual labels\nsplit_labels = df['GV_Label_Descriptions'].str.split(';').apply(pd.Series, 1).stack()\nsplit_labels.index = split_labels.index.droplevel(-1)  # to line up with df's index\nsplit_labels.name = 'Label'\n\n# Joining the split labels with the original dataframe\ndf_split = df.join(split_labels)\n\n# Creating a matrix of True/False values for each label per Image_BaseName\nmatrix = pd.pivot_table(df_split, index='Image_BaseName', columns='Label', aggfunc=lambda x: True, fill_value=False)\n\n# Resetting the column headers to be the label names only\nmatrix.columns = [col[1] for col in matrix.columns.values]\n\n# Now 'matrix' has a single level of column headers with only the label names\n\n\nmatrix\n\n\n  \n    \n\n\n\n\n\n\nAdaptation\nAdvertising\nAfterglow\nAgricultural machinery\nAgriculture\nAir travel\nAircraft\nAirliner\nAirplane\nAlloy wheel\n...\nVertebrate\nWater\nWater resources\nWheel\nWhiskers\nWhite\nWindow\nWood\nWorking animal\nWorld\n\n\nImage_BaseName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6750551853789891846.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6750761577349254405.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6751467034741067014.jpg\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6763591353164254469.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n6766552734108749062.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7321800737606896928.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321804342179204384.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321804909290999045.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321806774967815457.jpg\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n7321806890906701089.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n982 rows × 681 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Ensuring that 'Image_BaseName' is not part of the matrix to apply PCA\nimage_base_names = matrix.index  # Saving the image base names for later use\nlabel_matrix = matrix.values  # Convert to numpy array for PCA\n\n# Dimensionality reduction using PCA\n# Considering a variance ratio of 0.95 to determine the number of components\npca = PCA(n_components=0.95)\nmatrix_reduced = pca.fit_transform(label_matrix)\n\n# If needed, you can create a DataFrame from the PCA-reduced matrix and reattach the 'Image_BaseName' column\nmatrix_reduced_df = pd.DataFrame(matrix_reduced, index=image_base_names)\n\n\nmatrix_reduced_df\n\n\n  \n    \n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n\n\nImage_BaseName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6750551853789891846.jpg\n1.392793\n-0.851573\n-0.225060\n-0.630954\n0.345822\n-0.313126\n0.376667\n0.370456\n-0.012519\n-0.898472\n...\n-0.007803\n0.022912\n-0.002782\n0.019272\n-0.005465\n-0.005129\n0.011833\n0.000200\n0.006499\n0.010995\n\n\n6750761577349254405.jpg\n-1.045212\n0.139963\n-0.396712\n0.505531\n-0.186165\n0.278001\n0.860551\n-0.387782\n-0.041959\n0.146992\n...\n0.020865\n0.027422\n0.064993\n0.046791\n0.042511\n-0.040843\n-0.091713\n-0.064683\n0.043392\n-0.045372\n\n\n6751467034741067014.jpg\n0.364738\n0.089808\n0.603463\n0.717136\n0.084382\n0.130516\n0.835040\n0.056190\n-0.175465\n-0.551632\n...\n-0.009497\n0.144801\n-0.020713\n0.035502\n-0.085562\n-0.169911\n0.083582\n0.045916\n-0.123521\n0.032273\n\n\n6763591353164254469.jpg\n0.657532\n-0.007257\n-0.226448\n-0.142833\n-0.615043\n-0.208217\n-0.082478\n0.181550\n0.899774\n0.462160\n...\n-0.025889\n0.006257\n0.060421\n0.028564\n0.045773\n0.000179\n0.003499\n0.027838\n0.007171\n-0.051516\n\n\n6766552734108749062.jpg\n1.638604\n-0.418596\n-0.178993\n-0.522654\n0.663303\n-0.186928\n1.000894\n-0.307874\n-0.172688\n0.336597\n...\n-0.009052\n-0.002043\n0.007575\n-0.031553\n0.007831\n-0.005779\n-0.023599\n-0.021165\n-0.000496\n-0.006467\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n7321800737606896928.jpg\n-0.698156\n0.191274\n-0.529836\n0.047008\n0.862388\n-0.111187\n-0.390502\n-0.089231\n0.144091\n0.326504\n...\n-0.015025\n-0.068188\n-0.023787\n0.009343\n0.004624\n0.001396\n0.097441\n0.145987\n-0.102992\n0.110626\n\n\n7321804342179204384.jpg\n0.032051\n0.048450\n0.454149\n-0.012114\n0.395014\n0.128612\n0.042362\n1.019634\n-0.367217\n1.025644\n...\n-0.002146\n-0.042328\n0.114229\n-0.066740\n-0.051395\n-0.021397\n0.012134\n0.046365\n-0.005712\n0.036329\n\n\n7321804909290999045.jpg\n1.005015\n0.923683\n0.371054\n0.533427\n0.356759\n0.813597\n0.087288\n-0.289707\n0.377865\n1.242866\n...\n0.005721\n0.000672\n0.021087\n0.020260\n0.037709\n0.000290\n0.015725\n0.013237\n0.018040\n-0.002060\n\n\n7321806774967815457.jpg\n-0.597974\n0.855850\n-0.262498\n-0.214283\n-0.731812\n-0.209626\n-0.179683\n0.529353\n-0.239506\n0.048401\n...\n-0.012399\n0.023383\n-0.073488\n0.063523\n0.013320\n0.020351\n-0.033865\n0.029809\n-0.080413\n-0.074329\n\n\n7321806890906701089.jpg\n-0.042383\n-0.138050\n0.075564\n-0.396196\n0.056236\n0.612394\n-0.272538\n-0.230238\n-0.379339\n-0.668773\n...\n-0.106623\n-0.214393\n0.209117\n0.021869\n0.220278\n0.070092\n-0.198979\n0.140981\n-0.004653\n-0.070667\n\n\n\n\n\n982 rows × 242 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Elbow method to determine optimal number of clusters\ninertia = []\nrange_values = range(1, 20)  # Checking for 1 to 10 clusters\n\nfor i in range_values:\n    kmeans = KMeans(n_clusters=i, n_init=10, random_state=0)\n    kmeans.fit(matrix_reduced_df)\n    inertia.append(kmeans.inertia_)\n\n# Plotting the Elbow Curve\nplt.figure(figsize=(10, 6))\nplt.plot(range_values, inertia, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.show()\n\n\n\n\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport matplotlib.pyplot as plt\n\n# Define the range of clusters to try\nrange_values = range(2, 20)\n\nsilhouette_scores = []\n\n# Perform k-means clustering and compute silhouette scores\nfor i in range_values:\n    try:\n        kmeans = KMeans(n_clusters=i, n_init=10, random_state=0)\n        kmeans.fit(matrix_reduced_df)\n        score = silhouette_score(matrix_reduced_df, kmeans.labels_)\n        silhouette_scores.append(score)\n    except Exception as e:\n        print(f\"An error occurred with {i} clusters: {e}\")\n\n# Plotting the Silhouette Scores\nwith plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(10, 6))\n    plt.plot(range_values, silhouette_scores, marker='o')\n    plt.title('Silhouette Method')\n    plt.xlabel('Number of clusters')\n    plt.ylabel('Silhouette Score')\n    plt.show()\n\n\n\n\n\n# Final k-means clustering using n clusters\nkmeans_final = KMeans(n_clusters=11, n_init=10, random_state=0)\nclusters = kmeans_final.fit_predict(matrix_reduced)\n\n# Adding the cluster information back to the original dataframe\nmatrix['Cluster'] = clusters\n\n\n# Displaying the first few rows of the dataframe with cluster information\nmatrix.head()\n\n\n  \n    \n\n\n\n\n\n\nAdaptation\nAdvertising\nAfterglow\nAgricultural machinery\nAgriculture\nAir travel\nAircraft\nAirliner\nAirplane\nAlloy wheel\n...\nWater\nWater resources\nWheel\nWhiskers\nWhite\nWindow\nWood\nWorking animal\nWorld\nCluster\n\n\nImage_BaseName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6750551853789891846.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n8\n\n\n6750761577349254405.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n2\n\n\n6751467034741067014.jpg\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n6\n\n\n6763591353164254469.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n0\n\n\n6766552734108749062.jpg\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n...\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n8\n\n\n\n\n\n5 rows × 682 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n!unzip /content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-09-Images-Clean.zip\n\n\n# Display the result. See linked notebook for code.\n\nSource: k-means"
  },
  {
    "objectID": "image-analysis/exploration.html#bertopic",
    "href": "image-analysis/exploration.html#bertopic",
    "title": "Visual Exploration",
    "section": "BERTopic",
    "text": "BERTopic\n\nFor this notebook we use a 4CAT corpus collected from TikTok about the 2024 Farmers’ Protest in Germany. Let’s take a look at all relevant columns. We’re mostly dealing with the image_file column. Additionally, the images files should be extracted to the /content/media/images/ path. (See linked notebook for the conversion from the original 4CAT files).\n\ndf[['id', 'body', 'Transcript', 'image_file']].head()\n\n\n  \n    \n\n\n\n\n\n\nid\nbody\nTranscript\nimage_file\n\n\n\n\n0\n7321692663852404001\n#Fakten #mutzurwahrheit #ulrichsiegmund #AfD #...\nLiebe Freunde, schaut euch das an, das ist der...\n/content/media/images/7321692663852404001.jpg\n\n\n1\n7320593840212151584\nUnstoppable 🇩🇪 #deutschland #8januar2024 #baue...\nthe next, video!!\n/content/media/images/7320593840212151584.jpg\n\n\n2\n7321341957333060896\n08.01.2024 Streik - Hoss & Hopf #hossundhopf #...\nscheiß Bauern, die, was weiß ich, ich habe auc...\n/content/media/images/7321341957333060896.jpg\n\n\n3\n7321355364950117665\n#streik #2024 #bauernstreik2024 #deutschland #...\n😎😎😎😎😎😎😎😎😎\n/content/media/images/7321355364950117665.jpg\n\n\n4\n7321656341590789409\n#🌞❤️ #sunshineheart #sunshineheartforever #🇩🇪 ...\nNaN\n/content/media/images/7321656341590789409.jpg\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nBERTopic\nLet’s first install bertopic including the vision extensions.\n\n\n\n\n\n\nNote\n\n\n\nThe following code has been taken from the BERTopic documentation and was only slightly changed.\n\n\n\n!pip install bertopic[vision]\n\n\nImages Only\nNext, we prepare the pipeline for an image-only model: We want to fit the Topic Model on the image content only. We follow the BERTOpic Multimodal Manual, and generate image captions using the vit-gpt2-image-captioningpackage. The documentation offers a lot of different options, we can incorporate textual content for the topic modeling, or fit the model on textual information only and look for the best matching images for each cluster and display them.\nIn our example we focus on image-only topics models.\n\nfrom bertopic.representation import KeyBERTInspired, VisualRepresentation\nfrom bertopic.backend import MultiModalBackend\n\n# Image embedding model\nembedding_model = MultiModalBackend('clip-ViT-B-32', batch_size=32)\n\n# Image to text representation model\nrepresentation_model = {\n    \"Visual_Aspect\": VisualRepresentation(image_to_text_model=\"nlpconnect/vit-gpt2-image-captioning\")\n}\n\nNext, select the column with the path of your images files, in my example image_file. Convert it to a python list.\n\nimage_only_df = df.copy()\nimages = image_only_df['image_file'].to_list()\n\nNow it’s time to fit the model.\n\nfrom bertopic import BERTopic\n\n# Train our model with images only\ntopic_model = BERTopic(embedding_model=embedding_model, representation_model=representation_model, min_topic_size=5)\ntopics, probs = topic_model.fit_transform(documents=None, images=images)\n\nFinally let’s display the topics. Remember: Topic -1 is a collection of documenst that do not fit into any topic.\n\n# See linked notebook for code.\n\n\n\nSource: Visual BERTopic\n\n\n\nScreenshots from the final table: BERTopic identified e.g. these two topics. The top topic appears to be text-centric posts, where the embedded text makes up a large portion of the content. The bottom topic, on the other hand, is all about faces, showing people in a selfie-perspective, often speaking to the screen, possibly resembling what Sánchez-Querubı́n et al. (2023) titled “Playful Performance”. Note: I defamiliarized the faces for privacy."
  },
  {
    "objectID": "image-analysis/exploration.html#bertopic-1",
    "href": "image-analysis/exploration.html#bertopic-1",
    "title": "Visual Exploration",
    "section": "BERTopic",
    "text": "BERTopic\nLet’s first install bertopic including the vision extensions.\n\n\n\n\n\n\nNote\n\n\n\nThe following code has been taken from the BERTopic documentation and was only slightly changed.\n\n\n\n!pip install bertopic[vision]\n\n\nImages Only\nNext, we prepare the pipeline for an image-only model: We want to fit the Topic Model on the image content only. We follow the BERTOpic Multimodal Manual, and generate image captions using the vit-gpt2-image-captioningpackage. The documentation offers a lot of different options, we can incorporate textual content for the topic modeling, or fit the model on textual information only and look for the best matching images for each cluster and display them.\nIn our example we focus on image-only topics models.\n\nfrom bertopic.representation import KeyBERTInspired, VisualRepresentation\nfrom bertopic.backend import MultiModalBackend\n\n# Image embedding model\nembedding_model = MultiModalBackend('clip-ViT-B-32', batch_size=32)\n\n# Image to text representation model\nrepresentation_model = {\n    \"Visual_Aspect\": VisualRepresentation(image_to_text_model=\"nlpconnect/vit-gpt2-image-captioning\")\n}\n\nNext, select the column with the path of your images files, in my example image_file. Convert it to a python list.\n\nimage_only_df = df.copy()\nimages = image_only_df['image_file'].to_list()\n\nNow it’s time to fit the model.\n\nfrom bertopic import BERTopic\n\n# Train our model with images only\ntopic_model = BERTopic(embedding_model=embedding_model, representation_model=representation_model, min_topic_size=5)\ntopics, probs = topic_model.fit_transform(documents=None, images=images)\n\nFinally let’s display the topics. Remember: Topic -1 is a collection of documenst that do not fit into any topic.\n\n# See linked notebook for code."
  },
  {
    "objectID": "image-analysis/exploration.html#summary",
    "href": "image-analysis/exploration.html#summary",
    "title": "Visual Exploration",
    "section": "Summary",
    "text": "Summary\nI introduced several unsupervised approaches for exploring visual corpora. The first part of this article introduced commercial computer vision APIs as a source for labels describing the content of images, the second part derived the knowledge of image content by generating image captions. Using these captions we fit a topic model, that helped to cluster the images into classes. Overall, the approaches result in two or more groups of images, that show similarities. What makes an image similar, is based on the model we apply. PicArrange, for example, uses colours, while other approaches focus on detected objects and labels describing the content of images. These groups need human exploration in order to make sense of them. The exploration techniques can be useful for a first exploration of your visual corpus. In the next session we go one step further, we will classify images based on their content using different approaches, like CLIP and GPT-4."
  },
  {
    "objectID": "data-collection/ig-stories.html",
    "href": "data-collection/ig-stories.html",
    "title": "Project Creation",
    "section": "",
    "text": "Instagram stories, characterized by their ephemeral nature, expire after 24 hours. Therefore, it’s crucial to collect them in a timely manner, as retrospective data collection is not an option with this format. There are two feasible methods: Instaloader and Zeeschuimer-F. Additionally, commercial tools such as 4k Stogram are also available.\nOverall, the ephemeral nature of stories necessitates our continuous monitoring and data collection from our targeted profiles. To ensure that we capture every story item, I recommend collecting stories twice daily, approximately 12 hours apart. This method accounts for potential inaccuracies in timing, as the intervals overlap. Data can be gathered manually or through computational means. The manual approach, especially in conjunction with Zeeschuimer-F, is preferable as it does not violate the Terms of Service (TOS). For this method, we would install the plugin and view all stories in our browser twice daily. Alternatively, using Instaloader involves simply initiating the command and waiting for the software to gather all the data. Optimally, we could utilize tools like Cron to automate this process."
  },
  {
    "objectID": "data-collection/ig-stories.html#instaloader",
    "href": "data-collection/ig-stories.html#instaloader",
    "title": "Project Creation",
    "section": "Instaloader",
    "text": "Instaloader\nInstaloader for Stories operates in a manner akin to collecting Posts. Initially, the package must be installed:\n!pip -q install instaloader\nUnlike the method outlined in the previous tutorial, I advise employing the command-line interface of Instaloader for collecting stories. To do this, open a terminal and execute the command below:\ninstaloader --login your.profile.name --dirname-pattern ig_stories/{profile} :stories --no-compress-json\nExecuting this command generates a dedicated subfolder within ig_stories for each user followed by your profile. It downloads the metadata, images, and videos of each story. The metadata is saved in a JSON file. While these files are typically xz-compressed by default, using the --no-compress-json option prevents this compression. Subsequently, the JSON files can be imported into a pandas DataFrame in Python.\nThis process can be automated, for example, by utilizing a bash script in conjunction with cron:\n#!/bin/bash\n\n# Generate a random number of seconds between 0 and 3600 (1 hours)\nsleep_duration=$(( RANDOM % 3600 ))\n\n# Print the sleep duration\necho \"Sleeping for $sleep_duration seconds...\"\n\n# Sleep for the random duration\nsleep $sleep_duration\n\n# Run Instaloader command to download the latest Instagram stories\ninstaloader --login your.profile.name --dirname-pattern ~/ig_stories/{profile} :stories  --no-compress-json\n\n# Add more script to check for success and send alerts in case of error\nStart cron by entering crontab -e on your terminal and add a line pointing to the bash script, e.g.:\n* 8,20 * * * /path/to/your/script.sh &gt;/dev/null 2&gt;&1\n\n\nPros:\n\n\nVery easy to automate\n\n\nCollects all data: metadata, images, videos\n\n\n\n\nCons:\n\n\nPossibly against the TOS\n\n\nRate Limits\n\n\nBlocked Accounts (very quickly)"
  },
  {
    "objectID": "data-collection/ig-stories.html#zeeschuimer-f",
    "href": "data-collection/ig-stories.html#zeeschuimer-f",
    "title": "Project Creation",
    "section": "Zeeschuimer-F",
    "text": "Zeeschuimer-F\n\nThis method is based on the Zeeschuimer Firefox Plugin. I have adapted the original plugin to create Zeeschuimer-F, which is specifically tailored for collecting Instagram stories and interfacing with the Zeeschuimer-Firebase-Backend for real-time data collection. You can find Zeeschuimer-F on GitHub. To use it, download the latest version via Firefox and install the plugin. For our seminar, I’ll provide a backend instance; refer to the README.md on GitHub for guidance on setting up your own instance on Firebase. Credentials for our seminar will be distributed through GRIPS. Follow these steps to download stories using Zeeschuimer-F:\n\nDownload and install the plugin.\nCreate a project on the backend (via Notebook).\nConfigure the plugin.\nRegularly view stories in Firefox to collect them.\nDownload the collected data (via Notebook).\n\n\nPlugin Installation\nTo install the plugin, download the latest release .xpi file from GitHub using Firefox. After downloading, click on the file in Firefox and confirm the installation of the extension.\n\n\n\nScreenshot of Firefox with the open extensions menu\n\n\nVerify the extension’s installation by checking the right-hand menu in Firefox. We will return to the browser shortly.\n\n\n\nThe Firebase Interface Notebook\n\nThe following lines of code assume that the firebase Credential File has been downloaded from GRIPS and uploaded to Colab / your Jupyter project path. First of all install the necessary packages:\n\n!pip -q install firebase-admin\n\nNext, we connect to our firebase project. Please update the credentials_path variable with the path to your credentials file (see above).\n\nimport firebase_admin\nfrom firebase_admin import credentials, firestore\n\ncredentials_path = '/content/XXXX-adminsdk-YYYYYY.json' \n\ncred = credentials.Certificate(credentials_path)\nfirebase_admin.initialize_app(cred)\ndb = firestore.client()\n\n\nProject Creation\nPlease provide an alert_email and project_name to create a new project on the backend. The backend checks hourly when the last stories have been uploaded to a project. If no story has been uploaded for more than 12 hours, an email alert will be triggered.\nRun the cell to create the new project on the backend. When successfull, the project id and api key will be displayed.\n\nfrom IPython.display import display, Markdown\nimport pandas as pd\n\nalert_email = 'michael@achmann.me'\nproject_name = 'Forschungsseminar23 Test'\n\n# Create Project\nimport uuid\n\n# Generate a UUID for the document\nproject_id = str(uuid.uuid4())\napi_key = str(uuid.uuid4())\n\n# Your data\ndata = {\n    \"api_key\": api_key,\n    \"email\": alert_email,\n    \"name\": project_name\n}\n\n# Add a new document with a UUID as the document name (ID)\ndoc_ref = db.collection('projects').document(project_id)\ndoc_ref.set(data)\n\ndisplay(Markdown(\"### Project Created:\"))\ndisplay(Markdown(f\"**Project Name:** {project_name}\"))\ndisplay(Markdown(f\"**Alert Email:** {alert_email}\"))\ndisplay(Markdown(f\"**Project ID:** {project_id}\"))\ndisplay(Markdown(f\"**API-Key:** {api_key}\"))\n\n\nProject Created:\nProject Name: Forschungsseminar23 Test\nAlert Email: michael@achmann.me\nProject ID: 959466fe-4088-4099-a6b2-3cbe058889d3\nAPI-Key: 554fbce8-fb15-44f1-bb4d-54cdc57554f2\n\n\n\nConfigure the Plugin\nConfigure Zeeschuimer-F using the above information after creating a project. In order to access the settings of Firefox plugins click on the puzzle tile on the top right of the browser. Click on Zeeschuimer F and the settings open.\n\n\n\nScreenshot of Firefox with open extensions menu\n\n\nFill in the Firebase Project field with the project id and aFirebase API Key with the api key provided after running the Project Creation. The Firebase Endopint URL will be provided via GRIPS (unless you’ve installed your own instance).\n\n\n\nScreenshot of the Settings for Zeeschuimer-F\n\n\n1) Turn the IG Stories Switch on, 2) restart your browser for the values to be loaded correctly. Once the browser has started again, you’re ready to collect you first stories! Open the Instagram website and open any story.\n\n\n\nScreenshot of the switch\n\n\nCheck the extension settings page to see whether it is collecting stories while browsing. The counter should increase with each story visit. The remote collection process can currently only be checked through the Firebase Interface notebook. Follow the next steps to download the collected data.\n\n\nProject Export\nThe following code downloads all stories in JSON format and saves it locally (i.e. on your colab instance). Provide the PROJECT_ID variable and an export_path to download all stories.\n\nfrom tqdm.auto import tqdm\nimport os\nimport json\n\nPROJECT_ID = '959466fe-4088-4099-a6b2-3cbe058889d3'\nexport_path = '/content/export' \n\n\ndef fetch_stories(project_id):\n    stories_ref = db.collection('projects').document(project_id).collection('stories')\n    docs = stories_ref.stream()\n\n    stories = []\n    for doc in docs:\n        stories.append(doc.to_dict())\n\n    return stories\n\ndb = fetch_stories(PROJECT_ID)\n\nif not os.path.exists('export'):\n    os.makedirs('export')\n\n# Iterate over each element in the database\nfor element in tqdm(db, desc='Exporting elements'):\n    # Serialize the element to JSON\n    element_json = json.dumps(element, indent=4)\n\n    # Write to a file named {id}.json\n    with open(os.path.join('export', f\"{element['id']}.json\"), 'w') as f:\n        f.write(element_json)\n\n\n\n\n\n\nConvert to DataFrame\nNext, we convert the exported JSON files to a pandas DataFrame and save the table as CSV. Provide the df_export_path variable for the location where to save the exported CSV file.\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nThe DataFrame in the current version has a different structure than the one we created when downloading Instagram Posts.. In order to compare stories with posts we will might want to use the same data structure.\n\n\n\n\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n\ndf_export_path = '/content/2022-11-09-Stories-Exported.csv' \n\ndef process_instagram_story(data):\n\n    # Extract relevant information\n    story_info = {\n        'ID': data.get(\"id\"),\n        'Time of Posting': datetime.utcfromtimestamp(data['taken_at']).strftime('%Y-%m-%d %H:%M:%S'),\n        'Type of Content': 'Video' if 'video_duration' in data else 'Image',\n        'video_url': None,\n        'image_url': None,\n        'Username': data['user']['username'],\n        'Video Length (s)': data.get('video_duration', None),\n        'Expiration': (datetime.utcfromtimestamp(data['taken_at']) + timedelta(hours=24)).strftime('%Y-%m-%d %H:%M:%S'),\n        'Caption': data.get('caption', None),\n        'Is Verified': data['user']['is_verified'],\n        'Stickers': data.get('story_bloks_stickers', []),\n        'Accessibility Caption': data.get('accessibility_caption', ''),\n        'Attribution URL': data.get('attribution_content_url', '')\n    }\n\n    return story_info\n\nrows = []\nfor element in db:\n  rows.append(process_instagram_story(element))\n\ndf = pd.DataFrame(rows)\ndf.to_csv(df_export_path)\nprint(f\"Successfully exported {len(df)} rows as CSV.\")\n\nSuccessfully exported 22 rows as CSV.\n\n\nNow let’s take a look at the structure of the exported data:\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nID\nTime of Posting\nType of Content\nvideo_url\nimage_url\nUsername\nVideo Length (s)\nExpiration\nCaption\nIs Verified\nStickers\nAccessibility Caption\nAttribution URL\n\n\n\n\n0\n3231585718932790545_1483455177\n2023-11-08 14:50:59\nImage\n&lt;NA&gt;\nhttps://storage.googleapis.com/zeeschuimer-fb-...\nrmf24.pl\nNaN\n2023-11-09 14:50:59\nNone\nFalse\n[]\nPhoto by Fakty RMF FM | Rozmowy | Podcasty on ...\n\n\n\n1\n3231585778860997221_1483455177\n2023-11-08 14:51:06\nImage\n&lt;NA&gt;\nhttps://storage.googleapis.com/zeeschuimer-fb-...\nrmf24.pl\nNaN\n2023-11-09 14:51:06\nNone\nFalse\n[]\nPhoto by Fakty RMF FM | Rozmowy | Podcasty on ...\n\n\n\n2\n3231750838597692854_1349651722\n2023-11-08 20:19:00\nVideo\nhttps://storage.googleapis.com/zeeschuimer-fb-...\n&lt;NA&gt;\ntagesschau\n13.300\n2023-11-09 20:19:00\nNone\nTrue\n[]\n\n\n\n\n3\n3231750989408058657_1349651722\n2023-11-08 20:19:18\nVideo\nhttps://storage.googleapis.com/zeeschuimer-fb-...\n&lt;NA&gt;\ntagesschau\n15.267\n2023-11-09 20:19:18\nNone\nTrue\n[]\n\n\n\n\n4\n3231751135118088390_1349651722\n2023-11-08 20:19:35\nVideo\nhttps://storage.googleapis.com/zeeschuimer-fb-...\n&lt;NA&gt;\ntagesschau\n17.000\n2023-11-09 20:19:35\nNone\nTrue\n[]\n\n\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nDownload Images and Videos\nAll videos and images for our Instagram stories have been downloaded by our firebase backend. They are saved in a Cloud Bucket. The following cell helps with these two steps:\n\nCreate a signed link to each video and image\nDownload each file and saves it in the following structure: {media_export_path}/{image|video}/{username}/{ID.jpg|mp4}. It is important to keep a unique identifier (here ID) to map metadata and images for future data analysis.\n\nPlease provide a storage_bucket and media_export_path.\n\nstorage_bucket = \"XXXX.appspot.com\"  \nmedia_export_path =  '/content/media/'\n\nfrom firebase_admin import storage\nimport os\nimport requests\n\nbucket = storage.bucket(storage_bucket)\n\ndef generate_signed_url(username, content_id, file_type):\n    if file_type not in ['images', 'videos']:\n        raise ValueError(\"Invalid file type specified\")\n\n    ext = 'jpeg' if file_type == 'images' else 'mp4'\n    blob_path = f\"projects/{PROJECT_ID}/stories/{file_type}/{username}/{content_id}.{ext}\"\n    blob = bucket.blob(blob_path)\n    # Set the expiration of the link. Here, it's set to 24 hours.\n    return blob.generate_signed_url(expiration=timedelta(hours=24), method='GET')\n\n# Create a function to be applied across DataFrame rows\ndef apply_generate_signed_url(row):\n    image_url = generate_signed_url(row['Username'], row['ID'], 'images')\n    video_url = generate_signed_url(row['Username'], row['ID'], 'videos') if row['Type of Content'] == 'Video' else pd.NA\n    return pd.Series({'image_url': image_url, 'video_url': video_url})\n\n# Apply the function along the axis=1 (row-wise)\ndf[['image_url', 'video_url']] = df.apply(apply_generate_signed_url, axis=1)\n\n# Now, creating the lists for images and videos can be done more efficiently\ndata_images = df.loc[df['image_url'].notna(), ['ID', 'image_url', 'Username', 'Time of Posting']] \\\n               .rename(columns={'image_url': 'url', 'Time of Posting': 'datetime'}) \\\n               .to_dict('records')\n\ndata_videos = df.loc[df['video_url'].notna(), ['ID', 'video_url', 'Username', 'Time of Posting']] \\\n               .rename(columns={'video_url': 'url', 'Time of Posting': 'datetime'}) \\\n               .to_dict('records')\n\n\ndef create_directories(base_path, entries, subdir):\n    usernames = set(entry['Username'] for entry in entries)\n    for username in usernames:\n        os.makedirs(os.path.join(base_path, subdir, username), exist_ok=True)\n\ndef download_file(entry, media_type, media_export_path, session):\n    directory = os.path.join(media_export_path, media_type, entry['Username'])\n    ext = 'jpg' if media_type == 'images' else 'mp4'\n    filename = os.path.join(directory, f\"{entry['ID']}.{ext}\")\n\n    with session.get(entry['url'], stream=True) as response:\n        if response.status_code == 200:\n            with open(filename, 'wb') as file:\n                for chunk in response.iter_content(8192):\n                    file.write(chunk)\n        else:\n            print(f\"Failed to download {entry['url']}. Status code: {response.status_code}\")\n\nsession = requests.Session()\n# Pre-create directories\ncreate_directories(media_export_path, data_images, 'images')\ncreate_directories(media_export_path, data_videos, 'videos')\n\n# Download images\nfor entry in tqdm(data_images, desc=\"Downloading Images\", unit=\"file\"):\n    download_file(entry, 'images', media_export_path, session)\n\n# Download videos\nfor entry in tqdm(data_videos, desc=\"Downloading Videos\", unit=\"file\"):\n    download_file(entry, 'videos', media_export_path, session)\n\nprint(\"Download complete!\")\n\n\n\n\n\n\n\nDownload complete!\n\n\n\n\nPrepare Downloadable ZIP\nRun the following to ZIP all files. Optionally copy them to Google Drive.\n\n!zip -r 2023-11-09-Story-Media-Export.zip media/*\n\n\n!cp 2023-11-09-Story-Media-Export.zip /content/drive/MyDrive/\n\n\nSource: Firebase Interface Notebook\n\n\n\nPros:\n\n\nWe do not infringe the TOS\n\n\nCollects all data: metadata, images, videos\n\n\nThe firebase backend handles alert emails\n\n\n\n\nCons:\n\n\nCurrent solution relies on the firebase backend\n\n\nWe need to manually browse the stories twice a day (can be automated using Selenium)\n\n\nData is collected on firebase storage, we need to export to use it"
  },
  {
    "objectID": "data-collection/ig-stories.html#conclusion",
    "href": "data-collection/ig-stories.html#conclusion",
    "title": "Project Creation",
    "section": "Conclusion",
    "text": "Conclusion\nThis page offers an overview of two methods for collecting ephemeral Instagram stories, which are crucial to capture in real time due to their 24-hour expiration period. The first method, instaloader, is theoretically effective. However, similar to the case with posts, Instagram accounts utilizing Instaloader face a high risk of being banned swiftly.\nThe second approach adopts a less invasive strategy. It involves capturing the data transmitted to the browser while viewing stories on Instagram, and then transferring the metadata to our Firebase project. Upon the addition of a new story to the database, the backend initiates the download of videos and images for that story.\nTo facilitate this process, I have provided a notebook for project creation, a manual for configuring the plugin, and additional code to export the captured stories via a Jupyter notebook."
  },
  {
    "objectID": "data-collection/ig-posts.html",
    "href": "data-collection/ig-posts.html",
    "title": "Instagram Posts",
    "section": "",
    "text": "Instagram offers two ways of image sharing: permanent posts and ephemeral stories. In this chapter I will offer three approaches for collecting posts: Instaloader, CrowdTangle, and Zeeschuimer.\nPosts are shaped by several affordances and contain different type of media: least one image or video, often paired with text (captions). Posts may also contain an album consisting of more than one image or video. Captions may contain hashtags and / or mentions. Hashtags are used to self-organize posts on the platform, users can subscribe to hashtags and search for them. Mentions are used to link a post to another profile. Moreover, users can like, share and comment posts. Some data-collection approaches, like CrowdTangle, offer access to one image and post metrics, like the comment and like count. Instaloader, offer access to all images / videos, while being the legally most questionable approach. And then there’s the middle ground: Zeeschuimer (optionally in connection with 4CAT).\nThrough the following subchapters I will try to illuminate the advantages of each collection methods. For each method I will provide a manual to follow in order to collect metadata and the actual media for Instagram posts."
  },
  {
    "objectID": "data-collection/ig-posts.html#instaloader",
    "href": "data-collection/ig-posts.html#instaloader",
    "title": "Instagram Posts",
    "section": "Instaloader",
    "text": "Instaloader\nInstaloader is a python package for downloading instagram pictures and videos along with their metadata. I have written a getting started tutorial on Medium. It is, together with the provided notebook, the basis for this chapter.\n\n\n\n\n\n\nNote\n\n\n\nInstaloader is a stand-alone piece of software: It offers options to download most Instagram content, like posts and stories, through different strategies, e.g. lists of profiles or by hashtag. For complex tasks I recommend to call instaloader from terminal, see the documentation for more information.\n\n\n\nIn order to download posts and stories from Instagram, we use the package instaloader. You can install package for python using pip install &lt;package&gt;, the command -q minimizes the output.\n\n!pip -q install instaloader\n\n     |████████████████████████████████| 60 kB 3.0 MB/s eta 0:00:011\n  Building wheel for instaloader (setup.py) ... done\n\n\nOnce you install instaloader we log in using your username and password. Session information (not your credentials!) is stored in Google Drive to minimize the need for signing in.\nIn order to minimize the risk for your account to be disabled we suggest creating a new account on your phone before proceeding!\n\nusername = 'your.username'\n\n# We save the sessionfile to the following directory. Default is the new folder `.instaloader` in your google drive. (This is optional)\nsession_directory = '/content/drive/MyDrive/.instaloader/'\n\nimport instaloader\nfrom os.path import exists\nfrom pathlib import Path\n\n# Creating session directory, if it does not exists yet\nPath(session_directory).mkdir(parents=True, exist_ok=True)\n\nfilename = \"{}session-{}\".format(session_directory, username)\nsessionfile = Path(filename)\n\n\n# Get instance\nL = instaloader.Instaloader(compress_json=False)\n\n# Check if sessionfile exists. If so load session,\n# else login interactively\nif exists(sessionfile):\n  L.load_session_from_file(username, sessionfile)\n\nelse:\n  L.interactive_login(username)\n  L.save_session_to_file(sessionfile)\n\nLoaded session from /content/drive/MyDrive/.instaloader/session-mi_sm_lab05.\n\n\n\nDownloading first Posts\nNext, we try to download all posts of a profile. Provide a username and folder:\n\ndest_username = 'some.profile' \ndest_dir = '/content/drive/MyDrive/insta-posts/' # Once more we save the files to Google Drive. Replace this with a local directory if necessary.\n\nt = Path(\"{}{}\".format(dest_dir, dest_username))\nt.mkdir(parents=True, exist_ok=True)\n\nprofile = instaloader.Profile.from_username(L.context, dest_username)\nfor post in profile.get_posts():\n    L.download_post(post, target=t)\n\nWell, you just downloaded your first posts! Open Google Drive and check the folder insta-posts/ (or whatever folder you chose above)! There should be three files for each post, the image, a .json file and a .txt file. The .txt includes the image caption, the .json lots of metadata about the post.\n\nDiving into the metadata\nThe next cell reads all .json files of the downloaded posts. Then we browse through some interesting data.\n\n# Reading the paths of all JSON files from dest_dir\nimport os\n\njson_files = []\n\nfor subdir, dirs, files in os.walk(t):\n    for file in files:\n        fullpath = os.path.join(subdir, file)\n        filename, file_extension = os.path.splitext(fullpath)\n        if file_extension == \".json\":\n          json_files.append(fullpath)\n\n\n# Reading all JSON files\nfrom tqdm.notebook import tqdm\nimport json\n\njson_data = []\n\nfor file in tqdm(json_files):\n  with open(file, 'r') as f:\n    data = json.load(f)\n    json_data.append(data)\n\n\n\n\nOk, now all metadata for all posts is saved to the variable json_data. Run the next line and copy its output to http://jsonviewer.stack.hu/. Your output should look similar, go ahead and play around to explore your data! What information can you extract?\n\nprint(json.dumps(json_data[0]))\n\n\n\nMetadata Preprocessing\nPosts contain plenty of data, like time and location of the post, the authoring user, a caption, tagged users and more. The following cells demonstrate how to normalize the data into a table format, which is useful when working with pandas. Nevertheless, this is optional!\n\n# Use booleans (True / False) values to select what type of data you'd like to analyse. \nusername = True #@param {type:\"boolean\"}\ntimestamp = True #@param {type:\"boolean\"}\ncaption = True #@param {type:\"boolean\"}\nlocation = True #@param {type:\"boolean\"}\nshortcode = True #@param {type:\"boolean\"}\nid = True #@param {type:\"boolean\"}\ntagged_users = True #@param {type:\"boolean\"}\n\nNext we loop through the data and create a new pandas DataFrame. The DataFrame will have one column for each variable selected above and one row for each downloaded posts.\nIf you are not yet familiar with the concept of dataframes have a look at YouTube, there’s plenty of introductory videos available.\n\nimport pandas as pd\n\nposts = []  # Initializing an empty list for all posts\nfor post in tqdm(json_data):\n  row = {} # Initializing an empty row for the post\n\n  node = post.get(\"node\")\n\n  if username:\n    owner = node.get(\"owner\")\n    row['username'] = owner.get(\"username\")\n\n  if timestamp:\n    row['timestamp'] = node.get(\"taken_at_timestamp\")\n\n  if location:\n    l = node.get(\"location\", None)\n    if l:\n      row['location'] = l.get(\"name\")\n\n  if shortcode:\n    row['shortcode'] = node.get(\"shortcode\")\n\n  if id:\n    row['id'] = node.get(\"id\")\n  \n  if tagged_users:\n    pass\n\n  if caption:\n    c = \"\"\n    emtc = node.get(\"edge_media_to_caption\")\n    edges = emtc.get(\"edges\")\n    for element in edges:\n      caption_node = element.get(\"node\")\n      c = c + caption_node.get(\"text\")\n    row['caption'] = c\n\n  # Finally add row to posts\n  posts.append(row)\n\n# After looping through all posts create data frame from list\nposts_df = pd.DataFrame.from_dict(posts)\n\nNow all information selected above is saved to the dataframe posts_df. Run the next cell and it will return a nicely formatted table. If your data is quite long, output will be cropped. Click the wand and after a few seconds you are able to browse through the data or filter by columns\n\nposts_df\n\nIn order to get a first impression of dataframes, the head() method is also useful. Run the next cell to see the result\n\nposts_df.head()\n\nThe dataframe is only saved in memory, thus when disconnecting and deleting the runtime, the dataframe is lost. Running the next cell saves the table to a CSV-file on your drive.\nNow the processed data may be recovered or used in another notebook.\n\nposts_df.to_csv('{}{}.csv'.format(dest_dir, username))\n\n\n\nSource: Collecting Posts with Instaloader\n\n\nPros:\n\n\nMaximum Flexibility\n\n\nCan collect everything out of the box\n\n\nWe can collect content computationally\n\n\n\n\nCons:\n\n\nPossibly against the TOS\n\n\nRate Limits\n\n\nBlocked Accounts"
  },
  {
    "objectID": "data-collection/ig-posts.html#downloading-first-posts",
    "href": "data-collection/ig-posts.html#downloading-first-posts",
    "title": "Instagram Posts",
    "section": "Downloading first Posts",
    "text": "Downloading first Posts\nNext, we try to download all posts of a profile. Provide a username and folder:\n\ndest_username = 'some.profile' \ndest_dir = '/content/drive/MyDrive/insta-posts/' # Once more we save the files to Google Drive. Replace this with a local directory if necessary.\n\nt = Path(\"{}{}\".format(dest_dir, dest_username))\nt.mkdir(parents=True, exist_ok=True)\n\nprofile = instaloader.Profile.from_username(L.context, dest_username)\nfor post in profile.get_posts():\n    L.download_post(post, target=t)\n\nWell, you just downloaded your first posts! Open Google Drive and check the folder insta-posts/ (or whatever folder you chose above)! There should be three files for each post, the image, a .json file and a .txt file. The .txt includes the image caption, the .json lots of metadata about the post.\n\nDiving into the metadata\nThe next cell reads all .json files of the downloaded posts. Then we browse through some interesting data.\n\n# Reading the paths of all JSON files from dest_dir\nimport os\n\njson_files = []\n\nfor subdir, dirs, files in os.walk(t):\n    for file in files:\n        fullpath = os.path.join(subdir, file)\n        filename, file_extension = os.path.splitext(fullpath)\n        if file_extension == \".json\":\n          json_files.append(fullpath)\n\n\n# Reading all JSON files\nfrom tqdm.notebook import tqdm\nimport json\n\njson_data = []\n\nfor file in tqdm(json_files):\n  with open(file, 'r') as f:\n    data = json.load(f)\n    json_data.append(data)\n\n\n\n\nOk, now all metadata for all posts is saved to the variable json_data. Run the next line and copy its output to http://jsonviewer.stack.hu/. Your output should look similar, go ahead and play around to explore your data! What information can you extract?\n\nprint(json.dumps(json_data[0]))\n\n\n\nMetadata Preprocessing\nPosts contain plenty of data, like time and location of the post, the authoring user, a caption, tagged users and more. The following cells demonstrate how to normalize the data into a table format, which is useful when working with pandas. Nevertheless, this is optional!\n\n# Use booleans (True / False) values to select what type of data you'd like to analyse. \nusername = True #@param {type:\"boolean\"}\ntimestamp = True #@param {type:\"boolean\"}\ncaption = True #@param {type:\"boolean\"}\nlocation = True #@param {type:\"boolean\"}\nshortcode = True #@param {type:\"boolean\"}\nid = True #@param {type:\"boolean\"}\ntagged_users = True #@param {type:\"boolean\"}\n\nNext we loop through the data and create a new pandas DataFrame. The DataFrame will have one column for each variable selected above and one row for each downloaded posts.\nIf you are not yet familiar with the concept of dataframes have a look at YouTube, there’s plenty of introductory videos available.\n\nimport pandas as pd\n\nposts = []  # Initializing an empty list for all posts\nfor post in tqdm(json_data):\n  row = {} # Initializing an empty row for the post\n\n  node = post.get(\"node\")\n\n  if username:\n    owner = node.get(\"owner\")\n    row['username'] = owner.get(\"username\")\n\n  if timestamp:\n    row['timestamp'] = node.get(\"taken_at_timestamp\")\n\n  if location:\n    l = node.get(\"location\", None)\n    if l:\n      row['location'] = l.get(\"name\")\n\n  if shortcode:\n    row['shortcode'] = node.get(\"shortcode\")\n\n  if id:\n    row['id'] = node.get(\"id\")\n  \n  if tagged_users:\n    pass\n\n  if caption:\n    c = \"\"\n    emtc = node.get(\"edge_media_to_caption\")\n    edges = emtc.get(\"edges\")\n    for element in edges:\n      caption_node = element.get(\"node\")\n      c = c + caption_node.get(\"text\")\n    row['caption'] = c\n\n  # Finally add row to posts\n  posts.append(row)\n\n# After looping through all posts create data frame from list\nposts_df = pd.DataFrame.from_dict(posts)\n\nNow all information selected above is saved to the dataframe posts_df. Run the next cell and it will return a nicely formatted table. If your data is quite long, output will be cropped. Click the wand and after a few seconds you are able to browse through the data or filter by columns\n\nposts_df\n\nIn order to get a first impression of dataframes, the head() method is also useful. Run the next cell to see the result\n\nposts_df.head()\n\nThe dataframe is only saved in memory, thus when disconnecting and deleting the runtime, the dataframe is lost. Running the next cell saves the table to a CSV-file on your drive.\nNow the processed data may be recovered or used in another notebook.\n\nposts_df.to_csv('{}{}.csv'.format(dest_dir, username))"
  },
  {
    "objectID": "data-collection/ig-posts.html#crowdtangle",
    "href": "data-collection/ig-posts.html#crowdtangle",
    "title": "Instagram Posts",
    "section": "CrowdTangle",
    "text": "CrowdTangle\n\n\n\nScreenshot of the CrowdTangle interface.\n\n\nCrowdTangle is the best option to collect IG posts – in theory. It provides legal access to Instagram data and offers several tools to export large amount of data. For a current project we’ve exported more than 500.000 public posts through a hashtag query. Unfortunately there are several restrictions: CrowdTangle is the best tool to export metadata of public posts, and captions. The abilty to collect images through the platform is limited: Image links expire after a certain amount of time, thus we need to use some makeshift approach to download the images. When we can download the images, it’s always just one per post, no matter if it’s a gallery or a single image. And let’s not talk about videos. I have written another Medium story with a step-by-step guide to CrowdTangle.\n\n\nPros:\n\n\nLegal Access\n\n\nWe can select the time frame for export\n\n\nExport in CSV format\n\n\n\n\nCons:\n\n\nOnly access to one image for album posts\n\n\nLimited access to historical images, the browsing to the bottom strategy is limited\n\n\nNo videos for newer posts"
  },
  {
    "objectID": "data-collection/ig-posts.html#zeeschuimer-4cat",
    "href": "data-collection/ig-posts.html#zeeschuimer-4cat",
    "title": "Instagram Posts",
    "section": "Zeeschuimer & 4CAT",
    "text": "Zeeschuimer & 4CAT\n\n\n\nScreenshot of Zeeschuimer\n\n\nZeeschuimer (Peeters, n.d.) and 4CAT (Peeters, Hagen, and Wahl, n.d.) are two tools developed for the https://wiki.digitalmethods.net/. The first is a firefox plugin that captures traffic when browsing websites likes Instagram or TikTok. The second, 4CAT, is an analysis platform incorporating several steps of preprocessing and further analyses. For post collection we can use the original Zeeschuimer Firefox Plugin, download the latest release from GitHub and install it in Firefox. To download Instagram posts using Zeeschuimer follow these steps (* steps are only necessary when working with 4CAT):\n\nDownload and install Firefox\nDownload and install the Plugin\n*Register a 4CAT Account\nActivate the Instagram (Posts) Switch.\n*Fill out the 4CAT server URL field (https://4cat.digitalhumanities.io/).\nOpen Instagram in a new tab. Browse the profiles you’re interested in. Keep scrolling to the bottom of the profile until you reach posts at the end of your period of investigation.\nDownload the data from the plugin or export the data to 4CAT.\n\n\n\nPros:\n\n\nWe do not infringe the TOS\n\n\nCan collect data from private profiles\n\n\nWe can collect all media, also albums and videos\n\n\n\n\nCons:\n\n\nWe need to browse through the profiles\n\n\nPractical limitations (e.g. volume, timeframe, # of profiles …)\n\n\n\n\n\nWorking with 4CAT\n\n\n\nScreenshot of 4CAT\n\n\n4CAT is a tool developed by the Digital Methods Initiative. The collected data can be exported to 4CAT with only the click of a button. After successfully importing the post data, the tools offers several modules. At first, download the images associated with each post with the Download images module at the bottom. Select image_url in the options tab and hit Run.\n\n\n\nAvailable modules for visual analysis using 4CAT\n\n\nOnce the images have been downloaded more analysis options are available when clicking the More button on the right. Further, you may download images as a ZIP file and can export the posts from 4CAT in CSV format. Repeat the process with the Download Video function to access posted videos. We will be able to use the collected data using the CSV export and the media files provided in the ZIP packages. Additionally, each ZIP file contains a .metadata.json file which we may use to map filenames to media files.\nThe authors of Zeeschuimer and 4CAT have published a manual here.\n\n\nWorking with Python\nData collected using Zeeschuimer can also be exported as ndjson files. The Zeeschuimer Import notebook provides a code example for reading the files and converting them to either 4CAT format, or a table format compatible with the above notebooks for CrowdTangle and instaloader.\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nWe could download multiple images / videos for albums with little refactoring. We will work on an update if necessary."
  },
  {
    "objectID": "data-collection/ig-posts.html#references",
    "href": "data-collection/ig-posts.html#references",
    "title": "Instagram Posts",
    "section": "References",
    "text": "References\n\n\nPeeters, Stijn. n.d. “Zeeschuimer.” https://doi.org/10.5281/zenodo.8399900.\n\n\nPeeters, Stijn, Sal Hagen, and Dale Wahl. n.d. “4CAT Capture and Analysis Toolkit.” https://doi.org/10.5281/zenodo.8139174."
  },
  {
    "objectID": "image-analysis/index.html",
    "href": "image-analysis/index.html",
    "title": "Images as Data",
    "section": "",
    "text": "Within the computational social science community and their neighbouring disicplines, the concept of Images as Data is currently being established (Peng, Lock, and Ali Salah 2023; Joo and Steinert-Threlkeld 2022), equivalent to the Text as Data paradigm. From a Digital Humanities perspective Arnold and Tilton (2023) have developed a concept of Distant Viewing. Both concepts deal with the theory and application of visual analyses using computational methods, with similar very similar ends: as with computational text analyses, computational visual analyses promise to open a new, quantitative, perspective incorporating volumes of data unfeasable for human processing."
  },
  {
    "objectID": "image-analysis/index.html#automated-visual-analysis",
    "href": "image-analysis/index.html#automated-visual-analysis",
    "title": "Images as Data",
    "section": "Automated Visual Analysis",
    "text": "Automated Visual Analysis\nPeng, Lock, and Ali Salah (2023) regard images as data within the context of social media effect studies. Their perspective emphasizes the transformation of visual content into quantifiable insights through computational methods, enabling data-driven analysis. They highlight the application of computer vision and machine learning techniques to analyze various visual elements like color, texture, and object presence. Recognizing the mass of images on social media as rich data sets, they underline the importance of these images for the understanding of trends and cultural shifts in visual communication. However, they also acknowledge the complexities of analyzing images, including the need to understand the context and subtleties they embody. Additionally, they point out the potential of multimodal analysis, which combines text, visual, and audio components, to provide deeper insights into the complex interplay among different communication channels. Furthermore, they emphasize the critical importance of validating prediction, mapping theoretical relevance, and identifying biases in automated visual analysis. Overall, their approach integrates technical analysis with a deep understanding of the cultural and contextual aspects of images as data."
  },
  {
    "objectID": "image-analysis/index.html#distant-viewing",
    "href": "image-analysis/index.html#distant-viewing",
    "title": "Images as Data",
    "section": "Distant Viewing",
    "text": "Distant Viewing\nDistant Viewing, according to Arnold and Tilton (Arnold and Tilton 2023, ch. 1), is a methodology for the computational exploration and analysis of large collections of digital images. This approach is rooted in theories from a range of disciplines, including visual semiotics, media studies, communication studies, information science, and data science. It represents a significant shift from traditional manual methods of image analysis to a more automated, data-driven approach.\nIn their conception, Distant Viewing is not just about the technical analysis of images through computer vision algorithms, but also about understanding and interpreting the cultural, social, and historical contexts of these images. Arnold and Tilton emphasize the importance of structured annotations in this process, as they serve as crucial mediators that help in decoding and interpreting visual data. They advocate for a critical and reflexive approach to the use of Distant Viewing, urging users to be aware of the biases and power dynamics inherent in the way we “look” at images and the technological tools used for this purpose.\nOverall, Distant Viewing as conceptualized by Arnold and Tilton represents a comprehensive framework for the analytical engagement with visual materials, blending computational approach with theory to better understand the visual culture of the digital age."
  },
  {
    "objectID": "image-analysis/index.html#computer-vision-applications",
    "href": "image-analysis/index.html#computer-vision-applications",
    "title": "Images as Data",
    "section": "Computer Vision Applications",
    "text": "Computer Vision Applications\nPeng, Lock, and Ali Salah (2023) list several computer vision applications useful for the analysis of social media in context of communication science. Let’s quickly outline these, with regard to our projects and seminar:\n\nObject Detection\n\nMany models and services return bounding boxes and labels: The bounding boxes are a polygon and its coordinates in relation to the image, the detectable objects are usually defined by a finite list of labels. Knowing about the presence of objects, or counting them, can already serve as a good foundation for classification tasks. Humans are occassionally regarded as objects. We will use object detection for both, exploration and classification.\n\nFace Detection & Matching, Facial Attributes & Emotions\n\nSeveral commercial APIs and open source models offer face detection. Similar to object detection, face detection usually returns a bounding box for each face located in an image. Some models return more landmarks (e.g. left eye, right eye, mouth, …). Advanced systems (e.g. deepface for python) offer to compare faces with one another, by comparing faces on new images with labelled faces in our database, we can calculate the similarity and deduce who is pictured. I have experimented with face detection and matching for analyses in the context of political communication, notebooks and more are available upon request.\n\nText Detection (OCR)\n\nWe have already applied OCR in the Text as Data session. Commercial provides, like Google Vision AI, offer cheap OCR through their API, which is sometimes more useful than setting up your own notebook. In my (limited) experience, the quality between the commercial API and easyocr was very similar.\n\nCaptioning\n\nIs a rather new computer vision application. Using models like vit-gpt2-image-captioning, based on technologies such as CLIP and large language models, we can generate textual description from images. These automated caption can be regarded as text, opening up a world of NLP applications. We will use captioning as an intermediary for image exploration and classification.\n\nAesthetic Analyses & Pose Estimation\n\nWe can automatically measure extract aesthetic features, like dominat colors, or colour themes, of images and use them for downstream tasks. Similarly some technologies can estimate the pose of people or heads. Head positions have, for instance, been used as a proxy to estimate the camera angle in political communication (Haim and Jungblut 2021). I will provide a notebooks for simple colour analyses shortly, however aesthetics and poses are secondary in this semester."
  },
  {
    "objectID": "image-analysis/index.html#summary",
    "href": "image-analysis/index.html#summary",
    "title": "Images as Data",
    "section": "Summary",
    "text": "Summary\nThis brief overview of Images as Data and Distant Viewing in the Computational Social Science and Digital Humanities serves as a theoretical base for the next chapters, Visual Exploration and Visual Classification. Peng, Lock, and Ali Salah (2023)’s paper presents a wide variety of potential methods and tools, additionaly they have a particular perspective of political communication which aligns with several of our projects. Both materials emhasize the gap between theory and the pitfall of mistaking computational analyses for objective analyses, as the annotations used for validation and training of the computational models inherently have biases. Arnold and Tilton (2023)’s chapter is outstanding since they combine interests from the Digital Humanities and Computational Social Science, which reflects the motiviation of this seminar."
  },
  {
    "objectID": "image-analysis/index.html#further-reading",
    "href": "image-analysis/index.html#further-reading",
    "title": "Images as Data",
    "section": "Further Reading",
    "text": "Further Reading\nArnold, T., & Tilton, L. (2023). Distant Viewing: Computational Exploration of Digital Images. MIT Press.\nPeng, Y., Lock, I., & Ali Salah, A. (2023). Automated Visual Analysis for the Study of Social Media Effects: Opportunities, Approaches, and Challenges. Communication Methods and Measures, 1–23. https://doi.org/10.1080/19312458.2023.2277956\nChen, Y., Sherren, K., Smit, M., & Lee, K. Y. (2023). Using social media images as data in social science research. New Media & Society, 25(4), 849–871. https://doi.org/10.1177/14614448211038761\nJoo, J., & Steinert-Threlkeld, Z. C. (2022). Image as data: Automated content analysis for visual presentations of political actors and events. Computational Communication Research, 4(1). https://doi.org/10.5117/ccr2022.1.001.joo\nPeng, Y. (2021). What Makes Politicians’ Instagram Posts Popular? Analyzing Social Media Strategies of Candidates and Office Holders with Computer Vision. The International Journal of Press/Politics, 26(1), 143–166. https://doi.org/10.1177/1940161220964769"
  },
  {
    "objectID": "processing/exploration.html",
    "href": "processing/exploration.html",
    "title": "Data Import",
    "section": "",
    "text": "In the previous session we talked about text as data, suggesting that text data offers a rich source of insights. This chapter concentrates on the advanced tools for exploring these textual dimensions: BERTopic and the Generative Pre-trained Transformer (GPT). These technologies stand at the forefront of computational text analysis and are intersting tools to unlock the meanings and patterns hidden within the vast textual content of social media."
  },
  {
    "objectID": "processing/exploration.html#topic-modeling-with-bertopic",
    "href": "processing/exploration.html#topic-modeling-with-bertopic",
    "title": "Data Import",
    "section": "Topic Modeling with BERTopic",
    "text": "Topic Modeling with BERTopic\n\n\n\nBERTopic (Grootendorst 2022) is a transformer-based topic modeling tool. It uses the BERT (Bidirectional Encoder Representations from Transformers) framework, an advanced method for natural language processing (NLP) that understands the context of words in text. BERTopic is adept at identifying and clustering topics within short text documents Egger and Yu (2022), making it an interesting tool to analyze and categorize text data from social media. The author is actively working on the documentation and keeps improving the topic modeling technique to adapt the latest advances of Large Language Models (LLMs), just recently a Zero-Shot topic modeling approach has been added. I have used BERTopic for a first exploration of stories and posts published by politicians and parties during the 2021 Federal Election in Germany (Achmann and Wolff 2023). Past research has used LDA, another topic modeling algorithm, to explore themes and topics in Instagram posts by politicians (Rodina and Dligach 2019).\n\nFor this example we import a CrowdTangle dataframe, which has been preprocessing using the OCR Notebook. We are only dealing with one image per post, there are no videos (= no transcriptions). In this example, we have up to two text columns per Post, Description which contains the caption, and ocr_text. When exploring the textual content of the posts, we see each of those columns as one document. Thus, we transform our table and create new_df as a Text Table that contains a reference to the post (shortcode), the actual Text, and a Text Type column.\n\nimport pandas as pd\n\ndf = pd.read_csv('/content/drive/MyDrive/2023-11-30-Export-Posts-Crowd-Tangle.csv')\n\nNext, we want to transform the DataFrame from one post per row, to one text document per row (Think tidydata!)\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nAccount\nUser Name\nFollowers at Posting\nPost Created\nPost Created Date\nPost Created Time\nType\nTotal Interactions\nLikes\n...\nPhoto\nTitle\nDescription\nImage Text\nSponsor Id\nSponsor Name\nOverperforming Score (weighted — Likes 1x Comments 1x )\nshortcode\nimage_file\nocr_text\n\n\n\n\n0\n0\nFREIE WÄHLER Bayern\nfw_bayern\n9138\n2023-10-09 20:10:19 CEST\n2023-10-09\n20:10:19\nPhoto\n566\n561\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t51...\nNaN\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nFREIE WAHLER 15,8 %\nNaN\nNaN\n2.95\nCyMAe_tufcR\nmedia/images/fw_bayern/CyMAe_tufcR.jpg\nFREIE WAHLER 15,8 %\n\n\n1\n1\nJunge Liberale JuLis Bayern\njulisbayern\n4902\n2023-10-09 19:48:02 CEST\n2023-10-09\n19:48:02\nAlbum\n320\n310\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t51...\nNaN\nDie Landtagswahl war für uns als Liberale hart...\nNaN\nNaN\nNaN\n1.41\nCyL975vouHU\nmedia/images/julisbayern/CyL975vouHU.jpg\nFreie EDP Demokraten BDB FDP FB FDP DANKE FÜR ...\n\n\n2\n2\nJunge Union Deutschlands\njunge_union\n44414\n2023-10-09 19:31:59 CEST\n2023-10-09\n19:31:59\nPhoto\n929\n925\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t39...\nNaN\nNach einem starken Wahlkampf ein verdientes Er...\nHERZLICHEN GLÜCKWUNSCH! Unsere JUler im bayris...\nNaN\nNaN\n1.17\nCyL8GWWJmci\nmedia/images/junge_union/CyL8GWWJmci.jpg\nHERZLICHEN GLÜCKWUNSCH! Unsere JUler im bayris...\n\n\n3\n3\nKatharina Schulze\nkathaschulze\n37161\n2023-10-09 19:29:02 CEST\n2023-10-09\n19:29:02\nPhoto\n1,074\n1009\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t51...\nNaN\nSo viele Menschen am Odeonsplatz heute mit ein...\nNaN\nNaN\nNaN\n1.61\nCyL7wyJtTV5\nmedia/images/kathaschulze/CyL7wyJtTV5.jpg\nJuo I W\n\n\n4\n4\nJunge Union Deutschlands\njunge_union\n44414\n2023-10-09 18:01:34 CEST\n2023-10-09\n18:01:34\nAlbum\n1,655\n1644\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t39...\nNaN\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nNaN\nNaN\nNaN\n2.34\nCyLxwHuvR4Y\nmedia/images/junge_union/CyLxwHuvR4Y.jpg\n12/12 der hessischen JU-Kandidaten ziehen in d...\n\n\n\n\n\n5 rows × 25 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nWe restructure df to focus on two key text-based columns: ‘Description’ and ‘ocr_text’. The goal is to create a streamlined DataFrame where each row corresponds to an individual text entry, either from the ‘Description’ or the ‘ocr_text’ fields. To achieve this, we first split the original DataFrame into two separate DataFrames, one for each of these columns. We then rename these columns to ‘Text’ for uniformity. Additionally, we introduce a new column, ‘Text Type’, to categorize each text entry as either ‘Caption’ (originating from ‘Description’) or ‘OCR’ (originating from ‘ocr_text’). The ‘shortcode’ column is retained as a unique identifier for each entry. Finally, we concatenate these two DataFrames into a single DataFrame, ensuring a clean and organized structure. This restructured DataFrame facilitates easier analysis and processing of the text data, segregating it by source while maintaining a link to its original post via the ‘shortcode’. The code also includes a step to remove any rows with empty or NaN values in the ‘Text’ column, ensuring data integrity and cleanliness.\n\nimport pandas as pd\n\n# Creating two separate dataframes\ndf_description = df[['shortcode', 'Description']].copy()\ndf_ocr_text = df[['shortcode', 'ocr_text']].copy()\n\n# Renaming columns\ndf_description.rename(columns={'Description': 'Text'}, inplace=True)\ndf_ocr_text.rename(columns={'ocr_text': 'Text'}, inplace=True)\n\n# Adding 'Text Type' column\ndf_description['Text Type'] = 'Caption'\ndf_ocr_text['Text Type'] = 'OCR'\n\n# Concatenating the dataframes\nnew_df = pd.concat([df_description, df_ocr_text])\n\n# Dropping any rows where 'Text' is NaN or empty\nnew_df.dropna(subset=['Text'], inplace=True)\nnew_df = new_df[new_df['Text'].str.strip() != '']\n\n# Resetting the index\nnew_df.reset_index(drop=True, inplace=True)\n\n\nnew_df.head()\n\n\n  \n    \n\n\n\n\n\n\nshortcode\nText\nText Type\n\n\n\n\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\n\n\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\n\n\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\n\n\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\n\n\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nBERTopic\nAt this stage, the data is reading for Topic Modeling. We are using the BERTopic package and follow the tutorial notebook provided by the author.\n\n!pip install -q bertopic\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.1/154.1 kB 3.6 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 25.0 MB/s eta 0:00:00\n  Installing build dependencies ... done\n  Getting requirements to build wheel ... done\n  Preparing metadata (pyproject.toml) ... done\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.9/90.9 kB 12.1 MB/s eta 0:00:00\n  Preparing metadata (setup.py) ... done\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 11.0 MB/s eta 0:00:00\n  Preparing metadata (setup.py) ... done\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 36.3 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 7.3 MB/s eta 0:00:00\n  Building wheel for hdbscan (pyproject.toml) ... done\n  Building wheel for sentence-transformers (setup.py) ... done\n  Building wheel for umap-learn (setup.py) ... done\n\n\nIn the following cells we download a stopword dictionary for the German language and applied it according to the documentation\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\n\nSTOPWORDS = stopwords.words('german')\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=STOPWORDS)\n\nNow we’re ready to create our corpus in docs, a list of text documents to pass to BERTopic.\n\n# We create our corpus\ndocs = new_df['Text']\n\n\nfrom bertopic import BERTopic\n\n# We're dealing with German texts, therefore we choose 'multilingual'. When dealing with English texts exclusively, choose 'english'\ntopic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True, vectorizer_model=vectorizer_model)\ntopics, probs = topic_model.fit_transform(docs)\n\n\n\n\nThe following cells have been copied from the BERTopic Tutorial. Please check the linked notebook for more functions and the documentation for more background information.\n\n\nExtracting Topics\nAfter fitting our model, we can start by looking at the results. Typically, we look at the most frequent topics first as they best represent the collection of documents.\n\nfreq = topic_model.get_topic_info(); freq.head(5)\n\n\n  \n    \n\n\n\n\n\n\nTopic\nCount\nName\nRepresentation\nRepresentative_Docs\n\n\n\n\n0\n-1\n860\n-1_bayern_csu_uhr_mehr\n[bayern, csu, uhr, mehr, menschen, münchen, te...\n[Wir gehen mit #herzstatthetze in den Wahlkamp...\n\n\n1\n0\n137\n0_wählen_fdp_hessen_heute\n[wählen, fdp, hessen, heute, stimme, stimmen, ...\n[Unser Ministerpräsident @markus.soeder steigt...\n\n\n2\n1\n104\n1_energie_co2_klimaschutz_habeck\n[energie, co2, klimaschutz, habeck, wasserstof...\n[Habeck täuscht Öffentlichkeit mit Zensur: Rüc...\n\n\n3\n2\n103\n2_zuwanderung_migration_grenzpolizei_migration...\n[zuwanderung, migration, grenzpolizei, migrati...\n[Wir sagen Ja zu #Hilfe und #Arbeitsmigration,...\n\n\n4\n3\n89\n3_uhr_starke mitte_bayerns starke_bayerns\n[uhr, starke mitte, bayerns starke, bayerns, b...\n[\"Deutschland-Pakt\" aus Scholz der Krise komme...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n-1 refers to all outliers and should typically be ignored. Next, let’s take a look at a frequent topic that were generated:\n\nlen(freq)\n\n52\n\n\nWe have a total of 52 topics\n\ntopic_model.get_topic(0)  # Select the most frequent topic\n\n[('wählen', 0.01628736425293884),\n ('fdp', 0.01626632927971954),\n ('hessen', 0.013634118460503969),\n ('heute', 0.013441948777152065),\n ('stimme', 0.011907460231710654),\n ('stimmen', 0.011505832701270827),\n ('landtagswahl', 0.011272934711858047),\n ('wahlkampf', 0.01059385752962746),\n ('sonntag', 0.01057520846171656),\n ('bayern', 0.010322807358750668)]\n\n\n\nVisualize Topics\nAfter having trained our BERTopic model, we can iteratively go through perhaps a hundred topic to get a good understanding of the topics that were extract. However, that takes quite some time and lacks a global representation. Instead, we can visualize the topics that were generated in a way very similar to LDAvis:\n\ntopic_model.visualize_topics()\n\n\n\n\nVisualize Terms\nWe can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation. Insights can be gained from the relative c-TF-IDF scores between and within topics. Moreover, you can easily compare topic representations to each other.\n\ntopic_model.visualize_barchart(top_n_topics=15)\n\n\n\n\nTopic Reduction\nWe can also reduce the number of topics after having trained a BERTopic model. The advantage of doing so, is that you can decide the number of topics after knowing how many are actually created. It is difficult to predict before training your model how many topics that are in your documents and how many will be extracted. Instead, we can decide afterwards how many topics seems realistic:\n\ntopic_model.reduce_topics(docs, nr_topics=15)\n\n&lt;bertopic._bertopic.BERTopic at 0x794041658ca0&gt;\n\n\n\n\nVisualize Terms After Reduction\n\ntopic_model.visualize_barchart(top_n_topics=15)\n\n\n\n\nSaving the model\nThe model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved.\n\n# Save model\ntopic_model.save(\"/content/drive/MyDrive/2023-12-01-LTW23-CrowdTangle-Posts-model\")\n\n\n\nSource: Topic Modeling Using BERTopic"
  },
  {
    "objectID": "processing/exploration.html#extracting-topics",
    "href": "processing/exploration.html#extracting-topics",
    "title": "Data Import",
    "section": "Extracting Topics",
    "text": "Extracting Topics\nAfter fitting our model, we can start by looking at the results. Typically, we look at the most frequent topics first as they best represent the collection of documents.\n\nfreq = topic_model.get_topic_info(); freq.head(5)\n\n\n  \n    \n\n\n\n\n\n\nTopic\nCount\nName\nRepresentation\nRepresentative_Docs\n\n\n\n\n0\n-1\n860\n-1_bayern_csu_uhr_mehr\n[bayern, csu, uhr, mehr, menschen, münchen, te...\n[Wir gehen mit #herzstatthetze in den Wahlkamp...\n\n\n1\n0\n137\n0_wählen_fdp_hessen_heute\n[wählen, fdp, hessen, heute, stimme, stimmen, ...\n[Unser Ministerpräsident @markus.soeder steigt...\n\n\n2\n1\n104\n1_energie_co2_klimaschutz_habeck\n[energie, co2, klimaschutz, habeck, wasserstof...\n[Habeck täuscht Öffentlichkeit mit Zensur: Rüc...\n\n\n3\n2\n103\n2_zuwanderung_migration_grenzpolizei_migration...\n[zuwanderung, migration, grenzpolizei, migrati...\n[Wir sagen Ja zu #Hilfe und #Arbeitsmigration,...\n\n\n4\n3\n89\n3_uhr_starke mitte_bayerns starke_bayerns\n[uhr, starke mitte, bayerns starke, bayerns, b...\n[\"Deutschland-Pakt\" aus Scholz der Krise komme...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n-1 refers to all outliers and should typically be ignored. Next, let’s take a look at a frequent topic that were generated:\n\nlen(freq)\n\n52\n\n\nWe have a total of 52 topics\n\ntopic_model.get_topic(0)  # Select the most frequent topic\n\n[('wählen', 0.01628736425293884),\n ('fdp', 0.01626632927971954),\n ('hessen', 0.013634118460503969),\n ('heute', 0.013441948777152065),\n ('stimme', 0.011907460231710654),\n ('stimmen', 0.011505832701270827),\n ('landtagswahl', 0.011272934711858047),\n ('wahlkampf', 0.01059385752962746),\n ('sonntag', 0.01057520846171656),\n ('bayern', 0.010322807358750668)]\n\n\n\nVisualize Topics\nAfter having trained our BERTopic model, we can iteratively go through perhaps a hundred topic to get a good understanding of the topics that were extract. However, that takes quite some time and lacks a global representation. Instead, we can visualize the topics that were generated in a way very similar to LDAvis:\n\ntopic_model.visualize_topics()\n\n\n\n\nVisualize Terms\nWe can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation. Insights can be gained from the relative c-TF-IDF scores between and within topics. Moreover, you can easily compare topic representations to each other.\n\ntopic_model.visualize_barchart(top_n_topics=15)\n\n\n\n\nTopic Reduction\nWe can also reduce the number of topics after having trained a BERTopic model. The advantage of doing so, is that you can decide the number of topics after knowing how many are actually created. It is difficult to predict before training your model how many topics that are in your documents and how many will be extracted. Instead, we can decide afterwards how many topics seems realistic:\n\ntopic_model.reduce_topics(docs, nr_topics=15)\n\n&lt;bertopic._bertopic.BERTopic at 0x794041658ca0&gt;\n\n\n\n\nVisualize Terms After Reduction\n\ntopic_model.visualize_barchart(top_n_topics=15)\n\n\n\n\nSaving the model\nThe model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved.\n\n# Save model\ntopic_model.save(\"/content/drive/MyDrive/2023-12-01-LTW23-CrowdTangle-Posts-model\")"
  },
  {
    "objectID": "processing/exploration.html#exploration-through-prompting",
    "href": "processing/exploration.html#exploration-through-prompting",
    "title": "Data Import",
    "section": "Exploration Through Prompting",
    "text": "Exploration Through Prompting\n\n\nUsing GPT for Information Extraction\nThe focus of this chapter lies in demonstrating how GPT can be employed in a loop to analyze text documents. This methodology aligns with the principles of topic modeling but extends further by leveraging the advanced capabilities of the language model. Our approach involves the iterative processing of text, where GPT aids in identifying, categorizing, and interpreting the underlying themes and sentiments expressed in social media texts.\nThe GPT application presents a significant difference compared to traditional topic modeling. While topic modeling often aims to automatically uncover hidden thematic structures within a text corpus, our approach with GPT is based on a different assumption: We presuppose that there is already a specific theme or a particular question in mind according to which we want to organize and analyze the documents. This approach allows us to navigate through the vast amounts of text in social media in a targeted and efficient manner, identifying specific insights and patterns that are directly related to our predefined areas of interest.\nThe following workflow outlines how we could use this information extraction process to create a topic list. Using the list we can classify each document.\n\n\n\nAn example for a GPT based “Topic Modeling” approach. I have used this approach in a current research project, the process is not perfect yet.\n\n\n\n!pip install -q openai backoff gpt-cost-estimator\n\n\n\nSetup for the OpenAI API\nWe’re using the new Colab Feature to store keys safely within the Colab Environment. Click on the key on the left to add your API key and enable it for this notebook. Enter the name fpr your API-Key in the api_key_name variable below.\n\nimport openai\nfrom openai import OpenAI\nfrom google.colab import userdata\nimport backoff\nfrom gpt_cost_estimator import CostEstimator\n\napi_key_name = \"openai-lehrstuhl-api\"\napi_key = userdata.get(api_key_name)\n\n\n# Initialize OpenAI using the key\nclient = OpenAI(\n    api_key=api_key\n)\n\n\n\n@CostEstimator()\ndef query_openai(model, temperature, messages, mock=True, completion_tokens=10):\n    return client.chat.completions.create(\n                      model=model,\n                      temperature=temperature,\n                      messages=messages,\n                      max_tokens=600)\n\n# We define the run_request method to wrap it with the @backoff decorator\n@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APIError))\ndef run_request(system_prompt, user_prompt, mock):\n  messages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": user_prompt}\n  ]\n\n  return query_openai(\n          model=\"gpt-3.5-turbo-0613\",\n          temperature=0.0,\n          messages=messages,\n          mock=mock\n        )\n\nNext, we create a system prompt describing what we want to extract. For further examples of prompts and advice on prompt engineering see e.g. the prompting guide and further resources linked at the bottom of the page.\nFor the initial example we use social media content shared by politicans and parties. We know, that some of these texts mention policy issues, let’s try to extract these issues across all documents.\nNote: The extracted issues are not going to be consistent, because each document is sent as a singular request to the API, thus the previous issues are not going to be used as context.\nModify the following system prompt to extract other types of information. What else could you extract?\n\nLocations (based on names)\nNames (of persons or places)\nMentions of Companies\n…\n\nDo not forget the Prompt Archive when experimenting. Share your successfull prompt with us!\n\nsystem_prompt = \"\"\"\nYou are a helpful assistant, an expert for German politics.\n**Objective:** Extract policy issues from German language social media texts. Policy issues refer to specific topics or subjects that are the focus of public or governmental debate, analysis, and decision-making. Elections themselves and party slogans or their performance are no policy issues.\n**Instructions:** Return each policy issues referenced in user message as a comma-seperated list. Return 'None' if no policy issues are referenced.\n**Formatting:** Return a comma-seperated list.\n\"\"\"\n\n\n\nRunning the request.\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI! Make sure ‘run_request’ and ‘system_prompt’ are defined before this block by running the two blocks above!\nSet the following variables:\n\nMOCK: Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nRESET_COST: Do you want to reset the cost estimation when running the query?\nCOLUMN: What’s the column name to save the results of the data extraction task to?\nSAMPLE_SIZE: Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\n\n\nfrom tqdm.auto import tqdm\n\nMOCK = True\nRESET_COST = True \nCOLUMN = 'Policy Issues'\nSAMPLE_SIZE = 0 \n\n# Initializing the empty column\nif COLUMN not in new_df.columns:\n  new_df[COLUMN] = None\n\nif RESET_COST:\n  # Reset Estimates\n  CostEstimator.reset()\n  print(\"Reset Cost Estimation\")\n\nfiltered_df = new_df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df['Policy Issues'])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        response = run_request(system_prompt, row['Text'], MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n\n          # Convert the string 'r' to a list if it's not 'None', otherwise keep it as None\n          if r != 'None':\n              r = r.split(', ')\n          else:\n              r = None\n\n          # Update the 'new_df' DataFrame\n          new_df.at[index, 'Policy Issues'] = r\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\n\n\n\n\n\n\n# Save Results\nnew_df.to_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\nNext we create a set of Policy Issues. Sets are similar to lists in that they are used to store multiple items, but each unique item in a set appears only once, regardless of how many times it is added, as sets inherently enforce uniqueness and do not allow duplicates. Unlike lists, sets are unordered, meaning they do not record element position or order of insertion. This property makes sets highly efficient for checking membership and eliminating repeated entries. We create the list policy_issues to generate a word cloud.\n\nunique_policy_issues = set()\npolicy_issues = []\n\nfor issues in new_df['Policy Issues']:\n    if issues is not None:\n        unique_policy_issues.update(issues)\n\n        for issue in issues:\n            policy_issues.append(issue)\n\nprint(unique_policy_issues)\n\n{'faires Verfahren', 'Straßen', 'EU-Kommission', 'Zusammenhalt unserer Gesellschaft', 'migrationswende', 'bayernliebe', 'Thema Migration nicht unkontrolliert weiterlaufen lassen', 'Sprache', 'FREIHEITfürBayern', 'Freistaat Bayern', 'rezession', 'Hilfe', 'Mehrwertsteuer', 'tv', 'Lügen', 'Bayern stark und stabil bleibt', 'Baumfreiflächen', 'BAföG-Höchstsatz', 'Online Antrag', 'Zurückweisungen an Binnengrenzen', 'Autoverbot', 'wohnungskonzerne enteignen', 'Infrastrukturausbau', 'Reformierbarkeit des öffentlich-rechtlichen Rundfunks', 'bayerische Antidiskriminierungsstelle', 'Baden-Württemberg', 'Strompreiszonen', 'Streit und Chaos', 'linke Inhalte', 'Soldatenberuf', 'bezahlbare Energie', 'Verkaufszahlen bei Heizungssystemen', 'Forschung und Entwicklung', 'Ölheizungen', 'Situation an den Aussengrenzen', 'Leitungen', 'Verbotsorgien', 'Kriminalität', 'CDU/CSU', 'Sprachen und Kultur', 'deutsche Universität', 'bezahlbares Bayern für alle', 'Souveränität', 'wiedervereinigung', 'Landwirte', 'Rechtsstaat', 'moderne Lernumgebung', 'Iran', 'Hebammen', 'Tierschutz', 'Baumwipfelpfad', 'politische Einflüsse', 'bayrisches Brauchtum', 'Mitbestimmung', 'Linksextremisten', 'landtagbayern', 'BayernsOpposition', 'ddr', 'ltw', 'Parteidisziplin', 'Planungs- und Genehmigungsprozesse', 'Wirtschaft fördern', 'Energiepreis', 'Personalschlüssel', 'Bestandsgebäude', 'gleichwertige Lebensverhältnisse', 'Energiepreise', 'Sparen', 'bezahlbarer Wohnraum für alle', 'Jugendzentren', 'Wassersparen', 'niedrigere Standards', 'Sorgen und Nöte', 'Migrationswende', 'junge Männer', 'Haus- und Fachärzte', 'Landwirtschaftspolitik', 'unserezukunft', 'Faschist*innen', 'wegenmorgen', 'konservative Werte', 'innenminister', 'Politik', 'Bundeswehr', 'Startchancen für Kinder', 'Kulturlandschaft', 'umsteuern', 'Klimaschutzziele erreichen', 'Führerscheinrichtlinie', 'Kita-Betreuungsplätze', 'politischer Wechsel', 'Kaufnebenkosten', 'Obergrenze für Bargeldzahlungen', 'heimatliebe', 'Zivilist*innen', 'Glaubwürdigkeit', 'Mehrwertsteuer für die Gastronomie', 'unkontrollierte Zuwanderung', 'LOSvonBerlin', 'Anti-Atom-Ideologie', 'Ausbau der Erneuerbaren Energien', 'Mehr Platz für das Rad und die Öffis', 'Biodiversität', 'linke Medien', 'afdwählen', 'Sozialwohnungen', 'bayerischerlandtag', 'Grenzen', 'Migrationskatastrophe', 'rechtsradikale Parteien', 'Ego-Show', 'Bildungswende', 'Fach- und Ergänzungskräfte', 'Terroristen der Hamas', 'anpackenstattankleben', 'Nachtfahrverbot', 'unsereverantwortung', 'illegale Einwanderung', 'Hotel', 'erfolg', 'Deutschlandticket', 'Unterschleißheim', 'Wirtschafts- und Standortpolitik', 'Startchancen-Programm', 'Personal- und Sachmittel', 'Landtag Bayern', 'Grenzschutz', 'Dampfheizkraftwerk', 'Geflüchtete', 'Bayernpartei', 'Exportwirtschaft', 'Rechte der Bürger', 'Zivilgesellschaft', 'Ernsthaftigkeit', 'BürgerlicheMitte', 'pseudowissenschaftliche Gender-Ideologie', 'sichere Herkunftsstaaten', 'haustürwahlkampf', 'Bayern lebt es sich einfach besser', 'Wahlklatsche', 'Mittelstand', 'Diesel', 'Förderkürzungen', 'Deutschlandpakt', 'Stigmatisierung', 'Befreiung land- und forstwirtschaftlicher Fahrzeuge von der KfZ-Steuer', 'Mobilitätsmix', 'Innere & transnationale Sicherheit', 'LOSvonRom', 'Hetze', '8Oktober', 'MINT-Fächer', 'Stillstand', 'Beteiligung', 'Bevormundung aus Berlin', 'Finanzierungen', 'Technologieoffenheit bewahren', 'illegale Migration', 'islamistischer Terror', 'Auto-Verbot', 'oberfranken', 'Ampel-Regierung', 'GesunderMenschenverstand', 'Perspektiven', 'Arztsitze', 'Terrorangriffe der Hamas auf Israel', 'SPD', 'Bau einer weiteren Betonpiste', 'Bezirksvorsitzender für Unterfranken', 'sommertour', 'Sach- statt Geldleistungen', 'deutschegeschichte', 'ehrenamt', 'Sprachfeststellungstests', 'Klarheit bei Heizungsgesetz', 'opposition', 'bayerischen Steuerzahler entlasten', 'Kinderbetreuung', 'stationäre Versorgung', 'Überforderung', 'LTWBayern', 'Selbstbestimmungsgesetz', 'Interessen', 'landespolitische Fragen', 'Ausländer', 'Unternehmenssteuern', 'CO2-Maut für LKW', 'Öffentlich-rechtlicher Rundfunk', 'Bezirkstage', 'missionunion', 'Abgabe', 'Weltoffenheit', 'Waldbauern', 'Elster Zertifikat', 'Hohenwart', 'Meinungen aus', 'Terrororganisation', 'Aufbaugeneration', 'rechtskonform', 'Meisterausbildung', 'digitale Strategie', 'wichtige Themen', 'energiewende', 'Briefwahl', 'Umweltschutz', 'christlich', 'Kaputt gesparte Kommunen', 'Lebensmittel- und Energiepreise', 'kommende Wahlen', 'Chancengerechtigkeit', 'Entlastung', 'Geldleistungen', 'Bezahlbare Wohnungen und faire Mieten für 7 Mio. Mieter', 'Unterstützung', 'Wirtschaftswachstum', 'Heizungsverbote', 'Haushaltspolitik', 'jüdischer Staat', 'Wasserstoff-Region', 'Flurneuordnung', 'eigene Zukunft', 'Fachkräfte', 'Kontrolle', 'Biomassedeckel', 'Verkehr', 'Mehrwertsteuer auf Grundnahrungsmittel', 'Zuwanderung', 'Zahnsanierungen', 'soziale Leistungen', 'Entwicklungshilfe', 'Benachteiligungen des ländlichen Raums', 'Digitale Bildung', 'Chancenbereitung', 'Abschiebung', 'Einfluss der ideologisierten und politisierten „Klimaforschung“', 'LosvonBerlin', 'Tanz', 'Unterstützung für Familien', 'Weltsicht', 'Kahlschlag in der Krankenhauslandschaft', 'Heizgesetz', 'Klimasparbuch', 'Zahnarzt', 'grundsatzprogramm', 'Städten', 'Steuergeschenke für Konzerne', 'Gesundheitspolitik', 'steuerliche Entlastungen', 'Anpacken', 'Wiedereinzug in den Bayerischen Landtag', 'Teamgeist', 'Numerus Clausus', 'Inklusion', 'Verteidigungspolitik', 'Heimatliebe', 'ausrüsten', 'Ehrenamtlicher Einsatz', 'gefährdungslage', 'Gender', 'Beschränkungen der Bargeldnutzung', 'Stabilität', 'München', 'Dr. Markus Büchler', 'bevormundung', 'selbstbestimmtes Europa', 'Asylbewerberleistungsgesetz', 'wirtschaftspolitik', 'Waldstilllegungen', 'beschränkt gültiger Führerschein ab 60', 'Bayerns Wälder', 'Gräuel', 'Abschieben', 'islamistischer Terror der Hamas', 'Arbeit', 'MWST in der Gastronomie', 'bezahlbar', '8. Oktober', 'Katastrophenschutz', 'Nahverkehrsangebote', 'Mitmach-Aktionen', 'zivilgesellschaftliche Kräfte', 'Fernsehbosse', 'Brenner-Nordzulauf', 'Einigkeit', 'Gewalt', 'Parteiarbeit', 'Abtreibungen', 'Tanken', 'Privateigentumsschutz', 'politische und gesellschaftliche (Fehl-)Entwicklungen', 'Expertenkommission', 'Bayern selbst entscheiden können', 'Ideen', 'aktueller Rechtsruck', 'Asyl-Lobbyisten', 'Biotechnologie', 'starke Stimme', 'Klimaschutz', 'Kontoverbindung', 'bezahlbares Wohnen', 'bürgerliche Koalition', 'Klimawandel', 'Migranten', 'ungewollt schwangere Frauen', 'NGO', 'zeitgemäße Führung', 'gewöhnlicher Aufenthalt', 'Tourismus', 'Bürger', 'Interessen Italiens', 'Terror', 'Mietpreissteigerungen', 'Impfzwang', 'Batteriespeicher', 'Kahlschlag', 'Lärm', 'frühzeitiges Erlernen der deutschen Sprache', 'Bayern liebt', 'internationale Gemeinschaft', 'Maximilianeum', 'EUCH bewegen', 'Ausbildungsreform für die Kinderpflege', 'innovative Bauverfahren', 'Ehrenamt', 'Bildungsoffensive für Deutschland', 'antisemitische Sachverhalte', 'wirtschaft', 'Zusammenarbeit mit dem Regime', 'Pharmazie', 'mittelfranken', 'Abschiebungen', 'Ampel-Chaos', 'gesellschaftliche Unterstützung', 'Frieden in Europa', 'Übernahme nach dem Studium', 'Stimmung gegenüber Geflüchteten', 'Miete', 'Natur erhalten', 'Familien mit Kindern', 'BayernZuerst', 'Bezahlbare Wohnungen und faire Mieten', 'Mitarbeitenden', 'digitale Beantragung', 'Opfer rechter Gewalt', 'Wasserversorgung', 'Pflegegeld', 'Wohnungsoffensive', 'FürDieZukunft', 'Gesetz', 'praktische Übungsstunde', 'Verkehrsträger', 'Ideologiefreiheit an den Hochschulen', 'Jugendparlament', 'neonazistische Gruppen', 'Hessenweiterführen', 'Fahrverbote', 'Sachleistungen', 'Rechtsrutsch', 'Schutz vor Gefahren', 'Landwirtinnen', 'CO2-Bepreisung', 'Modlareuth', 'Bayernwahl', 'Weniger Bürokratie und eine digitale Verwaltung', 'Petition', 'Herausforderungen unserer Zeit', 'deutsche Richterbund', 'ltwby23', 'Klimafreundliches Heizen', 'Kunst', 'zweite Legislatur', 'Gesundheitswesen', 'H2-Heizung', 'Künstliche Intelligenz', 'Universität', 'Migrationsabkommen', 'E-Fuels', 'Politiker', 'bayerische Städtebauförderung', 'Rassismus', 'wählherzstatthetze', 'Länderfinanzausgleich reformieren', 'Medizin', 'Krimbrücke', 'landtagswahl', 'Wasserstoff massiv ausbauen', 'Führerschein für schwere PKWs', 'demokratische Werte', 'politisch Verfolgte', 'Verantwortung', 'Grenzpolizei', 'Leistung', 'Gute Pflege', 'recht', 'Leistungen', 'grüne Klimakonto', 'Ärmsten der Bevölkerung', 'gute Schulen', 'Geflüchtetenpolitik', 'Soldatischer Dienst', 'Stolz', 'Elterngeld', 'regionale Spezialitäten', 'soziale Sicherheit', 'klare Positionen', 'LKW', 'eigenständiges Fahren ab 16 Jahren', 'Bayerns Opposition', 'Klimakollaps', 'Tempolimit', 'einheit', 'CO2-Bilanz', 'heimat', 'friedliches Europa', 'EU-Außengrenzen', 'Grünen', 'Glasindustrie', 'ErbschaftsteuerAbschaffen', 'pro-palästinensische Terrororganisationen', 'Finanzierung', 'Umwelt', 'Schutz von Jüdinnen und Juden', 'Krankenhausreform', 'EU-Eliten', 'Windkraftausbau', 'DIELINKE', 'Bildungs- und Betreuungseinrichtungen', 'Einheimische Bevölkerung', 'steigende Mieten', 'Kostenlosen und ticketfreien ÖPNV', 'kleidung', 'Wochenmarkt', 'Verantwortungsvolle Regierung', 'unabhängige Justiz', 'Solarenergie-Anlage für Balkon oder Dach', 'Pflege', 'Hürden', 'Mehrwertsteuer auf Speisen in der Gastronomie', 'kathaunterwegs', 'Motor für Deutschland und Europa', 'Integration', 'Lehrstühle', 'Wiedervereinigung', 'Männern und Kindern in Israel', 'Asylrecht aushöhlen', 'Bildungsangebote von Verbänden', 'kostenloser Nahverkehr', 'Hürden für den Führerscheinerwerb', 'individuelle Mobilität', 'Halbzeitbilanz der Ampel', 'Gewerbe', 'Planungshoheit der Länder', 'Riedenburg', 'Gebäudeenergiegesetz', 'ökonomie', 'Diskriminierung bei Nichtverwendung der „Gendersprache“', 'Aiwanger', 'Sonderaufnahmeprogramme', 'Landtagswahlen', 'Taurusmarschflugkörper', 'Partei der Mitte', 'frühkindliche Bildung', 'Geiseln', 'Mobilität für alle', 'Vergesellschaftung großer profitorientierter Wohnungskonzerne', 'Apotheke', 'politische Bildung', 'Landräte', 'Wirtschaftlichkeit', 'Absenkung der Mehrwertsteuer', 'Ökomodellregionen', 'Leichenmisshandlung', 'Rückführungsabkommen', 'Unsicherheiten für Studierende', 'Sympathiekundgebungen für den Terror in Israel', 'bayerischerrundfunk', 'Corona-Bußgelder', 'Parteien', 'Dorferneuerung', 'Kernfusion', 'Werte', 'Krankenhausversorgung auf dem Land', 'Sauerlach', 'Bürgerinteresse', 'Bayern wird Wasserstoffland Nummer 1', 'Krankenhäuser', 'mauerfall', 'Genehmigungsprozesse', 'Schwarz-Grün', 'Atomkraftwerken', 'Hofsterben', 'Ausländer-Gewalt', 'Versorgung', 'Drittstaatsangehörige', 'Festung Europa', 'Unterfranken', 'Heimat', 'natürlicher Rohstoff Holz', 'Lösungen', 'Abgabelast pro gefahrenen km', 'gegen grüne Ideologie', 'Gegenpositionen zum herrschenden Zeitgeist', 'Hilfe und Arbeitsmigration', 'Sitzen bleiben', 'Familienbetriebe stärken', 'Landtagskandidat*innen', 'fossile Energieträger', 'europäische Regelung', 'CSU-Versprechen im Wahlkampf', 'palästinensische Terroristen', 'Grüne', 'Klimakonto', 'Menschenrechtsverletzungen', 'Verkehrsbelastung', 'autoritäre Gesundheitspolitik', 'Israel', 'wirtschaftliche Entwicklung des Freistaates', 'staatliche Verwaltung', 'tradition', 'gestiegene Kosten für Heizung', 'Zukunftsvertrag zur Landwirtschaft in Bayern', 'Kürzungshammer', 'Soziale Politik', 'grüne', 'Maghreb-Staaten', 'Förderrunde', 'gesellschaftliches Wohlergehen', 'Bewusstsein', 'Gewinnung von Arbeits- und Fachkräften', 'Bandenkriminalität', 'Stellenabbau', 'Fördergelder', 'Pflegeversorgung in der Heimat sicherstellen', 'Richtungsentscheidung', 'bezahlbare Wohnungen', 'Gelder für Freiwilligendienste', 'bayerische Volkspartei', 'Geburtsstationen', 'landtag', 'Bayerntour', 'konsequente Rückführung krimineller Straftäter', 'Gesundheitsversorgung', 'Bus und Bahn', 'Schweden', 'Regeln', 'kostenlose Kitas', 'Wahl am 8.10.', 'bayerische Grenzpolizei', 'Populistische Politik', 'Klimakleber', 'Leichenschändigung', 'vereint', 'EU-Sanktionen', 'Innere Sicherheit', 'konservative Opposition', 'Breitbandversorgung', 'Lebensqualität', 'Ausbildungskosten', 'bezahlbarkeit', 'Vertrauen in demokratische Institutionen', 'Minderheit im eigenen Land', 'Wasserstoffdrehkreuz', 'CO2-Preis', 'Erdgasheizungen', 'Erbschaftsteuer', 'Abkommen', 'landtagswahlen', 'Mobilfunk', 'Fakten', 'Lebensverhältnisse', 'Bayernliebe', 'DRG-Fallpauschal-Finanzierung abschaffen', 'Parteivorsitzende', 'Demokrat*innen', 'Demonstranten', 'Investition in Ausstattung der Schulen', 'EU stoppen', 'russischer Angriffskrieg gegen die Ukraine', 'politische Gefangene', 'FREIHEITfürBAYERN', 'Wirtschaftspolitik', 'Forschung an KI', 'gebührenfreie Kitas', 'Gesundheit', 'Familienpolitik', 'Ideologie', 'Handeln', 'Jugend', 'Rechtsstaatlichkeit', 'Startchancen', 'sinkender Strompreis', 'kostenfreie Bildung', 'Forschung', 'Gefahrenstellen', 'Schule und Berufsleben', 'Kommunen', 'Haft', 'Schlaganfall-Versorgung', 'straffällig', 'Heizungsgesetz', 'Grenze', 'ltwby', 'Selbstbestimmung', 'Geld', 'tagderdeutscheneinheit', 'ländliche Räume', 'Respekt', 'Bürgerenergie-Genossenschaften', 'Antisemitismus', 'EU-Asylkompromiss', 'Automobilindustrie', 'Markus Söder und die CSU', 'Immobilienhaie', 'Kandidierenden', 'Sanierungsbedarf', 'Kurs', 'Vernichtung', 'Wissenschaft', 'Kitaplätze', 'Wirtschafts- und Sozialpolitik', 'Rente', 'EWERG eG', 'Grüne raus aus der Regierung', 'Strompreise von Umlagen und Steuern', 'Arbeitsvertrag', 'Politik für die eigenen Leute', 'PolitikFürUnsereZukunft', 'Beseitigung von Weltraumschrott', 'Rundfunkrat', 'künftige Generationen', 'GEAS', 'Bezahlung in der Pflege', 'Spaltung', 'Verbeamtung', 'international', 'nürnberg', 'Strompreise', 'faire Bezahlung von Pflegekräften', 'rechte Politik', 'Wirtschaftszweig', 'Kandidatinnen und Kandidaten', 'Satellitendaten', 'Verkehrsentlastung', 'Nationaler Sicherheitsrat', 'begleitetes Fahren', 'starkes und bezahlbares Bayern', 'Migrationspolitik', 'NGOs', 'Umwidmung von Parkplätzen', 'heimische obst- und nahrungsmittel', 'Seenotrettung', 'Betonfundamente', 'CSU', 'Technologie-Offenheit', 'Datenschutz', 'öffentlich-rechtlichen Medien', 'Erhalt der heimischen Lebensmittelproduktion', 'politikmitverstand', 'Landwirtschaft', 'Nationale Raumfahrtstrategie', 'Hightech', 'Arbeitslosenquote', 'Artenvielfalt', 'Kassenleistungen', 'Wirtschaft', 'Wohlstand', 'PIN', 'Zukunftskurs', 'einheitliche Regelungen', 'EU', 'Wohnung', 'staatliche Betriebskostenförderung', 'neoliberale Wirtschafts- und Finanzpolitik', 'antisemitische Einstellungen', 'Lebensmittel', 'Dorfentwicklung', 'Wasserstoff', 'CO2-Bindung', 'Biomasse', 'handlungsfähiger Staat', 'Vergütung', 'starke Bildungspolitik', 'Judenhass', 'Privatsphäre', 'Wasserstoff-Tankstelle', 'Schienen', 'sauberes und bezahlbares Zuhause', 'Geschichte', 'bayerisches Familiengeld', 'Betriebskostenförderung', 'gemeinnützige Arbeit', 'LTWBy', 'Lärmschutz', 'Förderung von Ideen zur Verbesserung von Unterricht und Schule', 'Elektrolyseur', 'Kostenlose Kitas', 'versorgungsrelevant', 'WHO', 'HolDirDeineZukunftZurück', 'Rundfunkbeitrag', 'Photovoltaik', 'Gemeinschaftsschule', 'Mieten', 'Bau- und Wohnwirtschaft', 'Energie', 'Abgase', 'Wissenschaftsfreiheit', 'Terror der Hamas', 'BAföG Reform', 'Gedichte', 'Machen statt Niedermachen', 'Hüterin der Bürgerrechte', 'Chancen', 'Tariftreue-Paket', 'flächendeckende Notfallversorgung', 'Umweltfreundliche Mobilitätsformen stärken', 'Kliniken', 'Bildungssystem', 'Feindbilder', 'Landes-Antidiskriminierungsgesetz', 'Radio', 'Abrechnung der Arztkosten', 'Anmaßungen des EuGH', 'Eigentum', 'Eltern- und Schüler*innenvertretungen', 'Windkraft', 'Senioren', 'Ungleichheit', 'Liberalismus in Europa', 'Ausbau des mobilen Internets', 'Lauterbach', 'Abwehr dieses Terrorangriffs', 'Politik für Leistung und Eigentum', 'teambayern', 'Verbindungsachsen', 'exzellente Ausbildung', 'Demokratie-Dialog', 'Wasserstoffnetz', 'krise', 'Wohnraum', 'politik', 'Energieversorgung', 'Eigentum in Familienbesitz schützen', 'FreistaatBayern', 'praktische Berufe', 'Werkswohnungen', 'Europawahl 2024', 'Quiz-Spiel', 'Nancy Faeser', 'GemeinsamStark', 'Haft für Schutzsuchende', 'Ordnung und Sicherheit', 'Lieferung von schweren Waffen', 'Biotech-Standort', 'Grenzschutzoffensive Bayern', 'sittenwidrig', 'Energiewende', 'Abhängigkeit vom Ausland', 'Arbeit im Rentenalter', 'Engagement für Demokratie', 'queere Menschen', 'Holzwachstum', 'Durchforstungsholz', 'Ingolstadt', 'Pflegekrise', 'Grundnahrungsmittel', 'Versorgungssicherheit', 'attraktive Bedingungen für deutsche Weltraumunternehmen', 'Bildungspolitik', 'Effizienz', 'Straßengroßprojekt', 'Demoskopen', 'Mutter', 'LTW', 'linke', 'Pflegegesellschaft', 'Rechtsterrorismus', 'Hass und Hetze', 'Kartellamt', 'Zwang', 'Rundfunkgebühren abschaffen', 'Arbeitsmarktpolitik', 'Merz', 'Patient', 'Partei', 'Krisen', 'GRÜN', 'heimatmitherz', 'Frieden', 'bürokratischer Mehraufwand', 'Netto', 'bezahlbare Lebensmittel', 'Desinformation', 'Schulen', 'bildungsgerechtigkeit', 'Freilassung aller Geiseln', 'Oberbayern', 'MedizinischeVersorgung', 'Energie-Mix', 'Lebenshaltungskosten', 'Postleitzahl', 'Geothermie', 'Bayern', 'Wirtschaftsfreundlichere Rahmenbedingungen', 'starke Wirtschaft und bezahlbare Energie', 'regierung', 'geschichte', 'Wille', 'Europawahlen', 'ltw2023', 'Anstalten', '2023', 'Lieferkettengesetz', 'Verwaltung', 'Bildung und Forschung', 'sexuelle Gewalt', 'HerzStattHetze', 'Manifest für Freiheit in Europa', 'Fremdbestimmung', 'Steuersenkungen', 'Menschen in Israel', 'Schwaben', 'rechte Gewalt', 'Mietpreisbremse', 'würdevoll', 'EnergiewendeMitVerstand', 'Ländlichen Raum stärken', 'CDUParteitag', 'Zukunftsvertrag für die Landwirtschaft', 'DeineStimmeZählt', 'Gegenwehr gegenüber einer übergriffigen EU-Bürokratie', 'Bruder', 'freistaatbayern', 'Bürgergeldreform', 'Familie', 'ständige Hetze von Söder', 'Förderung innovativer Start-ups', 'demokratie', 'Wärmewende', 'rechte Szene', 'gute Pflege', 'Friedensbewegung', 'Windräder', 'Prinzipien', 'Tätern', 'Verbindungen', 'Sturm', 'Tauruslieferung', 'Kernkraft', 'Kleinkrafträder', 'soziale Gerechtigkeit', 'Hass und Antisemitismus', 'Drogenlegalisierung', 'einigkeit', 'klimaschutz', 'radikale Bewegungen in Österreich und Deutschland', 'wiederverwenden', 'Familien', 'Mangel an Kita- und Pflegeplätzen', 'Kraft der Vernunft', 'faire Mieten', 'Land Israel', 'Region', 'Rundfunk', 'Heizungspolitik', 'Migrationskrise', 'DIE LINKE', 'Sozialepolitik', 'Wohnungsbau', 'Flüchtende', 'Bewirtschaftete Wälder', 'gute Löhne', 'Ganztagsplätze', 'sicherer Strom', 'Grenzen kontrollieren', 'Gegenrechts', 'Chatkontrolle', 'Technologieoffenheit', 'Menschen in Armut', 'Weiden', 'Förderung des Ökolandbaus und der Biologischen Vielfalt', 'Europäische Staaten', 'Innenministerin Faeser', 'Zugangscode', 'Strompreis', 'Forschungspolitik', 'Mullah Regime', 'Verteidigung Israels', 'Situation in den Aufnahmekommunen', 'Klimakrise', 'Opfer', 'Ausbildungsstätte', 'Rechtsmittel', 'Streit', 'Bildungsprotest2023', 'heimatbayern', 'katrinebnersteiner', 'Kraft', 'Forschungsbedingungen', 'Verwaltungsrat', 'EU-Gängelung', 'Impuls', 'Produktionsverlagerung', 'Industrie', 'kriminelle Ausländer', 'Staatswald', 'Nazis', 'sachsenanhalt', 'Babys in Bayern', 'Spitzenkandidat', 'Überlänge von 16,50 m auf 17,40 m zulassen', 'Einwanderungs- und Asylpolitik', 'Spritpreisbremse', 'Fördermittelkürzungen', 'gemeinsame Sprache', 'Immatrikulation', 'U18-Wahl', 'mobilität', 'None', 'Kinder- und Jugendplan', 'Krisenverordnung', 'Pflegekonzepte', 'Bürokratieabbau', 'BayernSPD', 'bildung', 'Tradition', 'oberbayern', 'wählen', 'Zugang zur Justiz', 'Wälder', 'Gericht', 'Beste Bildung und weniger Unterrichtsausfall', 'Visionen', 'Terrorism', 'Asylrecht', 'Lernmittelfreiheit', 'Präventionsangebote', 'schlechter ÖPNV', 'Studis', 'humanitäre Verantwortung', 'Ampelpläne', 'Asylpolitik', 'br', 'Mopedführerschein', 'Abschaffung der ungerechten Erbschaftssteuer', 'Demokratieförderung', 'Landärzte', 'traditionelle Studiengänge', 'Enteignung', 'AfD-Wahlergebnisse', 'Holzöfen', 'Nationale Sicherheit', 'bayerische Bezirkstage', 'Bildungswende jetzt', 'Erbschaftssteuer', 'Volksentscheid', 'Landtags- und Bezirkstagswahl', 'Intoleranz', 'Abschaffung des Asylrechts', 'deutschland', 'ErbschaftssteuerAbschaffen', 'Gerechtigkeit', 'Größenwahn', 'Gewalt und Terror in Israel', 'Familienkasse', 'Atomwaffen', 'Wahl', 'GegenRechts', 'Wochen', 'Rücktritt', 'bayerische Staatsangehörigkeit', 'ehemalige SED-Partei', 'Wohnen', 'Mitgliedsstaaten', 'Kultursommer mit Links', 'arbeitsplätze', 'Kernkraftwerke', 'CSU Parteivorstand', 'Terrorismus', 'Anti-Demokrat*innen', 'Sorgen der Bürger ernst nehmen', 'bayerische Interessen im Bund und in Europa', 'die das Klima schützt', 'soziale Politik für Bayern', 'Tarifbindung', 'Bürger*innen-Energiegenossenschaft', 'Abschaffung der CO2-Steuer', 'linksextremistischen Gruppen', 'bayerische Staatlichkeit', 'EEG-Förderung', 'extremisten', 'Leistung und Eigentum', 'Durchhaltevermögen', 'oberpfalz', 'gerechter Freistaat', 'Verbrechen an unschuldigen Frauen', 'Grundsicherung', 'Verlässlichkeit und Kompetenz statt Beliebigkeit und Populismus', 'Los von Berlin', 'ambulante Anlaufstellen', 'AKW-Verteufelung', 'rechnen', 'Herangehensweisen', 'Bezahlbares Wohnen für 7 Mio. Mieter', 'Existenzrecht des jüdischen Staates Israel', 'staatliche Grundfinanzierung von Universitäten und Hochschulen ohne ideologische Vorgaben', 'Stärke', 'Kraftstoff', 'Wasserstoffinfrastruktur', 'vernünftige Mitte', 'Verträge mit Staaten in Nordafrika und Türkei', 'Landtagswahlen in Hessen und Bayern', 'Tempolimit auf Autobahnen', 'pädagogische Qualität von Kitas', 'Gewerkschaften', 'Polizei', 'Russland', 'FlurNatur-Struktur und Landschaftselemente', 'Arbeitsmigration', 'Verbrennungsmotoren', 'Arbeits- und Fachkräfte', 'Bürokratie', 'Kostenlose Kitas für 780 000 Kinder', 'schlechte Bildung', 'Enteignen', 'Steuersätze', 'soziale Probleme', 'Einreisekontrolle an den EU-Außengrenzen', 'israelische Städte und Dörfer', 'FDP', 'Rechtspopulismus', 'Krieg', 'Steuermodelle', 'Schule', 'alleinerziehend', 'buntes Kinderprogramm', 'VPN', 'Anstand', 'Staatsanwaltschaften', 'Arbeitskräftemangel', 'LandtagBayern', 'Verteilungsfragen', 'Souveränitätsverlust', 'Menschenrechte', 'Oberpfalz', 'Einkommensteuer', 'kostenfreie Kitas', 'lebenswertes Bayern', 'Investitionen in die Zukunft', 'sichere Stromversorgung', 'Staatsräson', 'sozialepolitikfürdich', 'Gute Pflege für 2,7 Mio. Senioren', 'Anerkennung', 'Kinder', 'ingolstadt', 'schlanker und effizienter Staat', 'Förderung', 'ausbau', 'Anpacken für Bayern', 'Persönlichkeitsrechte', 'Zuwanderungspolitik', 'Umweltschützer', 'erneuerbare Energien', 'Krankenhaus', 'Deutsche Stromkunden', 'Lehrer', 'Antragsprozess', 'Italianisierung', 'Gegenrassismus', 'inklusives Bildungssystem', 'Stromversorgung', 'Bundesregierung', 'Krankenhaus-Milliarde', 'MitDir', 'heimatschutz', 'Die Konfrontation', 'Toleranz', 'Freibeträge', 'fernsehen', 'freiberufliche Apotheken', 'Leerstandsabgabe', 'Stromleitungen', 'Zahlen', 'FreiheitfürSüdTirol', 'lpt2023', 'Deutschland-Pakt gegen unkontrollierte Zuwanderung', 'Lehrerinnen', 'Mehrsprachigkeit', 'Digitalministerin', 'Vereine und das Ehrenamt stärken', 'anpacken', 'Bevormundung', 'Identität und Nation', 'Kostenlose Bildung', 'Biotopen', 'Sprit sparen', 'Regierungsform', 'Katharina und Ludwig', 'Versorgungsstraßen', 'ÖPNV', 'Blockabfertigungen', 'Lohnersatzleistungen für pflegende Angehörige', 'Ladenschlussgesetz', 'Einbürgerung', 'sozialpolitik', 'Rathausplatz', 'Belebung von Ortszentren und Dorferneuerung', 'Mietendeckel', 'FREIE WÄHLER', 'Privatversicherte', 'Standort', 'Wiedervereinigung Deutschlands', 'Mindestlohn', 'Rückführung von kriminellen Straftätern', 'Insolvenzen', 'Mehr Personal und bessere Zusammenarbeit und Vernetzung', 'Einstellung von Richtern und Staatsanwälten', 'vereinbarkeit', 'Gendern', 'Erhaltung von Dörfern', 'Kinderzukunftsprogramm', 'Pelletheizung', 'Sicherheitsvorkehrungen', 'gute Bildung', 'Gesellschaft', 'landwirtschaft', 'Einzelleistungsvergütung', 'Verdoppelung Kapazität', 'Habeck', 'Naturpark', 'Übergriffigkeiten der EU-Eliten', 'Druck', 'Hausbesitzer', 'Verkehrspolitik', 'Gastronomie', 'starke Wirtschaft', 'Agieren und Finanzierung palästinensischer und propalästinensischer Terrororganisationen', 'kostenlosem ÖPNV für Kinder und Jugendliche', 'Ganzjahrestourismus', 'Schule für alle', 'Erdbeobachtungen', 'Vergesslichkeit', 'Pessimismus', 'Online Ausweis', 'klimaneutraler Wohnraum', 'Kinder und Jugendliche', 'innovativ', 'Ausbau der Windkraft', 'Landespflegegeld', 'besseres Europa', 'Sozialpolitik', 'Asyl', 'ampel', 'individuelle Förderung', 'BP', 'wahlprogramm', 'Menschen mit Behinderung', 'LINKE', 'internationale Wettbewerbsfähigkeit', 'mangelndem Wohnraum', 'Kinder und Jugendliche mit Migrationshintergrund', 'Wasserstoff-Gipfel', 'flächendeckend', 'junge Grüne Abgeordnete', 'Herausforderungen in der Migrationspolitik', 'Zwangsimpfungen', 'Freiheit für Bayern', 'Förderungen für Holz- und Pellets-Heizungen', 'Kindergrundsicherung', 'bayerische Arbeitsplätze', 'Innovation', 'Naturschutz', 'sozialer Aufstieg', 'aktuelle Lage', 'Mittelmeer', 'Gelder', 'innenministerherrmann', 'CO2-Einsparung im deutschen Strommix', 'grüne AKW-Heuchelei', 'Mobilität egal wo du hin willst', 'Italien', 'Deutschland', 'bayern', 'Berliner Senat', 'Gesundheitsreform', 'kostenloses Mittagessen', 'sauberer Strom', 'progressive', 'Mehrwertsteuer in der Gastronomie', 'Steuererhöhung', 'Finanzierung islamistischer Organisationen', 'Staat Israel', 'Begleitetes Fahren ab 15 Jahren', 'Ignoranz', 'Musik', 'kostenfreier Schulweg', 'Windrad', 'Kapazitäten', 'energie', 'konfrontation', 'Stromerzeugung', 'Studieren', 'wissenschaft', 'Menschen vor Ort', 'Haushaltsmittel zur Kofinanzierung der Gemeinschaftsaufgabe Agrarstruktur und Küstenschutz', 'Jugendhaus', 'Streuobstpakt', 'freiheit', 'staatlich subventionierter Industriestrompreis', 'Freie Wähler', 'Medienbildung', 'Antisemitismus-Beauftragter der Bayerischen Staatsregierung', 'Amberg', 'Bevölkerung', 'Rechtsextremismus', 'Trinkwasserschutz', 'dritter Nationalpark', 'Digitalisierung', 'Fachschüler*innen', 'Asylsystem', 'den Grünen und den linkslastigen Medien', 'Vielfalt', 'Humanität', 'Augsburg', 'neue Stromleitungen', 'Jom Kippur', 'Prost', 'stationäre Grenzkontrollen', 'grünklingelt', 'nachhaltigere Raumfahrt', 'Hackschnitzel', 'kostenloser Meister', 'kostenlosen ÖPNV', 'optimistische zukunftsorientierte Politik', 'Sparerpauschbetrag', 'Bargeldnutzung', 'Soziale Gerechtigkeit', 'Märkte', 'bayerisches Förderprogramm', 'Umgang mit Unternehmen', 'höherer Mindestlohn', 'Lebensgrundlagen', 'Handwerk', 'Kooperationsverträge mit der Bundespolizei', 'Flächenverbrauch', 'gleiche Chancen', 'psychische Gesundheit', 'Steuersenkung', 'Ausbildung', 'Grundwasserschutz', 'Institutionen', 'national strukturierteres Abschiebeverfahren', 'angriff', 'Oberfranken', 'Kommunale Krankenhäuser erhalten', 'Anti-Auto-Haltung', 'Rückführung', 'Wohnungsnot', 'finanzielle Förderung von Grundschulen', 'kostenfreie Meisterausbildung', 'Berlin', 'medizinische Versorgung', 'ökologie', 'Modernität', 'Innenentwicklung und die Vermeidung von Flächenverbrauch', 'brauchtum', 'Propagandafernsehen', 'Zeltlager', 'jungeunion', 'Mobilitätswende', 'Nutzung', 'Sozialdemokratie', 'Bayerischer Landtag', 'Genehmigungen', 'Soziale Politik Für Dich', 'Fachkräftemangel', 'Drogenkonsumräume', 'dezentrale Bevorratung in Bayern und Deutschland', 'unterfranken', 'Geburtshilfe', 'Azubis', 'Fallpauschalensystem', 'gute Pflege für 2,7 Mio. Senioren', 'Kitas', 'Druck auf die Ampel', 'rechtsrutschstoppen', 'Abdeckungs-Offensive', 'Kommerzialisierung', 'Solaranlage', 'rechte Ausschreitungen', 'bezahlbares Bayern', 'Landschaftswasserhaushalt', 'Bildungsorganisationen', 'echte Beteiligung', 'Mauerfall', 'Kampf gegen Rechts', 'Konkurrenz', 'AnpackenFürBayern', 'moedlareuth', 'klimaschädlicher Flugverkehr', 'Finanzen', 'Wahlalter 16', 'wichtige soziale Themen', 'Tempolimit auf deutschen Autobahnen', 'Umweltzerstörungen', 'Vorhaben', 'fachkräftemangel', 'Stellenwert in der Gesellschaft', 'Weltraummanagement', 'Fichtenbestand', 'Veränderungen', 'Dieselfahrverbot', 'Umwelt- und Naturschutz', 'Energie- und Industriepolitik', 'Technik', 'Ticketfreiheit', 'Unterstützung der Schulen bei der Umsetzung von Programmen', 'Chancengleichheit', 'Erhöhung der LKW Maut', 'Europawahlprogramm', 'Schutz der Zivilbevölkerung', 'Schleuserkriminalität', 'selbstverwaltete Justiz', 'EU-Gerichtshof', 'Verbotspolitik', 'LTWby23', 'Antragsberechtigung', 'generationengerechte Politik', 'demokratieverteidigen', 'Todesstrafe', 'Jährlichen Stellenaufbau bis 2029 verlängern', 'Holzheizung', 'klarer Kurs', 'Exekutive', 'Asyl-Migration', 'Schutzgrund', 'Recht', 'Nationalismus', 'Wende in der Migrationspolitik', 'Stromnetzausbau', 'Brauchtum', 'lesen', 'Unterdrückung im Iran', 'Waldschädlinge', 'Technologie', 'Ferienangebote', 'Landes- und Bündnisverteidigung', 'AUSSENGRENZEN', 'Entführungen', 'Tag der Deutschen Einheit', 'Markus Söder', 'herrmann', 'Benzin', 'Bayern-Energie', 'Klimaneutralität', 'Politsystem', 'Autonomie für Süd-Tirol', 'Erzeugerpreise', 'deutsche Staatsbürgerschaft', 'Heizen', 'inneresicherheit', 'Brandmauern', 'Bürgergeld', 'bezahlbare Mieten', 'Arbeitnehmerrechte', 'Bürgerinnen und Bürger', 'CO2', 'Grünen Partei', 'Kinderhaus', 'völkerrechtswidriger Angriff', 'Student', 'Zinsen', 'bezahlbarer Wohnraum', 'Wohnungsmangel', 'Safe Abortion Day', 'Einkommen', 'Diskutieren wir', 'Europäische Kommission', 'freistaat', 'Frieden und Freiheit', 'Kulturkampf', 'Spoken words', 'Produktion ins Ausland', 'Mödlareuth', 'Einheit', 'tvtipp', 'ländlicher Raum', 'angehobene Altersgrenzen', 'Schulsozialarbeit', 'Schutz', 'allestimmengrün', 'zukunft', 'Migration', 'Grünen wollen das ganze Land bevormunden', 'Grundschule', 'zweitehand', 'Massenmigration', 'Anpacken für unsere Bürger', 'organisiertes', 'Bürgerrechte', 'CO2-neutraler Kraftstoff', 'zielgerichtete Leistungen', 'Ampel', 'Life Science Campus', 'Steuerfreibeträge im Monat pro Arbeitnehmer auf 2000 Euro', 'europäische Zukunft', 'schwaben', 'Rückführungen', 'FSJ-Plätze', 'Wasserkraft', 'Grüne in der Landesregierung', 'Rechtsruck', 'Selbstbewusstsein', 'gemeinsames Lernen', 'Dürre', 'Wohnsitz', 'sicherheit', 'Wirtschaftsstrompreis', 'Heimatbewusstsein', 'Bodentruppen', 'DeutscheGeschichte', 'Bus', 'Verbote', 'Abschaffung Erbschaftssteuer', 'Förderung der ländlichen Entwicklung', 'Krankenhausversorgung', 'Legislative', 'Existenzrecht Israels', 'regensburg', 'durchgrüntes Berlin', 'Finanzierung des ÖPNVs', 'Heimatvertriebene', 'chrupalla', 'LTW23', 'Landschaftspfleger', 'Sommer', 'illegale Einreisen', 'heimische Energiewelt', 'Neonazi-Strukturen', 'Demokratiebildung', 'bundesweite Grenzpolizei', 'Deregulierung', 'Inflation', 'Zukunftsfinanzierungsgesetz', 'Herz statt Hetze', 'Bezahlbare Energie', 'gesellschaftliche Teilhabe', 'volle Unterstützung für die Ukraine', 'bayerische Interessen', 'Elternhaus', 'bessere Taktung', 'Abgaben', 'antisemitische Propaganda', 'ländliche Krankenhäuser', 'Grundversorgung', 'Bayerns erneuerbare Energie', 'Entlastungen', 'Auflösung des öffentlich-rechtlichen Rundfunks', 'grüne Dogmen', 'effektiver Grenzschutz', 'Erdgas', 'Kriminelle Straftaten', 'Rendite', 'Regensburg', 'Diskriminierung', 'AfD-Erfolgswelle', 'Mobilität', 'Erneuerbare', 'Windenergie', 'Kernwegenetzbau', 'Energieversorgung in Bayern', 'Vitalität', 'staatliche Wohnheime', 'Kinder und Jugendliche in den Fokus', 'Engagement für die Heimat', 'Löhne', 'Hochschule', 'Revolutionsgarden', 'Weltfriedenstag', 'Covid-Maßnahmen', 'Bildung für Bayern', 'Barrierefreiheit', 'Zwangsgebühren', 'bezahlbare und saubere Energie', 'Baupolitik', 'Wahnsinn des Nationalsozialismus', 'Genuss', 'einseitigen Wärmepumpen-Träume der Ampel', 'Selbstregierung', 'kostenlose Meisterausbildung', 'Hisbollah', 'Menschen mit Fluchtgeschichte', 'Zukunftsvertrag zwischen der Staatsregierung und dem Bayerischen Bauernverband', 'Mittelstand schützen', 'Kernfusions-Kraftwerk', 'Erhalt aller Schulstandorte', 'Landtagswahl', 'legale Zuwanderung', 'Gerichte', 'Länderfinanzausgleich', 'rechts', 'Mut', 'LTWby2023', 'bücher', 'Remigration', 'Bayerische Grenzpolizei', 'Freiheit', 'hohe Energiepreise', 'Klimakatastrophe', 'Existenz- und Altersabsicherung', 'Vernunft statt Ideologie', 'Zusammenleben', 'Asylanträge', 'ortsnahe Versorgung', 'Kontinuität', 'Zahlungen an Palästinenser', 'kostendeckende Schulstarthilfe', 'Aufnahmestopp für junge Männer', 'Inntal', 'Mieterschutz', 'Normalverdiener', 'KEINE dritte Startbahn am Flughafen München', 'gendern', 'bayernsOpposition', 'Ärztemangel', 'Zeitenwende', 'Haltung', 'LTW2023', 'Holzheizungen', 'Hilfe für Betroffene von Terrorismus', 'Sicherheit und Ordnung', 'Übergriffe des italienischen Staates', 'Online-Petition', 'Wirtschaftsminister', 'Theoriestunden', 'Schwangerschaftsabbrüche', 'Erneuerbare Energien', 'Terrorangriff der Hamas', 'Rechenschaft', 'br24wahl', 'Stärkung von Landschaften', 'Studierende', 'Artenschutz', 'Grundwasser', 'Wasserschutz', 'Auflagen', 'Zusammenhalt', 'Situation der Studierenden in Bayern', 'LudwigUntrwegs', 'Türkei', 'Nürnberg', 'Deutsche Einheit', 'Energiewende vor Ort', 'Hitze', 'Wertschätzung für ältere Menschen', 'Bezahlbare Wohnungen', 'Wahlprogramm', 'Bildung für alle unsere Kinder', 'nachhaltigkeit', 'Vorschriften', 'starke Infrastruktur', 'Organisationsbereiche', 'Gazastreifen', 'Steigerwaldzentrum', 'Außenpolitik', 'saubere Energie', 'Renten', 'Keine Grünen in der Regierung', 'duales Studium als Bildungsweg stärken', 'Löhne in Ostdeutschland', 'augsburg', 'Medikamente', 'anfängliche Fehler', 'Bund ID Konto', 'Unternehmen', 'Sicherheit bei Lebensplanung', 'Schnitzel', 'Mitglieder-Anteile', 'Richter', 'Stallbauvorschriften', 'Bildung unabhängig vom Geldbeutel', 'Bayern bleibt', 'Pflegekräfte', 'remigration', 'Klima', 'deutschlandfest', 'Aufgaben unserer Zeit', 'flächendeckende Gesundheitsversorgung', 'Chaos', 'Abschiebe-Zahlen', 'Ethos', 'Kampagne finanziert sich', 'Schutzversprechen für jüdisches Leben in Bayern', 'Energie und Treibstoffe', 'Steuerliche Förderungen', 'Bauern', 'Lehrstühle für „Genderforschung“', 'zukunftsfähiges Bildungssystem', 'Wasserstoff-Land Nummer 1 werden', 'Multimillllionäre', 'sozialpolitische Maßnahmen', 'Wärmepumpe', 'brzahlbares Wohnen', 'Niederbayern', 'Wohnen als Grundrecht', 'Bürgermeister', 'Chancengerechtigkeit in Deutschland', 'Schutz des ungeborenen Lebens', 'Ukraine', 'den Automobilstandort Deutschland stärken', 'Reform des Gesundheitswesens', 'Energiegewinnung', 'Landkreis München', 'ärztliche Versorgung', 'Akutsprechstunden', 'Kürzungspolitik', 'Vertrauen', 'Entlastungen für Sparerinnen und Sparer', 'Wohnungs- und Mietmarkt', 'Misstrauen', 'Erbschaftssteuer abschaffen', 'Steuerpolitik', 'Volksbegehren', 'EEG-Umlage', 'Ausbildungs- oder Studienstart', 'Zusatzleistungen', 'Bavarian Fusion Cluster', 'Investorenbetriebene Medizinische Versorgungszentren (MVZ)', 'Spitzenmedizin', 'Wahlkampf', 'Kirchen', 'Energiekosten', 'Hessen', 'Verbrennerverbot', 'Marktwirtschaft', 'Landtags- und Kommunalwahlen', 'Stil', 'Verwaltungsdirektor', 'deutsche Staatsräson', 'Nationalsozialismus', 'Europa', 'Grundlastfähigkeit', 'saubere und bezahlbare Energie', 'Bus und Bahn ins ganze Land bringen', 'Asylbewerber*innen', 'Hilfe und Fürsorge des Staates und der Gesellschaft', 'Hilfe in sozialen Fragen', 'Elektrolyseur-Förderprogramm', 'Familiengeld', 'Opposition', 'niederbayern', 'Sicherheit des Staates Israel', 'Führungspositionen', 'Wohnungsgemeinnützigkeit', 'Medien', 'soziale Herkunft', 'Fernsehen', 'CDU', 'Anpacken statt Ankündigen', 'GEZ abschaffen', 'Arbeitsplätze', 'soziale Politik', 'Wasserentnahme', 'Kinderarmut', 'Filz', 'saisonalität', 'Gesellschaften', 'staatliche Energieunternehmen', 'Heimatenergie', 'Süden', 'kreislauf', 'Energiepolitik', 'Bildung für alle', 'Finanzminister', 'steigende Preise', 'LOSvonBERLIN', 'Wahlerfolge für Boris Rhein und die CDU Hessen', 'mittelschicht', 'Deckelung der Mieten', 'Mitte-rechts', 'volle Unterstützung für Israel', 'Benachteiligung von Menschen mit psychischen Problemen', 'TeamBayern', 'beste Bildung', 'Altparteien', 'nächste Wahlen', 'günstiger ÖPNV', 'CO2-freier Strom', 'Bezirkstag', 'Hamas-Terror', 'Schienenverkehr ausbauen', 'Heimische Produktion von Arzneimittel stärken', 'Anteile', 'Stärkung der Demokratie', 'Ruhegehalt', 'Vergabeverfahren von Medizin-Studienplätzen', 'DeshalbAfD', 'Energiesparen', 'Holznutzung', 'dezentrale Unterbringungen', 'BayerischerLandtag', 'Verhältnis zur Partei', 'Identität', 'Abwärme', 'Wohnraumförderung', 'Grenzschutzbayern', 'Bildung', 'Freie und selbstbestimmte Entscheidung der Patienten', 'junge Generation', 'politiker', 'klimaneutrales Wirtschaften', 'Auto', 'Arbeitszeitflexibilisierung', 'H2-Tankstellen', 'AfD verspricht', 'umsetzen', 'Allgemeinbildung', 'ltwbayern', 'Bezahlbare und saubere Energie', 'Einkommensunterschiede', 'infostand', 'forschung', 'unserlandzuerst', 'Migrationsstopp', 'Freiheit und weniger Kontrollen für bayerische Landwirte', 'Bundestag', 'Sprachkurse', 'Hessenwahl', 'afd', 'gute Ganztagsbetreuung', 'Stromsteuer', 'Hamas', 'primetime', 'Jugendherberge', 'FREIEWÄHLER', 'Veranstaltung', 'wehrhafte Demokratie', 'Ursula von der Leyen', 'Mehr Kontrolle und Steuerung bei der Migration', 'Freistaat', 'Angriffe', 'Mieterinnen und Mieter', 'Abschottungswahnsinn', 'Medizinische Versorgung', 'Solidarität', 'Borkenkäfer', 'Hightech Agenda Bayern', 'Erhöhung der Steuerfreibeträge im Monat pro Arbeitnehmer auf 2000 Euro', 'Kommunen bei der Aufnahme von Geflüchteten unterstützen', 'Gesetzesvolksentscheid', 'Selbstverteidigung', 'Chancenbudget', 'Transportwege', 'familienfreundlicher', 'Wahlniederlage', 'Bayerischer Härtefallfonds', 'münchen', 'Tempo 90 für Fahranfänger', 'Belastungs-Stopp', 'Stromspeicher', 'Seniorinnen und Senioren', 'Artenschwund', 'AfD', 'strukturschwachen Kommunen', 'Vereine', 'Festanstellung', 'Krankenhausinvestitionen', 'Zukunft', 'Gewalttaten', 'Hausbau', 'schlafen', 'Notendruck', 'afdbayern', 'Energieversorgung der Zukunft', 'Kraftstoffpreis', 'Solidarität mit Israel', 'BAföG', 'Strom und Lebensmittel', 'Cannabis-Legalisierung', 'nächste Landtagswahl', 'Häuser', 'Profite mit unserer Miete', 'Frühe Hilfen', 'Regierungsbildung', 'individuelle Mobilität ermöglichen', 'LandtagswahlBayern', 'Bezahlbare und saubere Energie für Bayern', 'leistungsorientierte Bezahlung von Lehrkräften', 'Kinder eine Zukunft', 'Investitionen', 'Durchforstung', 'Binnengrenzen', 'Radwege', 'Vernichtung von Kultur', 'Verkehrssicherheit', 'Unterschriften Sammeln', 'Wärmenetz', 'Steuererleichterung für Agrardiesel', 'grüne Politik', 'Wartezeiten für Therapieplätze', 'Nahversorgung im ländlichen Raum stärken', 'kompetente Politik', 'Urteile', 'Waffenrecht', 'illegale Zuwanderung', 'mangelnde Mobilität', 'online', 'Stärkung von Regionen', 'Spitzenkandidaten', 'hightech', 'Steuern', 'Außenwirtschaft', 'startups', 'Benutzername & Passwort', 'Mobilität junger Menschen', 'illegaleMigration', 'gute gesundheitliche Versorgung', 'Direktkandidatin für den Bayerischen Landtag', 'mörderischer Angriff auf unseren Bundesvorsitzenden', 'Bauvorschriften', 'Grenzkontrollen', 'Alternative zu Deutschland', 'Bescheid', 'Heizungs-Lotsen', 'Massenzuwanderung', 'Asylbewerber', 'steigende Mietpreise', 'Grenzsicherung', 'Rechtsruck in Bayern', 'kostenlose Kitaplätze', 'Claudia Köhler', 'gesellschaftlicher Zusammenhalt', 'Integrationsfähigkeit', 'Militär', 'selbstbestimmt', 'Demokratie', 'juxcsu', 'bayernwahl', 'Staatssekretär für Inneres', 'Süd-Tirol-Autonomie', 'Landtagswahl in Bayern', 'Verweisung nichtdeutscher Staatsbürger', 'Armut', 'Mittelfranken', 'Studium', 'Hightech Agenda', 'Sicherheitsbehörden', 'politikmitherz', 'Windpark', 'Gesundheitsschutz', 'Wiedereinzug', 'Aktivrente', 'geringes Einkommen', 'ausländische Fachkräfte', 'Landtag', 'Terror stoppen', 'gerechte Politik', 'Erosionsschutz', 'Speicher', 'regionale Wertschöpfung', 'Unterbringung', 'marktwirtschaftliches Gewissen', 'Austausch mit den Bürgerinnen und Bürgern', 'wohnen', 'Umbau zu stabileren Wäldern', 'innenministerium', 'Bahn', 'Gesundheitsvorsorge', 'Entwicklung in Deutschland', 'Gemeinschaftsaufgabe „Verbesserung der Agrarstruktur und des Küstenschutzes“', 'Sicherheit', 'duales Studium verbessern', 'Integrationsgrenze', 'Ganztag', 'Süd-Tiroler Freiheit', 'CO2-Steuer abschaffen', 'Steuerverschwendung', 'Teambayern', 'Einwanderung', 'Kostenlose Kitas für 780.000 Kinder', 'interessierte Bürger', 'terroristischer Überfall', 'Klimapolitik', 'israelisches Volk', 'Dreigliedriges Schulsystem'}\n\n\nLet’s quickly generate a wordcloud to check for patterns. See the Simple Corpus Analysis Notebook for more information.\n\n!pip install -q wordcloud\n\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nimport requests\n\n# Retrieve Stopwords from Github\nr = requests.get('https://github.com/stopwords-iso/stopwords-de/raw/master/stopwords-de.json')\nstop_words = r.json()\n\n# Stopwörter in die WordCloud laden\nSTOPWORDS.update(stop_words)\n\ndef generate_wordcloud(text):\n    text = ' '.join(list(text))\n\n    # Generate a word cloud image\n    wordcloud = WordCloud(background_color=\"white\",width=1920, height=1080).generate(text)\n\n    # Dazugehörige Grafik erstellen\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.figtext(0.5, 0.1, \"Policy Issues\", wrap=True, horizontalalignment='center', fontsize=12)\n    plt.show()\n\ngenerate_wordcloud(policy_issues)\n\n\n\n\nNow we’re ready to pass the list to GPT to extract a manageable amount of topics. Note the list might be too long to fit into the GPT context window. In this case we have to split the list into several shorter lists and iterate over them.\nThis time we are not interested in a specific formatting for the response. We want to print the result for human interpretation.\n\nsystem_prompt = \"\"\"\nYou are a helpful assistant, an expert for German politics. Derive 15 topics of policy issues from this list of keywords provided by the user. Concentrate on overarching topics and avoid overlapping topics. Provide a set of 10 keywords per topic.\n\"\"\"\n\n\nkeyword_string = \", \".join(unique_policy_issues)\nresponse = run_request(system_prompt, row['Text'], False)\n\nCost: $0.0010 | Total: $0.3431\n\n\n\nprint(response.choices[0].message.content)\n\n1. Sicherheit\n- Polizei\n- Kriminalität\n- Terrorismus\n- Überwachung\n- Grenzkontrollen\n\n2. Wirtschaftswachstum\n- Industrie\n- Arbeitsplätze\n- Investitionen\n- Innovation\n- Export\n\n3. Arbeitslosenquote\n- Arbeitsmarkt\n- Arbeitslosengeld\n- Arbeitsvermittlung\n- Qualifikationen\n- Arbeitslosenversicherung\n\n4. Regierung\n- Politik\n- Parteien\n- Regierungsbildung\n- Koalitionen\n- Opposition\n\n5. Bayern-Power\n- Regionalpolitik\n- Infrastruktur\n- Bildung\n- Kultur\n- Tourismus\n\n6. Ampel-Frust\n- Politikverdrossenheit\n- Koalitionsstreitigkeiten\n- Stillstand\n- Kompromisse\n- Unzufriedenheit\n\n7. Familiengeld\n- Familienpolitik\n- Kinderbetreuung\n- Elternzeit\n- Kindergeld\n- Unterstützung\n\n8. Pflegegeld\n- Pflegepolitik\n- Altenpflege\n- Pflegeversicherung\n- Pflegeheim\n- Angehörigenpflege\n\n9. Meisterausbildung\n- Berufsausbildung\n- Fachkräftemangel\n- Handwerk\n- Aufstiegschancen\n- Weiterbildung\n\n10. Briefwahl\n- Wahlrecht\n- Wahlbeteiligung\n- Demokratie\n- Wahlkampf\n- Stimmabgabe\n\n\n\nSource: Text Exploration Using GPT"
  },
  {
    "objectID": "processing/exploration.html#conclusion",
    "href": "processing/exploration.html#conclusion",
    "title": "Data Import",
    "section": "Conclusion",
    "text": "Conclusion\nWe have explored two transformer based approaches for text exploration. BERTopic is an easy to use tool for topic modeling. Using this approach we can quickly explore patterns in the content of (textual) social media content – as long as there is a GPU available (e.g. on Colab). We will come back to this tool in the future, when dealing with images, as we might be able to harness its abilities for visual media.\nThe text exploration using GPT, on the other hand, does not rely on special hardware, as we query the API and OpenAI is taking care of the heavy computing. Prompting offers the possibilities to explore our data according to endless questions, yet we need some form of question to get started. We have explored policy issues using the gpt-3.5-turbo model, the results are mixed. Looking through the wordcloud we see issues that might have been at the centre of attention, like Education, Climate Protection, and Security. At this point, however, we should be cautious to generalize, other issues might have been named differently between requests, thus disappearing within the wordcloud. Looking at the BERTopic results, we can spot similar topics, like Security and Migration (Topic 2), Climate Protection (Topic 1), and Education (Topic 12).\nToday’s prompting marks the tip of the iceberg, over the course of the next weeks we will use more and more prompts, moving from exploration, to classification. One prompting technique which we will not discuss this semester is Retrieval Augmented Generation (RAG), which might also be useful for Text Exploration. This technique combines information retrieval with text generation. LlamaIndex and LangChain are python package that may help to build RAG applications. How to integrate them into our research workflow will be a future project (or topic for a future BA or MA thesis)."
  },
  {
    "objectID": "processing/exploration.html#more-resources",
    "href": "processing/exploration.html#more-resources",
    "title": "Data Import",
    "section": "More Resources",
    "text": "More Resources\n\nOpenAI Prompt Engineering Guide\nPrompting Guide\nBrown et al. (2020): Language Models are Few-Shot Learners\nLiu et al. (2023): Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing\nMøller et al. (2023): Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks.\nPromptCompass Prompts (Borra, n.d.)\nBERTopic for Topic Modeling - Maarten Grootendorst - Talking Language AI (YouTube)"
  },
  {
    "objectID": "processing/index.html",
    "href": "processing/index.html",
    "title": "Text as Data",
    "section": "",
    "text": "The analysis of texutal data has a long tradition under the term Natural Language Processing (NLP). As noted by Bengfort, Bilbro, and Ojeda (2018), “Language is unstructured data that has been produced by people to be understood by other people”. This characterization of language as unstructured data highlights its contrast with structured or semi-structured data. Unlike structured data, which is organized in a way that computers can easily parse and analyze, unstructured data like language requires more complex methods to be processed and understood. In the context of e.g. Instagram, CrowdTangle exports contain structured data columns such as ‘User Name’, ‘Like Count’, or ‘Comment Count’. These pieces of data are quantifiable and can be easily sorted, filtered, or counted, e.g. using tools like Excel or Python’s pandas library. For instance, we can quickly determine the most active users by counting the number of rows associated with each username. In contrast, unstructured data is not organized in a predefined manner and is typically more challenging to process and analyze. The ‘Description’ column in our dataset, which contains the captions of Instagram posts, is a prime example of unstructured data. These captions, composed of paragraphs or sentences, require different analytical approaches to extract meaningful insights. Unlike structured data, we cannot simply count or sort these texts in a straightforward manner. In our context, we often refer to the collection of texts we analyze as a “Corpus”. Each individual piece of text is called a “Document”. Each document can be broken down into smaller units known as “features”. Features can be words, phrases, or even patterns of words, which we then use to quantify and analyze the text (compare p. 230 Haim 2023). For the goal of our research seminar, we can follow the three technical perspectives inspired by Haim (2023): 1. Frequency Analysis, 2. Contextual Analysis, and 3. Content Analysis."
  },
  {
    "objectID": "processing/index.html#schedule",
    "href": "processing/index.html#schedule",
    "title": "Text as Data",
    "section": "Schedule",
    "text": "Schedule\n\nIn our first session, we begin with frequency analyses of our corpus, which involves counting words or phrases to identify the most common elements. This method provides a foundational understanding of the prominent themes or topics. Additionally, we learn to convert embedded text in images and videos into machine-readable format, using OCR, and automated audio transcription.\nNext, we will engage in explorative text analysis. This step enhances our understanding of the corpus and lays the groundwork for quantitative content analysis. We plan to utilize tools like GPT (and possibly BERTopic for an in-depth exploration of our documents.\nFinally, we move towards more complex methods like classification or coding. These techniques allow us to categorize text into predefined groups or themes, enabling a more nuanced and quantitative understanding of the content. By applying these methods, we can, for example, classify Instagram captions into categories such as ‘promotional’, ‘personal’, ‘informative’, etc., based on their content and context."
  },
  {
    "objectID": "processing/index.html#hands-on",
    "href": "processing/index.html#hands-on",
    "title": "Text as Data",
    "section": "Hands-On",
    "text": "Hands-On\nWe are working with Python and pandas, our data is structured in tables, also known as DataFrames. Each DataFrame (df) consists of rows and columns. We can store and structure data differently using these two dimensions, one concept for storing research data using tables is Tidy Data (Wickham 2014). According to this standard\n\n\nEach variable forms a column.\nEach observation forms a row.\nEach type of observational unit forms a table.\n\n\n\n\n\nVisualization of the tidy data components, source: R for Data Science.\n\n\nWhat, in context of social media data, is an obersavtion? Is it a post? I suggest to start by seeing posts as observations, i.e. rows. Thus, we have one table for our corpus, consisting of one row per post with multiple columns for different variables, including an ID, possibly a link, a referrence to the image / video, and one or more text variables for each post. When dealing with Instagram or TikTok posts, we might have three text columns: caption / description, OCR, and transcription. When dealing with stories two: OCR and transcription.\n\n\n\n\n\n\nNote\n\n\n\nWhen dealing with more complex data, e.g. Instagram albums that may contain multiple images per post, we will have to reconsider this choice. In this case we might consider each observation to be one image / video, which has variables like OCR and transcription. Keeping the ID column for images and videos, we have a fixed reference to the original post, thus we may re-merge the data later on with the post metadata or combine variables across media for one post.\n\n\nAll data exported from CrowdTangle, 4CAT, and Zeeschuimer-F are saved as CSV files. Throughout the semester, we keep using this file format to save our progress. We work with multiple Jupyter notebooks, generally one notebook per task. This helps to keep a good structure of our projects. Each time we modified the df, we save the CSV file to our Google Drive / Harddrive. In the two examples below we add an OCR and a Transcription column to our DataFrame, for each task we use one notebook. After completing each task, we store the results in a file. While Google Drive provides file versioning to mitigate data loss in certain scenarios, I recommend to save your results to a new file during the experimental phase. This practice ensures data safety until you have fully verified the functionality of your code. Additionally, I recommend naming your files in a YYYY-MM-DD-descriptive-name.csv fashion. When working with colab notebooks I recommend to keep track of notebooks using notes / lists, e.g. using the Dataloom plugin for Obsidian.\n\n\n\nKeeping track of Colab notebooks with Obsidian and the Dataloom plugin.\n\n\nThe CSV files contain only metadata, the actual media files (images / videos) are saved to different locations. The OCR and Transcription notebooks below contain code to import media files from 4CAT and Zeeschuimer-F. I suggest to save the files to media/videos or media/images. Both notebooks introduce a column image_file or video_file where the relative location of the media files is written to. Creating a new ZIP file using the new folder structure and saving the file to Google Drive allows us to use the media files in future notebooks (e.g. for image classification) without modifying the image_file or video_file columns again.\n\n\n\n\n\n\nNote\n\n\n\nThis page and all referenced notebooks deal with 4CAT and Zeeschuimer-F metadata and media files. Generally all information applies to instaloader as well. Its advisable to use the --filename-pattern command line parameter to control the filename of the media files. Mapping JSON metadata to actual media objects becomes easier this way. Once all posts / stories have been loaded using instaloader, I recommend to read all JSON files in a loop and create a DataFrame (see Data Collection / Posts / Instaloader for more information and code examples).\n\n\nKey Take-Aways\n\nWe organize our data inspired by TidyData\n\nOne row per post\nOne column per variable\n\nWe use one notebook per task\nWe save our progress to CSV files, either on our harddrive or Google Drive\nWe keep a reference to media files as a relative reference in our DataFrame\nWe keep our media files in the structure media/videos, and media/images, which we compress to ZIP and keep on our Google Drive (or central HDD location)\nWhen working with experimental code, keep backups of your data file, do not overwrite the original file!"
  },
  {
    "objectID": "processing/index.html#from-images-videos-to-text",
    "href": "processing/index.html#from-images-videos-to-text",
    "title": "Text as Data",
    "section": "From Images / Videos to Text",
    "text": "From Images / Videos to Text\nComputational approaches for text analyses are established as part of computational sociales science research (Baden et al. 2022), which we may utilize when dealing with visual and multimodal social media. Instagram posts often contain embedded text, TikTok posts often contain an audio layer, both of which we can transform to computer readable text. For the first, we are going to use OCR, for the second we apply Whisper. The following subchapters demonstrate the application of these technique in order to extract textual content from images and videos. In the thirs subchapter, I demonstrate a simple application of corpus analytics for a first analysis of the social media content based on word frequencies.\n\nOCR\n\nWe’re using easyocr. See the documentation for more complex configurations. Using CPU only this process takes from minutes to hours (depends on the amount of images). OCR may also be outsourced (e.g. using Google Vision API), see future sessions (and Memespector) for this.\n\n!pip -q install easyocr\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 29.7 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 908.3/908.3 kB 57.5 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 29.6 MB/s eta 0:00:00\n\n\n\n# Imports for OCR\nimport easyocr\nreader = easyocr.Reader(['de','en'])\n\nProgress: |██████████████████████████████████████████████████| 100.0% CompleteProgress: |██████████████████████████████████████████████████| 100.0% Complete\n\n\nWe define a very simple method to receive one string for all text recognized: The readtextmethod returns a list of text areas, in this example we concatenate the string, therefore the order of words is sometimes not correct.\nAlso, we save the file to Google Drive to save our results.\n\ndef run_ocr(image_path):\n    ocr_result = reader.readtext(image_path, detail = 0)\n    ocr_text = \" \".join(ocr_result)\n    return ocr_text\n\ndf['ocr_text'] = df['image_file'].apply(run_ocr)\n\n# Saving Results to Drive\ndf.to_csv('/content/drive/MyDrive/2022-11-09-Stories-Exported.csv')\n\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0.1\nUnnamed: 0\nID\nTime of Posting\nType of Content\nvideo_url\nimage_url\nUsername\nVideo Length (s)\nExpiration\n...\nIs Verified\nStickers\nAccessibility Caption\nAttribution URL\nvideo_file\naudio_file\nduration\nsampling_rate\nimage_file\nocr_text\n\n\n\n\n0\n0\n0\n3234500408402516260_1383567706\n2023-11-12 15:21:53\nImage\nNaN\nNaN\nnews24\nNaN\n2023-11-13 15:21:53\n...\nTrue\n[]\nPhoto by News24 on November 12, 2023. May be a...\nhttps://www.threads.net/t/CzjB80Zqme0\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234500408402516260_1383567706.jpg\nKeee WEEKEND NEWS24 PLUS: TESTING FORDS RANGER...\n\n\n1\n1\n1\n3234502795095897337_8537434\n2023-11-12 15:26:39\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:26:39\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234502795095897337_8537434.jpg\nDieses Auto ist einfach der Horror Du glaubst ...\n\n\n2\n2\n2\n3234503046678453705_8537434\n2023-11-12 15:27:10\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:27:10\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234503046678453705_8537434.jpg\nTouchdown bei Taylor Swift und Travis Kelce De...\n\n\n3\n3\n3\n3234503930728728807_8537434\n2023-11-12 15:28:55\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:28:55\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234503930728728807_8537434.jpg\nHorror-Diagnose für Barton Cowperthwaite Netfl...\n\n\n4\n4\n4\n3234504185910204562_8537434\n2023-11-12 15:29:25\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:29:25\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234504185910204562_8537434.jpg\n3v Bilde GG JJ Besorgniserregende Ufo-Aktivitä...\n\n\n\n\n\n5 rows × 21 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nSource: OCR using easyocr\n\n\nAutomated Audio Transcription (Whisper)\n\n\n\n\n\n\nNote\n\n\n\nOpenAI offers Whisper transcriptions as a service, see their documentation. The notebook below takes you step-by-step through using the Whisper model on your own computer / colab.\n\n\n\nExtract Audio from Video File\nAfter loading the metadta and media files from the Google Drive, we extract the audio from each video file to prepare the automated transcription.\n\n!pip install -q moviepy\n\n\nimport os\n\n# Set audio directory path\naudio_path = \"media/audio/\"\n\n# Check if the directory exists\nif not os.path.exists(audio_path):\n    # Create the directory if it does not exist\n    os.makedirs(audio_path)\n\n\nfrom moviepy.editor import *\n\nfor index, row in df.iterrows():\n    if row['video_file'] != \"\":\n        # Load the video file\n        video = VideoFileClip(row['video_file'])\n        filename = row['video_file'].split('/')[-1]\n\n        # Extract the audio from the video file\n        audio = video.audio\n\n        if audio is not None:\n            sampling_rate = audio.fps\n            current_suffix = filename.split(\".\")[-1]\n            new_filename = filename.replace(current_suffix, \"mp3\")\n\n            # Save the audio to a file\n            audio.write_audiofile(\"{}{}\".format(audio_path, new_filename))\n        else:\n            new_filename = \"No Audio\"\n            sampling_rate = -1\n\n        # Update DataFrame inplace\n        df.at[index, 'audio_file'] = new_filename\n        df.at[index, 'duration'] = video.duration\n        df.at[index, 'sampling_rate'] = sampling_rate\n\n        df.at[index, 'video_file'] = row['video_file'].split('/')[-1]\n\n        # Close the video file\n        video.close()\n\nMoviePy - Writing audio in media/audio/CzD93SEIi-E.mp3\nMoviePy - Done.\n\n\nWe’ve extracted the audio content of each video file to a mp3 file in the media/audio folder. The files keep the name of the video file. We added new columns to the metadata for audio duration and sampling_rate. In case the video did not include an audio file, smapling_rateis set to -1, which we use to filter the df when transcribing the files.\n\ndf[df['video_file'] != \"\"].head()\n\n\n  \n    \n\n\n\n\n\n\nid\nthread_id\nparent_id\nbody\nauthor\nauthor_fullname\nauthor_avatar_url\ntimestamp\ntype\nurl\n...\nnum_comments\nnum_media\nlocation_name\nlocation_latlong\nlocation_city\nunix_timestamp\nvideo_file\naudio_file\nduration\nsampling_rate\n\n\n\n\n4\nCzD93SEIi-E\nCzD93SEIi-E\nCzD93SEIi-E\nMitzuarbeiten für unser Land, Bayern zu entwic...\nmarkus.soeder\nMarkus Söder\nhttps://scontent-fra3-1.cdninstagram.com/v/t51...\n2023-10-31 12:06:23\nvideo\nhttps://www.instagram.com/p/CzD93SEIi-E\n...\n227\n1\nNaN\nNaN\nNaN\n1698753983\nCzD93SEIi-E.mp4\nCzD93SEIi-E.mp3\n67.89\n44100.0\n\n\n\n\n\n1 rows × 24 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\nLet’s update the ZIPed folder to include the audio files.\n\n!zip -r /content/drive/MyDrive/2023-11-24-4CAT-Images-Clean.zip media\n\nupdating: media/ (stored 0%)\nupdating: media/videos/ (stored 0%)\nupdating: media/videos/CzD93SEIi-E.mp4 (deflated 0%)\n  adding: media/audio/ (stored 0%)\n  adding: media/audio/CzD93SEIi-E.mp3 (deflated 1%)\n\n\nAnd save the updated metadata file. Change filename when importing stories here!\n\ndf.to_csv(four_cat_file_path)\n\nTranscriptions using Whisper\n\nThe Whisper model was proposed in Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.\n\n\nThe abstract from the paper is the following:\n\n\n\nWe study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zeroshot transfer setting without the need for any finetuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.\n\n\n– https://huggingface.co/docs/transformers/model_doc/whisper\n\n!pip install -q transformers\n\nThe next code snippet initializes the Whisper model. The transcribe_aduio method is applied to each row of the dataframe where sampling_rate &gt; 0, thus only to those lines with referencees to audio files. Each audio file is transcribed using Whisper, the result, one text string, is saved to the transcript column.\nAdjust the language variable according to your needs! The model is also capable of automated translation, e.g. setting language to english when processing German content results in an English translation of the speech. (Additionally, the task variable accepts translate).\n\nimport torch\nfrom transformers import pipeline, WhisperProcessor, WhisperForConditionalGeneration\nimport librosa\n\n# Set device to GPU if available, else use CPU\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize the Whisper model pipeline for automatic speech recognition\npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=\"openai/whisper-large\",\n    chunk_length_s=30,\n    device=device,\n)\n\n# Load model and processor for multilingual support\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n\n# Function to read, transcribe, and handle longer audio files in different languages\ndef transcribe_audio(filename, language='german'):\n    try:\n        # Load and resample audio file\n        audio_path = f\"{audio_folder}/{filename}\"\n        waveform, original_sample_rate = librosa.load(audio_path, sr=None, mono=True)\n        waveform_resampled = librosa.resample(waveform, orig_sr=original_sample_rate, target_sr=16000)\n\n        # Get forced decoder IDs for the specified language\n        forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=\"transcribe\")\n\n        # Process the audio file in chunks and transcribe\n        transcription = \"\"\n        for i in range(0, len(waveform_resampled), 16000 * 30):  # 30 seconds chunks\n            chunk = waveform_resampled[i:i + 16000 * 30]\n            input_features = processor(chunk, sampling_rate=16000, return_tensors=\"pt\").input_features\n            predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n            chunk_transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n            transcription += \" \" + chunk_transcription\n\n        return transcription.strip()\n    except Exception as e:\n        print(f\"Error processing file {filename}: {e}\")\n        return \"\"\n\n\n# Filter the DataFrame (sampling_rates &lt; 0 identify items without audio)\nfiltered_index = df['sampling_rate'] &gt; 0\n\n# Apply the transcription function to each row in the filtered DataFrame\ndf.loc[filtered_index, 'transcript'] = df.loc[filtered_index, 'audio_file'].apply(transcribe_audio)\n\n\ndf[df['video_file'] != \"\"].head()\n\n\n  \n    \n\n\n\n\n\n\nid\nthread_id\nparent_id\nbody\nauthor\nauthor_fullname\nauthor_avatar_url\ntimestamp\ntype\nurl\n...\nnum_media\nlocation_name\nlocation_latlong\nlocation_city\nunix_timestamp\nvideo_file\naudio_file\nduration\nsampling_rate\ntranscript\n\n\n\n\n4\nCzD93SEIi-E\nCzD93SEIi-E\nCzD93SEIi-E\nMitzuarbeiten für unser Land, Bayern zu entwic...\nmarkus.soeder\nMarkus Söder\nhttps://scontent-fra3-1.cdninstagram.com/v/t51...\n2023-10-31 12:06:23\nvideo\nhttps://www.instagram.com/p/CzD93SEIi-E\n...\n1\nNaN\nNaN\nNaN\n1698753983\nCzD93SEIi-E.mp4\nCzD93SEIi-E.mp3\n67.89\n44100.0\nIch bitte auf den abgelagerten Vortrag der Maa...\n\n\n\n\n\n1 rows × 25 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\n\ndf.loc[4, 'transcript']\n\n'Ich bitte auf den abgelagerten Vortrag der Maaßen-Söder-Entfühlen ein.  Erfüllung meiner Amtspflichten, so wahr mir Gott helfe. Ich schwöre Treue der Verfassung des Freistaates Bayern, Gehorsam den Gesetzen und gewissenhafte Erfüllung meiner Amtspflichten, so wahr mir Gott helfe. Herr Ministerpräsident, ich darf Ihnen im Namen des ganzen Hauses ganz persönlich die herzlichsten Glückwünsche aussprechen und wünsche Ihnen viel Erfolg und gute Nerven auch bei Ihrer Aufgabe. Herzlichen Dank.  Applaus'\n\n\nOverall, the transcriptions work well. The first sentence above, however, shows that we still can expect misinterpretations.\nSource: Transcription using Whisper\n\n\nAnalyzing Corpus and Word Frequencies\n\nAmong a variety of possibilities, we can, for example, look at the frequencies of the words contained in the corpus or examine the corpus for recurring themes it contains.\nFirst we need to import all the required libraries once again. The Natural Language Toolkit (NLTK) gives us access to a variety of natural language processing functions (e.g. tokenisation, stop word removal, part-of-speech tagging, …).\n\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport requests\nimport pandas as pd\n\nWhen analysing word frequencies, we can use stop word lists to ignore words that occur frequently but are not relevant to us. We can easily download such a list. However, this can also be individually adapted to the purpose.\n\n# Retrieve Stopwords from Github\nsw_json = requests.get('https://github.com/stopwords-iso/stopwords-de/raw/master/stopwords-de.json')\n\nNow we can tokenise the existing text, remove the stop words or punctuation marks they contain, convert the words to lower case, or use bi-grams in addition to single-word tokens.\nWe then sum up the occurrences of the individual words and make the results available in a DataFrame.\n\ndef word_freq(text, punctuation=False, stop_words = False, lowercasing = False, bigrams = False):\n\n    if punctuation:\n        # Tokenizing, removing punctuation\n        tokens = RegexpTokenizer(r'\\w+').tokenize(text) # https://regexr.com/\n    else:\n        # Tokenizing, w/o removing punctuation\n        # tokens = text.split()\n        tokens = word_tokenize(text)\n\n    if stop_words:\n        # Removing Stopwords\n        tokens = [w for w in tokens if not w.lower() in stop_words]\n\n    if lowercasing:\n        # Lower-Casing\n        tokens = [w.lower() for w in tokens]\n\n    if bigrams:\n        # Converting text tokens into bigrams\n        tokens = nltk.bigrams(tokens)\n\n    # Creating Data Frame\n    freq = nltk.FreqDist(tokens) # display(freq)\n    df = pd.DataFrame.from_dict(freq, orient='index')\n    df.columns = ['Frequency']\n    df.index.name = 'Term'\n\n    # Here we calculate the total number of tokens in our Frequency List\n    total_tokens = sum(freq.values()) # sum([2,3,4,5,6])\n\n    # Here we add a new column `Relative` (*100 for percentage)\n    df['Relative'] = (df['Frequency'] / total_tokens) * 100\n\n    return df\n\n\nfrom pathlib import Path\nimport os\n\n#@markdown Do you want bigrams included?\nbigrams = True #@param {type:\"boolean\"}\n\n#@markdown Should all words get lower cased before counting the occurances?\nlowercasing = True #@param {type:\"boolean\"}\n\n#@markdown Do you want to exclude stopwords in your result list?\nstopwords = True #@param {type:\"boolean\"}\n\n#@markdown Do you want to remove punctuation before counting the occurances?\npunctuation = True #@param {type:\"boolean\"}\n\n\n# Load stopwords file if necessary\nif stopwords:\n    stopwords = sw_json.json()\n\n# Read source file and concat all texts\ntext = ' '.join(list(df[text_column]))\n\n# Call word_freq() with specified parameters\ndf_freq = word_freq(text, punctuation = punctuation, stop_words = stopwords, lowercasing = lowercasing, bigrams = bigrams)\n\n# Sort results for descending values\ndf_freq = df_freq.sort_values(\"Relative\", ascending = False)\n\ndisplay(df_freq[0:10])\n\n\n  \n    \n\n\n\n\n\n\nFrequency\nRelative\n\n\nTerm\n\n\n\n\n\n\n(jüdisches, leben)\n5\n1.259446\n\n\n(allerheiligen, allerseelen)\n4\n1.007557\n\n\n(ilse, aigner)\n3\n0.755668\n\n\n(bayerischer, landtag)\n3\n0.755668\n\n\n(klare, haltung)\n2\n0.503778\n\n\n(wünschen, einfach)\n2\n0.503778\n\n\n(vaters, freundschaftliche)\n2\n0.503778\n\n\n(tod, vaters)\n2\n0.503778\n\n\n(günter, tod)\n2\n0.503778\n\n\n(schwiegervater, günter)\n2\n0.503778\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nWordcloud\nOne way to visualise word frequencies and recurring themes of texts are word clouds. These basically show the most frequently occurring words in the text (similar to the table created earlier), but more frequently occurring words are depicted larger than less frequently occurring words.\nFirst, we have to install the necessary library wordcloud.\n\n!pip install -q wordcloud\n\nThe actual implementation of this approach is relatively simple. We need to combine all the texts into a single text, as we did in the previous step with the frequency analysis, and pass it to the imported library.\n\nfrom wordcloud import WordCloud, STOPWORDS\n\ndef generate_wordcloud(text, path):\n\n    text = ' '.join(list(text))\n\n    # Generate a word cloud image\n    wordcloud = WordCloud(background_color=\"white\",width=1920, height=1080).generate(text)\n\n    # Dazugehörige Grafik erstellen\n    plt.imshow(wordcloud, interpolation=\"bilinear\") # Auflösung/Interpolation der Grafik\n    plt.axis(\"off\")\n    plt.figtext(0.5, 0.1, wordcloud_subcaption, wrap=True, horizontalalignment='center', fontsize=12)\n    plt.savefig(path, dpi=300)\n    plt.show()\n\nOnce again, we have the option of adjusting various parameters. Remember to specify the right file path, file name and column of your text data!\n\n#@markdown Input for additional stopwords; whitespace separated\nstopwords_extension_wc = '' #@param {type: \"string\"}\n\n#@markdown Subcaption for the wordcloud, leave blank to ignore\nwordcloud_subcaption = 'Markus S\\xF6der' #@param {type: \"string\"}\n\nNow all we have to do is load the stop word file, add our own additions and then trigger the creation of the word cloud using the function we created at the beginning.\nThe result image is saved in the defined data_path.\n\nimport matplotlib.pyplot as plt\nimport requests\n\n# Retrieve Stopwords from Github\nr = requests.get('https://github.com/stopwords-iso/stopwords-de/raw/master/stopwords-de.json')\nstop_words = r.json()\n\n# Convert input into list\nstopwords_extension_wc_list = stopwords_extension_wc.split(' ')\nstop_words.extend(stopwords_extension_wc_list)\n\n# Stopwörter in die WordCloud laden\nSTOPWORDS.update(stop_words)\n\n\ngenerate_wordcloud(df[text_column], 'wordcloud.png')\n\n\n\n\nSource: Introduction to Corpus Analysis"
  },
  {
    "objectID": "processing/index.html#conclusion",
    "href": "processing/index.html#conclusion",
    "title": "Text as Data",
    "section": "Conclusion",
    "text": "Conclusion\nIn summary, this session provides us with the practical skills to use Python, pandas, and Jupyter notebooks for the computational analysis of multimodal social media data. Our adherence to Tidy Data principles and the integration of technologies like OCR and Whisper are integral to extract and analyze textual content from multimedia sources. In the next session we will keep exploring the content through a textual lens. Further, we will use prompting as a technique to classify texts as part of a computational content analysis."
  },
  {
    "objectID": "processing/index.html#more-resources",
    "href": "processing/index.html#more-resources",
    "title": "Text as Data",
    "section": "More Resources",
    "text": "More Resources\nPython & Computational Social Sciences\n\nPython for Computational Social Science and Digital Humanities (YouTube)\nIntroduction to Computational Social Science methods with Python (Online)\nIntroduction to Data Science: A Python Approach to Concepts, Techniques and Applications (E-Book)\nR for Data Science (2nd edition) – not Python, but the principles can easily be migrated to pandas.\n\nPython & NLP\n\nNatural Language Processing (Notebook, GESIS CSS)\nWord Frequencies (Online)\nIntroduction Jupyter Notebooks (Online)\nKonchady (2016): Text Mining Application Programming (Somewhat older, still an interesting reading for the basics of computational corpus analysis)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes on Computational Social Media Research",
    "section": "",
    "text": "Welcome to this collection of notes on social media analysis with a special focus on computational methods. It is a work-in-progress website, created as part of my PhD project and teaching at the Media Informatics Group at the University of Regensburg, Germany. My name is Michael Achmann-Denkler and I’m currently experimenting with computational approaches for multimodal analysis of social media content, like Instagram posts and stories. My aim for this website is to develop a collection of notes exploring various methodologies, techniques, and tools for social media research. As a first milestone, the website will accompany my research seminar Computational Analysis of Visual Social Media in the 2023/24 winter semester."
  },
  {
    "objectID": "index.html#content",
    "href": "index.html#content",
    "title": "Notes on Computational Social Media Research",
    "section": "Content",
    "text": "Content\n\nCourse Organization: Introduction to the course including the course schedule.\nIntroduction to Social Media Analysis: Overview of Social Media Analysis (SMA) in academic and professional contexts, focusing on its intersection with communication science, political science, and computational methods.\nTools: A short guide for tools and software beneficial for visual social media analysis. Key tools discussed include Colab, a Google platform for collaborative work using Python and Jupyter notebooks, and Obsidian, a versatile note-taking app with plugins for task organization and literature notes.\nData Collection: Instagram Posts: Code examples and notebooks to collect Instagram posts using instaloader, CrowdTangle, or Zeeschuimer & 4CAT.\nData Collection: Instagram Stories: Code examples and notebooks to collect Instagram posts using instaloader or Zeeschuimer-F.\nData Collection: TikTok (External): Link to the Zeeschuimer & 4CAT manual for TikTok provided by the digital methods initiative.\nText as Data: Provides an overview of using text as a data source in computational social science. It differentiates between structured and unstructured data, emphasizing the complexity of processing unstructured language data.\nText Exploration: Introduces two approaches for the exploration of textual content: Topic Modeling using BERTopic and OpenAI’s GPT-API.\nText Classification: An introduction to text classification using GPT. The article presents several approaches, like Zero-Shot and Few-Shot classification. The accompanying notebook provides all the necessary code to get started with GPT.\nGold Standard Validation: This chapter emphasizes the importance of validation in computational social media analysis, focusing on external validation through non-expert annotations using LabelStudio for creating gold standard data. It discusses developing an annotation manual and setting up a Label Studio project for text data annotation, highlighting the iterative nature of manual development and the importance of clear, consistent guidelines.\nAgreement & Evaluation: Work in Progress.\nExploration of Visual Data: Work in Progress.\nComputational Image Classification: Work in Progress.\nOptimizing Image Classification: Work in Progress.\nData Analysis as a Conversation – Exploring trends using ChatGPT: Work in Progress.\nVisual Presentation of your Data & Results: RAWGraphs and more: Work in Progress."
  },
  {
    "objectID": "index.html#citation-and-licences",
    "href": "index.html#citation-and-licences",
    "title": "Notes on Computational Social Media Research",
    "section": "Citation and Licences",
    "text": "Citation and Licences\nThe website repository is available on GitHub and registered with Zenodo . Please use the citation data provided by Zenodo when quoting parts of this website in academic work. Code examples and computational notebooks are published on the supplement repository, which is also registered with Zenodo . All text content on this website is published under the creative commons attribution (CC-BY) license. All code is released under the GNU GPLv3."
  },
  {
    "objectID": "getting-started/related-work.html",
    "href": "getting-started/related-work.html",
    "title": "Related Work",
    "section": "",
    "text": "While the two visual platforms Instagram and TikTok, are relatively new, plenty of research has already been published about both platforms. A naive search on google scholar for the term instagram analysis results in 4.180.000 results, for tiktok analysis in 54.800 results. We are going to take a look at current literature review studies, concentrating on Instagram. The goal for this chapter is to identify major research areas in (visual) social media research. Beyond themes, trends, and topics, review studies also offer methodological overviews on how to study social media platforms.\nAdditionally, we will explore tools like Publish or Perish that help in creating one’s own literature review. The Related Work section forms a pivotal foundation for high-quality scientific research, and a successful project report."
  },
  {
    "objectID": "getting-started/related-work.html#literature-reviews",
    "href": "getting-started/related-work.html#literature-reviews",
    "title": "Related Work",
    "section": "Literature Reviews",
    "text": "Literature Reviews\nRejeb et al. (2022) compiled a bibliometric analysis of 2,242 publications collected from the Web of Science1 database. They cover publications dated from 2013–2021 and outline 22 prior review studies, most of them concentrating on a smaller scope. Topics of these reviews include: Health, Psychology, Journalism, Mental Health, Body Image, and Marketing. Overall, their bibliographic study found similar themes in the current research: Some articles analyse the use of Instagram in the context of business, marketing, and travel. Others take a psychological angle and look into personality traits or health issues. They also found scholarly articles on privacy concerns and Instagram. Here’s some research interests they encountered in their review:\n\n\nHow does Instagram affect social and health issues, such as social comparison, eating disorders, addiction, and suicidal ideation?\nHow does Instagram facilitate and transform healthcare?\nWhat are the security and privacy concerns that result from the use of Instagram?\nHow does Instagram inter-relate with other social media platforms, such as Facebook and Twitter?\nWhat are the emerging research trends and frontiers in Instagram research?\n\n\nThey found researchers to use a multitude of methods, including surveys and questionnaires; content analysis to examine user-generated content; experimental designs to test the effects of Instagram use on users’ psychological states and behaviors; and qualitative methods, such as interviews and focus groups, to gain in-depth insights into users’ experiences with Instagram.\nInterestingly the bibliometric study seems to overlook a larger portion of research covering political communication on Instagram. Bast (2021) concentrates on this exact topic, she reviewed 37 studies on Instagram usage by politicians, parties, and governments. 30 studies were concerned with the Instagram use of political actors. They explored different aspects, like the self-presentation of politicians, mobilization and campaign information or whether they used Instagram to talk about political issues or interact with voters. Some of the studies use a comparative approach, e.g. comparing the Instagram activity of multiple actors, others compared the Instagram usage of political actors across different countries, political systems, or election/non-election periods (Bast 2021).\nFrom a methodological point of view the review of visual content analysis for image-based social media by Milanesi and Guercini (2020) is quite interesting: They included 29 articles in their study and explored the platforms, that have been invastigated as well as the approach, whether the analysis was manual or automated. Outstanding at first is the large share of projects that have been classified as using automated approaches. Upon closer inspection, they have also classified the use of qualitative data analysis software like NVivo, as automation. Few projects, however, have already been using deep learning and computer vision based approaches for image analysis. Finally, the paper suggests that a mixed methodology that combines a netnographic approach, a research methodology that adapts ethnographic research techniques to the study of online communities, for textual and visual data collection in online communities and textual and visual content analysis may provide new insights for branding or destination management research. Overall, they argue for a combined analysis of textual and visual data. It should be noted, that their review focuses on literature from marketing research.\nOverall, each of the outlined reviews has a different focus. Taken together, they display a large variety of different fields and questions, which Instagram content helps to answer. We can use these literature reviews in two way: We can identify patterns of how to approach social media content, how to operationalize, what questions to ask, what methods to use, and – looking at the future work sections of the reviews and the reviewed papers, where to pick up! Secondly, the literature review helps us to identify interesting literature for our own related work section and reading."
  },
  {
    "objectID": "getting-started/related-work.html#selected-articles",
    "href": "getting-started/related-work.html#selected-articles",
    "title": "Related Work",
    "section": "Selected Articles",
    "text": "Selected Articles\nThrought the next passages I’d like to introduce few interesting pieces. First, I’ll outline some of the first papers concerned with Instagram content. Thereafter we proceed to take a look at Instagram stories and ephemeral content in social media.\nOne of the first analyses of Instagram content was published in 2013: The article explores how the interfaces of social media platforms like Instagram shape user interactions and the creation and sharing of media. Through computational analysis and visualizations of Instagram content, the authors study social and cultural patterns. They compare visual data from 13 global cities and provide a detailed analysis of photos from Tel Aviv, Israel, showing how such visualizations can offer insights into social, cultural, and political activities in specific locales over time​ (Hochman and Manovich 2013).\n\n\n\nScreenshot of the phototrails website visualizing 50.000 images per city.\n\n\nShortly afterwards, in 2014, one of the most cited studies about Instagram was published. It provides a comprehensive analysis of Instagram photo content and user types, using computer vision techniques and clustering. The authors collected Instagram data using the Instagram API and developed a coding scheme for categorizing the photos. They identified eight popular photo categories and five distinct types of Instagram users in terms of their posted photos. They also found that a user’s audience (number of followers) is independent of their shared photos on Instagram. This study was the first in-depth analysis of content and users on Instagram (Hu, Manikonda, and Kambhampati 2014).\n\nInstagram Stories\nStories, as a special format due to their ephemeral nature, and have often been evaded academic research. The freature has been introducted of Instagram Stories in 2016 Leaver, Highfield, and Abidin (2020). An early analysis of stories is part of a master thesis on Snapchat and Instagram: Through qualitative content analysis, observation and in-depth interviews Amancio (2017) found four narrative elements used by Snapchat and Instagram storytellers to tell their stories and construct a narrative. Looking at Instagram specifically, Bainotti, Caliandro, and Gandini (2020) investigated 292 Stories by private users using an ethnographic coding approach. They claim to have identified specific grammars by matching the content and context-of-use, the two main ones are: “a grammar for documentation and a grammar for interaction”. Other areas of interest for stories were ephemeral journalism (Vázquez-Herrero, Direito-Rebollal, and López-Garcı́a 2019) and Female Atheletes’ self-presentation (Li et al. 2021). Finally, just recently Towner and Muñoz (2022) published a first analysis of political communication in Instagram Stories, studying the stories published by the two U.S. presidential candidates in the 2020 campaign. The authors took a marketing perspective, and identified several flaws of the campaign: missed opportunities to share user-generated content, and inconsistencies to communication norms of the ephemeral format.\nOverall, stories have been explored by researchers from different domains. The ephemeral character sticks out in a world where the effort for deleting photos may be more expensive than keeping them (Mayer-Schönberger 2011). Thus, I see potential for many different cultural and societal questions to be answered by looking at this type of content, and great potential for using stories in our semester projects. In contrast to most other social media content, stories need to be collected in real time. This is a challenge for research and limits our questions to material that we may collect throughout the seminar.\n\n\nTikTok\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nI have yet concentrated on literature about Instagram. An update for this section will be the outcome of our seminar!\n\n\n\n\nRecommended Reading\n\n\n\n\n\n\n\n\nReference\nTitle\nNote\n\n\n\n\nBainotti, Caliandro, and Gandini (2020)\nFrom archive cultures to ephemeral content, and back: Studying Instagram Stories with digital methods\nThis paper explores Instagram stories and their collection. The authors conduct a content analysis and derive different grammars for private Instagram stories.\n\n\nHaßler, Kümpel, and Keller (2021)\nInstagram and political campaigning in the 2017 German federal election. A quantitative content analysis of German top politicians’ and parliamentary parties’ posts\nA detailed analysis of the 2017 election campaign showcasing theory-driven operationalization and (manual) content analysis.\n\n\nOmena, Rabello, and Mintz (2020)\nDigital Methods for Hashtag Engagement Research\nIntroduction of a multilayer hashtags engagement research framework paired with the concept of grammars of action. Demonstrates an interesting concept of grouping users.\n\n\nRettberg (2018)\nSnapchat: Phatic Communication and Ephemeral Social Media\nOne of the first scholarly articles on ephemeral stories, originally introduced by Snapchat.\n\n\nSánchez-Querubı́n et al. (2023)\nPolitical TikTok: Playful performance, ambivalent critique and event-commentary\nAn interesting blueprint for doing research of political communication on TikTok; take a special look at the coding variables!\n\n\n…\nto be continued!\n…"
  },
  {
    "objectID": "getting-started/related-work.html#writing-the-related-work-section",
    "href": "getting-started/related-work.html#writing-the-related-work-section",
    "title": "Related Work",
    "section": "Writing the Related Work section",
    "text": "Writing the Related Work section\nThe aim of our project paper diverges somewhat from a comprehensive literature review, such as those that commonly serve as the start for dissertations. Nevertheless, the “Related Work” section of your paper is as an important element of your research project. The goal here is to showcase a thorough understanding of the existing literature in your field of study. This enables you to position your research within the broader academic context, highlighting its relevance and identifying gaps that your project seeks to address. It is important to discuss your findings in this section, offering insights into the methodologies, findings, and limitations of the studies you review. Here are some steps to follow:\n\nAsk yourself: What is your research interest?\n\nWrite down key-words for your research interest.\nUsing the key-words, start your initial search with e.g. the Quick and Dirty strategy. Using the first results, start an in-depth search based on other strategies.\nWrite notes to retain search terms and selected results. Tools like Obsidian or Notion are excelent tools for notes, Excel or Google Sheets are simple, yet efficient, tools to structure your searches and selected literature (and we can export the data as csv files to process them using Python). Publish or Perish is a great tool to help in this stage, as it retains a protocol of your searches and offers the data export of search results.\nConcentrate on reading the abstract in your initial searches. We have to work efficiently, the abstract should contain the most relevant information about a given article for a first evaluation of its importance for your project.\nUse literature management software like Paperpile, Zotero, or Citavi to organize your reading. You might start using the software already at the skimming and abstract reading stage, once the reading starts, however, I would absolutely recommend to add the read articles to the managment software: Keep the PDFs organized using the software, keep your annotations in there, keep your notes in there!\nAt the end of your literature search process, you should be able to write the related work section of your project report and methods section. The related work section is part of your introduction and should include a summary and analysis of the relevant studies and research that has been conducted on your topic. Furthermore, your method section should ideally contain references to previous studies that have used similar methods or approaches.\n\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nAs a warm-up with ChatGPT / GPT we will extract information from abstracts in out tools session. The notebook will be added shortly, you will be able to use this approach with Publish or Perish lists.\n\n\n\nPublish or Perish\nPublish or Perish is a neat piece of software, that helps documenting your literature review process. It provides a unified interface to a majority of databases. Each search can be saved, multiple searches can be organized into folders. Additionally, the results can be exported to different formats. Thus, Publish or Perish is also a good starting point for AI-Assisted literature reviews.\n\n\n\n\n\n\n\nConnected Papers\nConnected Papers is one of my favorite tools for literature reseraches. Paste any DOI into the search field and the tool will create a graph of the article, linking the cited literature as well as incorporating newer literature that cites the work that you’ve been looking for. Using colors and node sizes all data is visualised neatly.\n\n\n\nAI Tools\nOver the past months, several AI Literature Review tools have been released:\n\nPerplexity incorporates GPT-3 (GPT-4 and Claude-2 in the pro version) and offers a chat interface. You can ask any question, it starts answering your question based on sources which are provided in the interface.\nElicit works somewhat differently, it expects you to ask a research question and tries to answer you question based on papers and has the ability to extract different type of information from papers automatically. In my experience the system does not work that well for social science questions.\nChatPDF is one of many tools that allow to upload PDF files, process them, and allow to chat with their content. In my experience it works rather well. However, as with all AI tools, we should be careful to manually verify the responses. The tool returns a link to the text anchor it refers to for answers. Overall, I recommend this tool for refinding information in papers that you’ve already read, or as a companion for skimming papers – although you might miss out important information!\nLangChain and LlamaIndex are python package that help building applications like ChatPDF yourself.\n\n\n\n\nReferences\n\n\nAmancio, Marina. 2017. “‘Put it in your Story’: Digital Storytelling in Instagram and Snapchat Stories.” PhD thesis. https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1111663&dswid=-5700.\n\n\nBainotti, Lucia, Alessandro Caliandro, and Alessandro Gandini. 2020. “From archive cultures to ephemeral content, and back: Studying Instagram Stories with digital methods.” New Media & Society, September, 1461444820960071. https://doi.org/10.1177/1461444820960071.\n\n\nBast, Jennifer. 2021. “Politicians, Parties, and Government Representatives on Instagram: A Review of Research Approaches, Usage Patterns, and Effects.” Review of Communication Research 9 (July). https://www.rcommunicationr.org/index.php/rcr/article/view/108.\n\n\nHaßler, Jörg, Anna Sophie Kümpel, and Jessica Keller. 2021. “Instagram and political campaigning in the 2017 German federal election. A quantitative content analysis of German top politicians’ and parliamentary parties’ posts.” Information, Communication and Society, July, 1–21. https://doi.org/10.1080/1369118X.2021.1954974.\n\n\nHochman, Nadav, and Lev Manovich. 2013. “Zooming into an Instagram City: Reading the local through social media.” First Monday, June. https://doi.org/10.5210/fm.v18i7.4711.\n\n\nHu, Yuheng, Lydia Manikonda, and Subbarao Kambhampati. 2014. “What We Instagram: A First Analysis of Instagram Photo Content and User Types.” Proceedings of the International AAAI Conference on Web and Social Media 8 (1): 595–98. https://doi.org/10.1609/icwsm.v8i1.14578.\n\n\nLeaver, Tama, Tim Highfield, and Crystal Abidin. 2020. Instagram: Visual Social Media Cultures. John Wiley & Sons.\n\n\nLi, Bo, Olan K M Scott, Michael L Naraine, and Brody J Ruihley. 2021. “Tell Me a Story: Exploring Elite Female Athletes’ Self-Presentation via an Analysis of Instagram Stories.” Journal of Interactive Advertising 21 (2): 108–20. https://doi.org/10.1080/15252019.2020.1837038.\n\n\nMayer-Schönberger, Viktor. 2011. Delete: The Virtue of Forgetting in the Digital Age. Princeton University Press.\n\n\nMilanesi, Matilde, and Simone Guercini. 2020. “Image-based Social Media and Visual Content Analysis: Insights from a Literature Review.” Micro & Macro Marketing, no. 3: 537–58. https://ideas.repec.org/a/mul/jyf1hn/doi10.1431-97640y2020i3p537-558.html.\n\n\nOmena, Janna Joceli, Elaine Teixeira Rabello, and André Goes Mintz. 2020. “Digital Methods for Hashtag Engagement Research.” Social Media + Society 6 (3): 2056305120940697. https://doi.org/10.1177/2056305120940697.\n\n\nRejeb, Abderahman, Karim Rejeb, Alireza Abdollahi, and Horst Treiblmaier. 2022. “The big picture on Instagram research: Insights from a bibliometric analysis.” Telematics and Informatics 73 (September): 101876. https://doi.org/10.1016/j.tele.2022.101876.\n\n\nRettberg, Jill Walker. 2018. “Snapchat: Phatic Communication and Ephemeral Social Media.” In Appified: Culture in the Age of Apps, edited by Jeremy Wade Morris and Sarah Murray, 188–95. “University of Michigan Press.”\n\n\nSánchez-Querubı́n, Natalia, Shuaishuai Wang, Briar Dickey, and Andrea Benedetti. 2023. “Political TikTok: Playful performance, ambivalent critique and event-commentary.” In The Propagation of Misinformation in Social Media, edited by Richard Rogers, 187–206. A Cross-Platform Analysis. Amsterdam University Press. https://doi.org/10.2307/jj.1231864.12.\n\n\nTowner, Terri L, and Caroline Lego Muñoz. 2022. “A Long Story Short: An Analysis of Instagram Stories during the 2020 Campaigns.” Journal of Political Marketing, July, 1–14. https://doi.org/10.1080/15377857.2022.2099579.\n\n\nVázquez-Herrero, Jorge, Sabela Direito-Rebollal, and Xosé López-Garcı́a. 2019. “Ephemeral Journalism: News Distribution Through Instagram Stories.” Social Media + Society 5 (4): 2056305119888657. https://doi.org/10.1177/2056305119888657."
  },
  {
    "objectID": "getting-started/related-work.html#footnotes",
    "href": "getting-started/related-work.html#footnotes",
    "title": "Related Work",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAccessible via VPN / on campus (when connected to eduroam).↩︎"
  },
  {
    "objectID": "getting-started/theory.html",
    "href": "getting-started/theory.html",
    "title": "Introduction to SMA",
    "section": "",
    "text": "Social Media Analyses (SMA) are used both, in academia and in professional settings. Depending on the research agenda, different methodologies may be applied (Kanthawala et al. 2022; Rejeb et al. 2022). In our course, we focus on the academic exploration of Social Media. We place particular emphasis on questions related to media, politics, and society. This represents a confluence of communication science and political science, intertwined with computational methods."
  },
  {
    "objectID": "getting-started/theory.html#social-media-analyses-in-different-contexts",
    "href": "getting-started/theory.html#social-media-analyses-in-different-contexts",
    "title": "Introduction to SMA",
    "section": "Social Media Analyses in different contexts",
    "text": "Social Media Analyses in different contexts\nBridging this discussion, there are several disciplines pivotal to the academic analysis of social media data at this intersection: Lazer et al. (2009) outlined in an influencial article computational social science as an emerging field that built on the ability to collect and analyze vast amounts of data. The goal of the computational social science, according to this article, is to reveal patterns in human interactions, benefiting from various data sources such as emails, phone records, online social networks, and other digital traces left by individuals. We are going to concentrate on social media data, a type of data described by Quan-Haase and Sloan (2022a) as incidental, since the data exists and is being created, no matter the researchers observing them – or not. One special type of data, Instagram stories, even have an ephemeral character. 24 hours after posting the story expires – becoming invisible for followers and researchers alike (see also Leaver, Highfield, and Abidin 2020 on the importance of stories). Atteveldt and Peng (2018) noted a surge in the use of computational methods in communication science, attributing it to three primary factors: the availability of digital data, sophisticated data analysis tools, and the emergence of cost-effective, potent processing capabilities complemented by accessible computing infrastructure. Building on this perspective, Haim (2023) sees the computational communication science as a sub-discipline of communication science that addresses digitally altered objects of research, which require computational approaches to tackle to amount and complexity of this special type of data.\nIn the realm of digital humanities, computational approaches to text analysis have a long history, influenced by concepts such as distant reading (Moretti 2000) and macroanalysis (Jockers 2013). Manovich picks up these concepts in his cultural analytics, see below. Lately also distant viewing has been outlined, as “a methodological and theoretical framework for the study of large collections of visual materials” (Arnold and Tilton 2019). I see potential in integrating approaches and methods from the digital humanities into social media analysis. Vice versa, there’s also potential in utilizing methods used for social media analysis to address questions in the humanities.\nChallenges for social media analyses have been outlined by Quan-Haase and Sloan (2022a): the role of theory, representativeness of data, scale, multimodality, data accessability, and legal and ethical considerations. Through our semester we are going to work on several of those challenges: In the Operationalization session we are going to talk about data-driven approaches (bearing in mind Anderson et al. 2008), as well as theories as basis for your research questions and operationalizations. The representativeness of data will be the challenge for our data collection sessions: We will not just answer how to collect data, but also what data to collect. The two challenges left are at the centre of our seminar: Our answer for the challenge of scale is to apply computational methods for data analysis, to process data at scale. Multimodality is another key issues of this seminar: We want to computationally process visual (or multimodal) data. We will talk about accessability problems throughout our data collection classes, and talk about legal and ethical issues on this page.\nKeeping these introductory considerations in mind, we immerse into a short outline of two theories: Cultural Analytics and Digital Methods, as foundational elements for social media research. Subsequently, we’ll address the ethical and legal challenges associated with analyzing social media. We’ll conclude the chapter by presenting an array of methodologies. In the related work chapter, you’ll find an overview of research on Instagram and TikTok content, even extending beyond our primary topics of interest.\n\n\n\n\n\n\nNote\n\n\n\nThe intent of this article is to provide a brief introduction to the field of computational social media analysis, tailored for my Winter 2023/24 seminar. It offers only a cursory glance at various theories and methodologies. As such, please do not regard the content of this page as a definitive scientific piece. Instead, view it as a compass to guide and inspire your own research endeavors. For a deeper dive into the theory of Digital Media in Politics and Society see the lecture by Prof. Jungherr."
  },
  {
    "objectID": "getting-started/theory.html#cultural-analytics",
    "href": "getting-started/theory.html#cultural-analytics",
    "title": "Introduction to SMA",
    "section": "Cultural Analytics",
    "text": "Cultural Analytics\nCultural analytics, as explained in the introductory chapter of the book “Cultural Analytics” by Lev Manovich, is a field that uses computers to analyze and understand large amounts of cultural information or “big cultural data”. This might include exploring big collections of images, videos, or other media data to see patterns and trends that are happening in digital culture. Manovich talks about some key questions and challenges in cultural analytics. For example, one big question is whether we should focus on finding common themes and patterns in our data, or whether we should pay more attention to things that are unusual or rare. Also, while cultural analytics can be a powerful tool for understanding aspects of culture, especially in the digital world, Manovich tells us to be aware of its limits. He says that computers and data analysis can tell us a lot, but they can’t understand culture in the rich and deep way that humans can, especially when it comes to understanding things like aesthetics (beauty, style, etc.). So, while cultural analytics can help us see large scale patterns and trends in culture, Manovich advises us to also appreciate and be aware of what it can’t see or understand. The field of cultural analytics then becomes a space where we use computational tools to explore and question culture, while also being mindful of the limitations and challenges of using these tools (Manovich 2020)."
  },
  {
    "objectID": "getting-started/theory.html#digital-methods",
    "href": "getting-started/theory.html#digital-methods",
    "title": "Introduction to SMA",
    "section": "Digital Methods",
    "text": "Digital Methods\n“Digital Methods,” as introduced by Rogers (2013), proposes a paradigm wherein the internet is both a site and a source for research, especially for social media studies. Unlike conventional research approaches that see the internet merely as a tool or data source, Rogers advocates for a methodology that is intrinsically web-centric, understanding and employing the unique dynamics and mechanics of the digital medium itself. An example for a digital methods research project is understanding algorithmic operations, especially of search engines like Google, and comprehending their impact on digital culture, information accessibility, and user engagement. This perspective is important to explore the foundations of how information is organized, ranked, and accessed online. Studying the digital medium itself means to study web-native phenomena such as hyperlink networks, search engine behaviors, and social media activities to uncover patterns, tendencies, and hierarchical structures within digital cultures and societies.\nThe concepts of cultural analytics and digital methods will guide us through our semester and our projects: We borrow the idea to use computational methods in order to understand “big cultural data” form Manovich and the concept of studying the digital medium itself from Rogers. Throughout the semester will enrich our projects through your own literature and theory based on the research interests. Beyond these foundations, we will borrow from i.e. the Computational Social Sciences (Lazer et al. 2009), the concept of Distant Viewing (Arnold and Tilton 2019), or Grammars of Action (Agre 1994; Gerlitz and Rieder 2018; Bainotti, Caliandro, and Gandini 2020; Omena, Rabello, and Mintz 2020), and Platform Vernaculars (Gibbs et al. 2015)."
  },
  {
    "objectID": "getting-started/theory.html#legal-ethical-challenges",
    "href": "getting-started/theory.html#legal-ethical-challenges",
    "title": "Introduction to SMA",
    "section": "Legal & Ethical Challenges",
    "text": "Legal & Ethical Challenges\n\n\n\n\n\n\nWarning\n\n\n\nThis subchapter scratches the surface. Recommended reading: Haim (2023) pp. 62–69; 126–128.\n\n\nWhen working with social media data, we’re dealing with personal information. As such we need to take into account legal and ethical considerations. From the legal perspective we need to focus on two aspects: The ownership of the data, and – when dealing with personal data – the GDPR. For the latter we need to take into account consent and should think about pseudonymisation or anonymisation of our data (Haim 2023). Further, the German Urheberrecht, the equivalent of the anglo-saxon copyright law (there are important differences, see Bundeszentrale für politische Bildung for a synopsis), defines exceptions for scientific research: I recommend the publication by Rat für Sozial- und Wirtschaftsdaten (RatSWD) (2019) which takes a closer look at the database law and provides some practical guidance (more in our slides).\nThe importance of the legal perspective social media research grew recently: Following the Cambridge Analytica scandal Meta platforms (like Instagram) started closing down on APIs, which would have offered a legal and accepted (by the plattform) point of access for researchers. I recommend to read McCrow-Young’s (2021) article, as she demonstrates how academic research may be interrupted by platform changes, like the closure of the Instagram-API in the wake of above incident. Post-API social media research found creative ways to access the data: Bainotti, Caliandro, and Gandini (2020), for example, took a unique approach for data collection by capturing Instagram content through YouTube videos. Recent publications on Instagram analyses, and most approaches in our future session, rely on crawling and scraping. Venturini and Rogers (2019) see a chance in the API-closure and argue that these techniques are “more than a ‘necessary evil’”, as it might force researchers to come back to (digital) field work.\nFinally a word about reserach ethics. While the GDPR provides a rigid legal framework for dealing with personal information, I’d like to recommend the article “But the Data is Already Public” by Zimmer (2010). The article documents how, in a matter of days, an anonymous dataset of 1700 facebook profiles became (partly) deanonymized. Based on this case study, the author compiles ethical concerns for future research, which we should also incorporate into our work."
  },
  {
    "objectID": "getting-started/theory.html#methodology",
    "href": "getting-started/theory.html#methodology",
    "title": "Introduction to SMA",
    "section": "Methodology",
    "text": "Methodology\nIn this chapter we are going to take a look at different methods for use with social media research, and particularly, with our projects. We are going to use (Visual) Content Analysis to understand the content of posts and stories. The concept of Plattform Affordances will help us understand these posts and stories as embedded in the platform and its available functions and options. Finally, the idea of Platform Vernaculars & Grammars serves as a guide to wire everything up, to discover patterns and trends in how users communicate and engage on these platforms.\n\n(Visual) Content Analysis\nWe are going to apply quantitative content analyses to our corpora. For a quantitative approach we are going to operationalize our theory-based interests and questions using formal and / or content features. Next, we need to apply the operationalization to the documents, in form of human annotations or computational coding (see Döring and Bortz 2016). Döring and Bortz (2016) outline a general approach to content analysis, Rose (2016) in contrast concentrates on visual content analyses. She suggests four steps:\n\n\n“Finding your Images.\nDevising your categories for coding.\nCoding the images.\nAnalysing the results.” – (Rose 2016 ch. 5)\n\n\nThe challenge of the first step is the sampling: Even with computational approaches, is it feasible to collect everything? The cultural analytics approach suggests such a goal, e.g. in order to obtain data and traces of subcultures. Due to practical limitations also Manovich’s works use an approach to break the large amount of available data into a smaller portion (see Hochman and Manovich 2013). This approach is called sampling, Rose (2016) introduces several sampling approaches like random, stratified, systematic, or cluster sampling. Döring and Bortz (2016) provide a deeper look into sampling strategies.\nThe codes, for the second step, may be devised from a qualitative exploration of the data or theories and related work. In context of our projects we are going to use both approaches: We will annotate a subset of our data as ground-truth while coding the total data using computational approaches. On code development there exists another large body of literature, like the Grounded Theory (e.g. Corbin and Strauss 2008) and Ethnic Coding Approach (Altheide 1987).\nFor the final analysis we are going to apply statistical data analyses. For an initial understanding of our data we will start with some exploratory analyses, e.g. plotting the data. In combination with the two approaches below, the platform affordances and platform vernaculars & grammars we may discover patterns of social media use. In most cases, our projects will compare different groups: These groups might be different user types (e.g. Politician Accounts vs. Party Accounts), or different Posts types (e.g. Posts vs. Stories), or different platforms (e.g. Instagram vs. TikTok).\n\n\nPlatform Affordances\nBossetta (2018) provides an overview of the concept of affordances and their application in social media analyses. He traces the term back to boyd and Papacharissi & Yuan who argued “that digital communication tech- nologies provide structural affordances to agents” (p. 473 Bossetta 2018). There are two important take-aways from his work: 1) The concept of affordances is not used consistently, and 2) the platforms shape affordances and thereby how users interact with the platform. Bainotti, Caliandro, and Gandini (2020) used the “Instagram-specific digital objects” as codes for their analysis of stories, linking the concept of affordances in the context of Instagram to the use of stickers.\nIn the context of our seminar we might consider the following elements as platform affordances:\n\n\n\nTikTok\nIG – Posts\nIG – Stories\n\n\n\n\nLikes\nLikes\nSliders\n\n\nComments\nComments\nVotes\n\n\nShares\nViews\nQuestions\n\n\nMusic\nMentions\nMentions\n\n\nHashtags\nHashtags\nHashtags\n\n\n…\n…\nLocations\n\n\n\n\n…\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDid you spot the difference between some of the listed affordances? Likes and comments, for instance, are reactions to posts. Would you consider these features as affordances? Let’s discuss this is in class!\n\n\n\n\nPlatform Vernaculars & Grammars\nPrevious studies have looked into ‘grammars’ in Instagram stories. Originally linked to research on privacy (Agre 1994), grammars classify activities using specific types, making data collection and analysis easier. This uncovers patterns in user behavior, beneficial for purposes such as advertising. To the best of my knowledge, this concept was first used for social media data by Gerlitz and Rieder (2018) in a Twitter study.\nOmena, Rabello, and Mintz (2020) discussed a “grammar of hashtags”, referring to the rules of hashtag use and how they’re organized on platforms. They suggest that hashtags, content visibility, and the nature of the content itself are essential in understanding hashtag use. Meanwhile, Bainotti, Caliandro, and Gandini (2020) used grammars to understand Instagram Stories, focusing on visual elements and their cultural meanings.\nLastly, Gibbs et al. (2015) examined the unique styles and logics of social media, termed “platform vernaculars”. These are influenced both by platform features and user habits."
  },
  {
    "objectID": "getting-started/theory.html#summary",
    "href": "getting-started/theory.html#summary",
    "title": "Introduction to SMA",
    "section": "Summary",
    "text": "Summary\nIn this chapter we have positioned ourselves between several disciplines: The computational social science, computational communication science, and digital humanities. In this position, we see social media data as trace data of human and social behaviour. The digitalness of our subject is, however, just one side of the coin: Follwing the theoretical frameworks of Digital Methods and Cultural Analytics, we want to conduct our analyses computationally with the aim to uncover patterns and trends of user behaviour on social media plattforms. Methodologically we can draw from quantitative content analysis, and the concept of platform affordances as features, and apply the concept of platform vernaculars and grammars to make sense of these features."
  },
  {
    "objectID": "getting-started/theory.html#additional-resources",
    "href": "getting-started/theory.html#additional-resources",
    "title": "Introduction to SMA",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nConferences\n\nInternational Conference on Social Media & Society\nIC²S² 2022\nICWSM\nAoIR\nWebSci\nInternational Conference on CMC and Social Media Corpora for the Humanities\n\n\n\nJournals\n\nNew Media & Society\nBig Data & Society\n\n\n\nTextbooks\n\nRose (2016): Visual Methodologies: An Introduction to Researching with Visual Materials.\nHaim (2023): Computational Communication Science: Eine Einführung.\nQuan-Haase and Sloan (2022b): The SAGE handbook of social media research methods.\n\n\n\nOnline Resources\n\nRichard Rogers: Social Media Research with Digital Methods (YouTube)\n\n\n\n\n\n\n\nNote\n\n\n\nDo you know of any ressources to be added to this list? Drop me a line: michael.achmann@ur.de.\n\n\n\n\n\nReferences\n\n\nAgre, Philip E. 1994. “Surveillance and capture: Two models of privacy.” The Information Society 10 (2): 101–27. https://doi.org/10.1080/01972243.1994.9960162.\n\n\nAltheide, David L. 1987. “Reflections: Ethnographic content analysis.” Qualitative Sociology 10 (1): 65–77. https://doi.org/10.1007/BF00988269.\n\n\nAnderson, Chris, Medea Giordano, Matt Jancer, Philip Ball, Will Knight, Sassafras Lowrey, and Laurence Scott. 2008. “The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.” Wired, June. https://www.wired.com/2008/06/pb-theory/.\n\n\nArnold, Taylor, and Lauren Tilton. 2019. “Distant viewing: analyzing large visual corpora.” Digital Scholarship in the Humanities 34 (Supplement_1): i3–16. https://doi.org/10.1093/llc/fqz013.\n\n\nAtteveldt, Wouter van, and Tai-Quan Peng. 2018. “When Communication Meets Computation: Opportunities, Challenges, and Pitfalls in Computational Communication Science.” Communication Methods and Measures 12 (2-3): 81–92. https://doi.org/10.1080/19312458.2018.1458084.\n\n\nBainotti, Lucia, Alessandro Caliandro, and Alessandro Gandini. 2020. “From archive cultures to ephemeral content, and back: Studying Instagram Stories with digital methods.” New Media & Society, September, 1461444820960071. https://doi.org/10.1177/1461444820960071.\n\n\nBossetta, Michael. 2018. “The Digital Architectures of Social Media: Comparing Political Campaigning on Facebook, Twitter, Instagram, and Snapchat in the 2016 U.S. Election.” Journalism & Mass Communication Quarterly 95 (2): 471–96. https://doi.org/10.1177/1077699018763307.\n\n\nCorbin, Juliet M, and Anselm L Strauss. 2008. Basics of qualitative research: techniques and procedures for developing grounded theory. Sage Publications, Inc.\n\n\nDöring, Nicola, and Jürgen Bortz. 2016. Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-642-41089-5.\n\n\nGerlitz, and Rieder. 2018. “Tweets are not created equal: Investigating Twitter’s client ecosystem.” International Journal of Communication Systems, no. 12: 528–47. https://pure.uva.nl/ws/files/23266519/5974_30096_2_PB.pdf.\n\n\nGibbs, Martin, James Meese, Michael Arnold, Bjorn Nansen, and Marcus Carter. 2015. “#Funeral and Instagram: death, social media, and platform vernacular.” Information, Communication and Society 18 (3): 255–68. https://doi.org/10.1080/1369118X.2014.987152.\n\n\nHaim, Mario. 2023. Computational Communication Science: Eine Einführung. Springer Fachmedien Wiesbaden.\n\n\nHochman, Nadav, and Lev Manovich. 2013. “Zooming into an Instagram City: Reading the local through social media.” First Monday, June. https://doi.org/10.5210/fm.v18i7.4711.\n\n\nJockers, Matthew L. 2013. Macroanalysis: Digital Methods and Literary History. University of Illinois Press.\n\n\nKanthawala, Shaheen, Kelley Cotter, Kali Foyle, and J R Decook. 2022. Proceedings of the 55th Hawaii international conference on system sciences. Proceedings of the ... Annual Hawaii International Conference on System Sciences. Annual Hawaii International Conference on System Sciences. Hawaii International Conference on System Sciences. https://doi.org/10.24251/hicss.2022.000.\n\n\nLazer, David, Alex Pentland, Lada Adamic, Sinan Aral, Albert-Laszlo Barabasi, Devon Brewer, Nicholas Christakis, et al. 2009. “Social science. Computational social science.” Science 323 (5915): 721–23. https://doi.org/10.1126/science.1167742.\n\n\nLeaver, Tama, Tim Highfield, and Crystal Abidin. 2020. Instagram: Visual Social Media Cultures. John Wiley & Sons.\n\n\nManovich, Lev. 2020. Cultural Analytics. MIT Press.\n\n\nMcCrow-Young, Ally. 2021. “Approaching Instagram data: reflections on accessing, archiving and anonymising visual social media.” Communication Research and Practice 7 (1): 21–34. https://doi.org/10.1080/22041451.2020.1847820.\n\n\nMoretti, Franco. 2000. “Conjectures on World Literature.” New Left Review II (1): 54–68. https://newleftreview.org/issues/ii1/articles/franco-moretti-conjectures-on-world-literature.\n\n\nOmena, Janna Joceli, Elaine Teixeira Rabello, and André Goes Mintz. 2020. “Digital Methods for Hashtag Engagement Research.” Social Media + Society 6 (3): 2056305120940697. https://doi.org/10.1177/2056305120940697.\n\n\nQuan-Haase, Anabel, and Luke Sloan. 2022a. “Chapter 1: Introduction.” In The SAGE handbook of social media research methods, edited by Anabel Quan-Haase and Luke Sloan, 2nd ed., 1–9. London, England: SAGE Publications. https://doi.org/10.4135/9781529782943.\n\n\n———. 2022b. The SAGE handbook of social media research methods. Edited by Anabel Quan-Haase and Luke Sloan. 2nd ed. London, England: SAGE Publications. https://doi.org/10.4135/9781529782943.\n\n\nRat für Sozial- und Wirtschaftsdaten (RatSWD). 2019. “Big Data in den Sozial-, Verhaltens- und Wirtschaftswissenschaften: Datenzugang und Forschungsdatenmanagement - Mit Gutachten \"Web Scraping in der unabhängigen wissenschaftlichen Forschung\".” RatSWD Output. German Data Forum ( RatSWD). https://doi.org/10.17620/02671.39.\n\n\nRejeb, Abderahman, Karim Rejeb, Alireza Abdollahi, and Horst Treiblmaier. 2022. “The big picture on Instagram research: Insights from a bibliometric analysis.” Telematics and Informatics 73 (September): 101876. https://doi.org/10.1016/j.tele.2022.101876.\n\n\nRogers, Richard. 2013. Digital Methods. MIT Press.\n\n\nRose, Gillian. 2016. Visual Methodologies: An Introduction to Researching with Visual Materials. SAGE Publications.\n\n\nVenturini, Tommaso, and Richard Rogers. 2019. “‘API-Based Research’ or How can Digital Sociology and Journalism Studies Learn from the Facebook and Cambridge Analytica Data Breach.” Digital Journalism 7 (4): 532–40. https://doi.org/10.1080/21670811.2019.1591927.\n\n\nZimmer, Michael. 2010. “\"But the Data is Already Public\": On the Ethics of Research in Facebook.” Ethics and Information Technology 12 (4): 313–25. https://doi.org/10.1007/s10676-010-9227-5."
  },
  {
    "objectID": "getting-started/literature-review-assistant.html",
    "href": "getting-started/literature-review-assistant.html",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "This notebook demonstrates how to work with the GPT-API based on a simple use case. First, we are going to import search results of our literature review with Publish or Perish. Next, we are going to explore how we could use python in combination with Publish or Perish to speed up our review process: We will manually code the relevance, using the Jupyter notebook as our labelling interface. Afterwards we are going to add a GPT-API call to extract features from the abstract, the first step towards our assistant guiding our literature review process.\nOverall, this notebooks is a simple implementation demonstrating how prompts work and how easy it is to use GPT in Jupyter notebooks. The notebook is available in the supplement repository, you can clone the notebook to your Colab account with one click.\n\n\nAt first we need to install necessary packages. Hit run and wait.\n\nprint(\"Install Packages\")\n!pip install -q openai crossref-commons\n\n\n\n\nIf this is the start of your review process, upload the csv file exported from Publish or Perish in the left-hand Files pane. Enter the filename in publish_or_perish_file_name. Define the output name in file_name. If you want to save the imported file in the google drive add /content/drive/MyDrive/ to the path.  Skip this cell if you want to work with a file that has been imported in the past.\n\n\n\n\n\n\nWarning\n\n\n\nWe delete rows with missing DOIs. Without a DOI our code cannot retrieve abstracts. When importing the Publish or Perish file, the following code will display the number of rows that have been deleted due to missing DOIs. When using this notebook for real-world projects, you should be aware of the missing rows and manually review them!\n\n\n\n#@title Import from Publish or Perish Data.\n#@markdown If this is the start of your review process, upload the `csv` file exported from [Publish or Perish](https://harzing.com/resources/publish-or-perish) in the left-hand *Files* pane. Enter the filename in `publish_or_perish_file_name`. Define the output name in `file_name`. If you want to save the imported file in the google drive add `/content/drive/MyDrive/` to the path. &lt;br/&gt; **Skip this cell if you want to work with a file that has been imported in the past.**\n\nimport pandas as pd\nimport numpy as np\nimport io\n\npublish_or_perish_file_name = \"scholar.csv\" # @param {type: \"string\"}\nfile_name = \"2023-10-31-Literature-Review.csv\" # @param {type: \"string\"}\n\n# Initialize empty DataFrame\nall_data = pd.DataFrame()\n\n\ntry:\n    all_data = pd.read_csv(publish_or_perish_file_name)\n\n    # Remove Duplicates\n    initial_len = len(all_data)\n    all_data = all_data.drop_duplicates(subset='DOI', keep='first')\n    removed_len = initial_len - len(all_data)\n    print(f'Removed {removed_len} duplicates based on DOI.')\n\n    # Remove missing DOIs\n    initial_len = len(all_data)\n    all_data = all_data[~pd.isna(all_data['DOI'])]\n    removed_len = initial_len - len(all_data)\n    print(f'Removed {removed_len} rows without DOI.')\n\n    all_data = all_data.sort_values(by='Cites', ascending=False).reset_index(drop=True)\n\n    print('Sorted Table by Cites.')\n\n    # Create empty columns for Literature Review\n    all_data[\"Relevant\"] = \"\"\n    all_data[\"Notes\"] = \"\"\n    all_data[\"Checked\"] = False\n\n    print('Initialized Columns')\n\n    all_data.to_csv(file_name)\n    print(f\"Success: Saved data to {file_name}\")\n\n    print(f'Success: Data loaded from File \"{file_name}\".')\nexcept Exception as e:\n    print(f\"Error: Failed to load data from File. {str(e)}\")\n\nRemoved 172 duplicates based on DOI.\nRemoved 1 rows without DOI.\nSorted Table by Cites.\nInitializes Columns\nSuccess: Saved data to 2023-10-31-Literature-Review.csv\nSuccess: Data loaded from File \"2023-10-31-Literature-Review.csv\".\n\n\n\n\n\nIf you want to keep going with a former review process, we can read an uploaded file / a file from google drive. Only run one cell, this one or the above.\n\n#@title Read previously imported File\n#@markdown If you want to keep going with a former review process, we can read an uploaded file / a file from google drive. **Only run one cell, this one or the above.**\nimport pandas as pd\nimport numpy as np\nimport io\n\nfile_name = \"2023-10-31-Literature-Review.csv\" # @param {type: \"string\"}\n\ntry:\n    all_data = pd.read_csv(file_name)\n\n    print(f'Success: Data loaded from File \"{file_name}\".')\nexcept Exception as e:\n    print(f\"Error: Failed to load data from File. {str(e)}\")\n\nSuccess: Data loaded from File \"2023-10-31-Literature-Review.csv\".\n\n\n\nIn this example we’ve saved the file locally. When working with Colab, the file will be deleted when we disconnect. For colab you should link your google drive (open the files pane on the left, click the Google Drive button). Once connected, save the file in the folder /content/drive/MyDrive/YOUR-FILENAME.csv. It will be accessible through Drive, and Colab is from now on going to connect automatically to drive.\nCheck the imported data. We’re using pandas, the imported data is saved in the all_datavariable. head(2)displays the two top rows of the table. Additionally, we have added three columns: Relevant, Notes, and Checked. We are going to make use of them to keep track of our progress.\n\n# Check the structure (and content) of the file\nall_data.head(2)\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0.2\nUnnamed: 0.1\nUnnamed: 0\nCites\nAuthors\nTitle\nYear\nSource\nPublisher\nArticleURL\n...\nAge\nAbstract\nFullTextURL\nRelatedURL\nbabbage_similarity\nbabbage_search\nsimilarities\nRelevant\nNotes\nChecked\n\n\n\n\n0\n0\n746\n844\n21\nFlorian Arendt\nSuicide on Instagram – Content Analysis of a G...\n2019.0\nCrisis\nHogrefe Publishing Group\nhttp://dx.doi.org/10.1027/0227-5910/a000529\n...\n3.0\nAbstract. Background: Suicide is the second le...\nhttps://econtent.hogrefe.com/doi/pdf/10.1027/0...\nNaN\n[-0.0018475924152880907, 0.022463073953986168,...\n[-0.014954154379665852, 0.026176564395427704, ...\n-1\nNaN\nNaN\nFalse\n\n\n1\n1\n770\n868\n4\nPaloma de H. Sánchez-Cobarro, Francisco-Jose M...\nThe Brand-Generated Content Interaction of Ins...\n2020.0\nJournal of Theoretical and Applied Electronic ...\nMDPI AG\nhttp://dx.doi.org/10.3390/jtaer16030031\n...\n2.0\nThe last decade has seen a considerable increa...\nhttps://www.mdpi.com/0718-1876/16/3/31/pdf\nNaN\n[-0.0029447057750076056, 0.01190990675240755, ...\n[-0.01012819167226553, 0.02539714053273201, -0...\n-1\nNaN\nNaN\nFalse\n\n\n\n\n\n2 rows × 35 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nIn the next step we are going to start our literature review:\n\nWe filter for the first unchecked row, ordered by the cite count.\nWe retrieve the abstract from CrossRef API using the DOI.\nWe display all information\nWe answer whether the paper appear to be relevant by entering y or n for yes or no.\n\nFor our session, the cell only runs through one row and finishes afterwards. For a real world application you’d probably like to add some kind of loop.\n\nfrom crossref_commons.retrieval import get_publication_as_json\nimport json\nimport openai\nimport textwrap\nimport IPython\nimport re\n\n# Get one row: Not checked, highest Citation count.\nhighest_cites_unchecked = all_data[all_data['Checked'] == False].sort_values(by=\"Cites\", ascending=False).iloc[0]\nindex = highest_cites_unchecked.name\n\n# Retrieve Abstract from Crossref\nresponse = get_publication_as_json(highest_cites_unchecked['DOI'])\nabstract = response.get(\"abstract\", \"\")\n\n# Remove XML\nabstract = re.sub(r'&lt;[^&gt;]+&gt;', '', abstract)\nall_data.loc[index, 'Abstract'] = abstract\n\n\n# Display all information\nIPython.display.clear_output(wait=True)\ntitle_disp = IPython.display.HTML(\"&lt;h2&gt;{}&lt;/h2&gt;\".format(highest_cites_unchecked['Title']))\nauthors_disp = IPython.display.HTML(\"&lt;p&gt;{}&lt;/p&gt;\".format(highest_cites_unchecked['Authors']))\ndoi_disp = IPython.display.HTML(\"&lt;p&gt;&lt;a target='_blank' href='https://doi.org/{}'&gt;{}&lt;/a&gt;&lt;/p&gt;\".format(highest_cites_unchecked['DOI'],highest_cites_unchecked['DOI']))\ndisplay(title_disp, authors_disp, doi_disp)\nprint(textwrap.fill(abstract, 80))\nrelevant_input = input('Relevant? (y/n): ').lower().strip() == 'y'\n\n# Save user input\nall_data.loc[index, 'Checked'] = True\nall_data.loc[index, 'Relevant'] = relevant_input\n\n\n\n\nFlorian Arendt\n\n\n10.1027/0227-5910/a000529\n\n\nAbstract. Background: Suicide is the second leading cause of death among\n15–29-year-olds globally. Unfortunately, the suicide-related content on\nInstagram, a popular social media platform for youth, has not received the\nscholarly attention it deserves. Method: The present study provides a content\nanalysis of posts tagged as #selbstmord, a German suicide-related hashtag. These\nposts were created between July 5 and July 11, 2017. Results: Approximately half\nof all posts included words or visuals related to suicide. Cutting was by far\nthe most prominent method. Although sadness was the dominant emotion, self-hate\nand loneliness also appeared regularly. Importantly, inconsistency – a gap\nbetween one's inner mental state (e.g., sadness) and one's overtly expressed\nbehavior (e.g., smiling) – was also a recurring theme. Conversely, help-seeking,\ndeath wishes, and professional awareness–intervention material were very rare.\nAn explorative analysis revealed that some videos relied on very fast cutting\ntechniques. We provide tentative evidence that users may be exposed to\npurposefully inserted suicide-related subliminal messages (i.e., exposure to\ncontent without the user's conscious awareness). Limitations: We only\ninvestigated the content of posts on one German hashtag, and the sample size was\nrather small. Conclusion: Suicide prevention organizations may consider posting\nmore awareness–intervention materials. Future research should investigate\nsuicide-related subliminal messages in social media video posts. Although\ntentative, this finding should raise a warning flag for suicide prevention\nscholars.\nRelevant? (y/n): y\n\n\nNext, we check whether our input has been saved:\n\n# Check the result\nall_data.iloc[index]\n\nUnnamed: 0.2                                                          0\nUnnamed: 0.1                                                        746\nUnnamed: 0                                                          844\nCites                                                                21\nAuthors                                                  Florian Arendt\nTitle                 Suicide on Instagram – Content Analysis of a G...\nYear                                                             2019.0\nSource                                                           Crisis\nPublisher                                      Hogrefe Publishing Group\nArticleURL                  http://dx.doi.org/10.1027/0227-5910/a000529\nCitesURL                                                            NaN\nGSRank                                                               26\nQueryDate                                           2022-09-08 10:44:44\nType                                                    journal-article\nDOI                                           10.1027/0227-5910/a000529\nISSN                                                          0227-5910\nCitationURL                                                         NaN\nVolume                                                             40.0\nIssue                                                               1.0\nStartPage                                                          36.0\nEndPage                                                            41.0\nECC                                                                  21\nCitesPerYear                                                        7.0\nCitesPerAuthor                                                       21\nAuthorCount                                                           1\nAge                                                                 3.0\nAbstract              Abstract. Background: Suicide is the second le...\nFullTextURL           https://econtent.hogrefe.com/doi/pdf/10.1027/0...\nRelatedURL                                                          NaN\nbabbage_similarity    [-0.0018475924152880907, 0.022463073953986168,...\nbabbage_search        [-0.014954154379665852, 0.026176564395427704, ...\nsimilarities                                                         -1\nRelevant                                                           True\nNotes                                                               NaN\nChecked                                                            True\nName: 0, dtype: object\n\n\n\n\n\nNow for the fun part: Is it possible to use GPT to help us during the review process? We are going to try and extract text features automatically. For the moment we are going to use gpt3.5-turbo.\nNote: Please feel free to test different prompts and questions. The Promptingguide is a good resource to learn more about different prompting techniques. Use the ChatGPT interface to cheaply test prompts prior to using them with the API. Use the OpenAI Playground to optimize your prompts with a visual user interface for different settings and a prompting history (trust me, this can save your life!).\nPrompts: We’re going to use the system prompt for our instructions, and the user prompt to send our content.\n\n\n\n\n\n\nCaution\n\n\n\nA word of warning: You should not trust the quality of the GPT output at this stage. The prompt has not been evaluated, overall LLMs produce output that appears meaningful most of the times. Sometimes, however, it is Hallucinations. Thus, before using prompts and LLMs for production, we have to make sure we can trust their outputs. We will dive deeper into this topic in the classification sessions.\n\n\n\nsystem_prompt = \"\"\"\nYou're an advanced AI research assistant. Your task is to extract **research questions**, **operationalization**, **data sources**, **population**, and **scientific disciplines** from user input. Return \"None\" if you can't find the information in user input.\n\n**Formatting**\nReturn a markdown table, one row for each extracted feature: **research questions**, **operationalization**, **data sources**, **population**, and **scientific disciplines**.\n\"\"\"\n\nPlease enter your API-Code in the next code cell for the openai.api_key variable. We have changed the cell to include the gpt_prompt variable, which sends the title and abstract as a user prompt. We’re using the openai.ChatCompletion.create() method to send our request to the API. We expect the response in api_response['choices'][0]['message']['content'] to be markdown (see prompt above), as such we display the markdown in our notebook.\n\nfrom crossref_commons.retrieval import get_publication_as_json\nimport json\nimport openai\nimport textwrap\nimport IPython\nimport re\n\n# Enter OpenAI API-Code\nopenai.api_key = \"sk-XXXXXXXXX\"\n\n# Get one row: Not checked, highest Citation count.\nhighest_cites_unchecked = all_data[all_data['Checked'] == False].sort_values(by=\"Cites\", ascending=False).iloc[0]\nindex = highest_cites_unchecked.name\n\n# Retrieve Abstract from Crossref\nresponse = get_publication_as_json(highest_cites_unchecked['DOI'])\nabstract = response.get(\"abstract\", \"\")\n\n# Remove XML\nabstract = re.sub(r'&lt;[^&gt;]+&gt;', '', abstract)\n\nall_data.loc[index, 'Abstract'] = abstract\n\n# Display all information (before we send the request to OpenAI)\nIPython.display.clear_output(wait=True)\ntitle_disp = IPython.display.HTML(\"&lt;h2&gt;{}&lt;/h2&gt;\".format(highest_cites_unchecked['Title']))\nauthors_disp = IPython.display.HTML(\"&lt;p&gt;{}&lt;/p&gt;\".format(highest_cites_unchecked['Authors']))\ndoi_disp = IPython.display.HTML(\"&lt;p&gt;&lt;a target='_blank' href='https://doi.org/{}'&gt;{}&lt;/a&gt;&lt;/p&gt;\".format(highest_cites_unchecked['DOI'],highest_cites_unchecked['DOI']))\ndisplay(title_disp, authors_disp, doi_disp)\nprint(textwrap.fill(abstract, 80))\n\ngpt_prompt = f\"\"\"\n**Title**: {highest_cites_unchecked['Title']}\n**Abstract**: {abstract}\n\"\"\"\n\n# Sending request, takes a moment. In the meantime you may read the abstract.\nmessages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": abstract}\n]\n\ntry:\n  api_response = openai.ChatCompletion.create(\n      model=\"gpt-3.5-turbo\",\n      messages=messages,\n      temperature=0,\n      timeout=30\n    )\n\n  gpt_result = api_response['choices'][0]['message']['content']\n\n  # Display the GPT result\n  display(IPython.display.HTML(f\"&lt;h3&gt;GPT Extracted Data&lt;/h3&gt;\"))\n  display(IPython.display.Markdown(gpt_result))\nexcept:\n  print(\"GPT API Error\")\n\nrelevant_input = input('Relevant? (y/n): ').lower().strip() == 'y'\n\n# Save user input\nall_data.loc[index, 'Checked'] = True\nall_data.loc[index, 'Relevant'] = relevant_input\n\n\n\n\nPaloma de H. Sánchez-Cobarro, Francisco-Jose Molina-Castillo, Cristina Alcazar-Caceres\n\n\n10.3390/jtaer16030031\n\n\nThe last decade has seen a considerable increase in entertainment-oriented\ncommunication techniques. Likewise, the rise of social networks has evolved,\noffering different formats such as publication and stories. Hence, there has\nbeen a growing interest in knowing which strategies have the greatest social\nimpact to help position organizations in the mind of the consumer. This research\naims to analyze the different impact that stories and publications can have on\nthe Instagram social network as a tool for generating branded content. To this\nend, it analyses the impact of the different Instagram stories and publications\nin various sectors using a methodology of structural equations with composite\nconstructs. The results obtained, based on 800 stories and publications in four\ndifferent companies (retailers and manufacturers), show that the reach of the\nstory generally explains the interaction with Instagram stories. In contrast, in\nthe case of publications, impressions are of greater importance in explaining\nthe interaction with the publication. Among the main contributions of the work,\nwe find that traditional pull communication techniques have been losing\neffectiveness in front of new formats of brand content generation that have been\noccupying the time in the relationship between users and brands.\nRelevant? (y/n): y\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nValue\n\n\n\n\nResearch questions\n- What strategies have the greatest social impact on Instagram?- How do stories and publications on Instagram impact the consumer’s perception of brands?- What is the relationship between reach and interaction with Instagram stories?- What is the relationship between impressions and interaction with Instagram publications?\n\n\nOperationalization\n- Analyzing the impact of Instagram stories and publications in various sectors- Using a methodology of structural equations with composite constructs\n\n\nData sources\n- 800 stories and publications on Instagram\n\n\nPopulation\n- Four different companies (retailers and manufacturers)\n\n\nScientific disciplines\n- Marketing- Communication\n\n\n\n\n\n\nThe above output shows a formatted table listing all extracted features. In this short warm-up session on GPT we have seen one use case of the LLM: The extraction of text feautures. In future sessions we are going to dive deeper into this topic.\n\n\n\n\n\n\nNote\n\n\n\nDid you create an excellent prompt? Share it with us! Enter your prompt into this Excel Sheet\n\n\n\n\n\nThe following line saves all progress to file_name. If file_name is a path to Google Drive you will be able to pick up your work later on.\n\nall_data.to_csv(file_name)\n\n\nSource: GPT Literature Review Assistant"
  },
  {
    "objectID": "getting-started/literature-review-assistant.html#setup",
    "href": "getting-started/literature-review-assistant.html#setup",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "At first we need to install necessary packages. Hit run and wait.\n\nprint(\"Install Packages\")\n!pip install -q openai crossref-commons"
  },
  {
    "objectID": "getting-started/literature-review-assistant.html#import-publish-or-perish-data.",
    "href": "getting-started/literature-review-assistant.html#import-publish-or-perish-data.",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "If this is the start of your review process, upload the csv file exported from Publish or Perish in the left-hand Files pane. Enter the filename in publish_or_perish_file_name. Define the output name in file_name. If you want to save the imported file in the google drive add /content/drive/MyDrive/ to the path.  Skip this cell if you want to work with a file that has been imported in the past.\n\n\n\n\n\n\nWarning\n\n\n\nWe delete rows with missing DOIs. Without a DOI our code cannot retrieve abstracts. When importing the Publish or Perish file, the following code will display the number of rows that have been deleted due to missing DOIs. When using this notebook for real-world projects, you should be aware of the missing rows and manually review them!\n\n\n\n#@title Import from Publish or Perish Data.\n#@markdown If this is the start of your review process, upload the `csv` file exported from [Publish or Perish](https://harzing.com/resources/publish-or-perish) in the left-hand *Files* pane. Enter the filename in `publish_or_perish_file_name`. Define the output name in `file_name`. If you want to save the imported file in the google drive add `/content/drive/MyDrive/` to the path. &lt;br/&gt; **Skip this cell if you want to work with a file that has been imported in the past.**\n\nimport pandas as pd\nimport numpy as np\nimport io\n\npublish_or_perish_file_name = \"scholar.csv\" # @param {type: \"string\"}\nfile_name = \"2023-10-31-Literature-Review.csv\" # @param {type: \"string\"}\n\n# Initialize empty DataFrame\nall_data = pd.DataFrame()\n\n\ntry:\n    all_data = pd.read_csv(publish_or_perish_file_name)\n\n    # Remove Duplicates\n    initial_len = len(all_data)\n    all_data = all_data.drop_duplicates(subset='DOI', keep='first')\n    removed_len = initial_len - len(all_data)\n    print(f'Removed {removed_len} duplicates based on DOI.')\n\n    # Remove missing DOIs\n    initial_len = len(all_data)\n    all_data = all_data[~pd.isna(all_data['DOI'])]\n    removed_len = initial_len - len(all_data)\n    print(f'Removed {removed_len} rows without DOI.')\n\n    all_data = all_data.sort_values(by='Cites', ascending=False).reset_index(drop=True)\n\n    print('Sorted Table by Cites.')\n\n    # Create empty columns for Literature Review\n    all_data[\"Relevant\"] = \"\"\n    all_data[\"Notes\"] = \"\"\n    all_data[\"Checked\"] = False\n\n    print('Initialized Columns')\n\n    all_data.to_csv(file_name)\n    print(f\"Success: Saved data to {file_name}\")\n\n    print(f'Success: Data loaded from File \"{file_name}\".')\nexcept Exception as e:\n    print(f\"Error: Failed to load data from File. {str(e)}\")\n\nRemoved 172 duplicates based on DOI.\nRemoved 1 rows without DOI.\nSorted Table by Cites.\nInitializes Columns\nSuccess: Saved data to 2023-10-31-Literature-Review.csv\nSuccess: Data loaded from File \"2023-10-31-Literature-Review.csv\"."
  },
  {
    "objectID": "getting-started/literature-review-assistant.html#read-previously-imported-file",
    "href": "getting-started/literature-review-assistant.html#read-previously-imported-file",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "If you want to keep going with a former review process, we can read an uploaded file / a file from google drive. Only run one cell, this one or the above.\n\n#@title Read previously imported File\n#@markdown If you want to keep going with a former review process, we can read an uploaded file / a file from google drive. **Only run one cell, this one or the above.**\nimport pandas as pd\nimport numpy as np\nimport io\n\nfile_name = \"2023-10-31-Literature-Review.csv\" # @param {type: \"string\"}\n\ntry:\n    all_data = pd.read_csv(file_name)\n\n    print(f'Success: Data loaded from File \"{file_name}\".')\nexcept Exception as e:\n    print(f\"Error: Failed to load data from File. {str(e)}\")\n\nSuccess: Data loaded from File \"2023-10-31-Literature-Review.csv\".\n\n\n\nIn this example we’ve saved the file locally. When working with Colab, the file will be deleted when we disconnect. For colab you should link your google drive (open the files pane on the left, click the Google Drive button). Once connected, save the file in the folder /content/drive/MyDrive/YOUR-FILENAME.csv. It will be accessible through Drive, and Colab is from now on going to connect automatically to drive.\nCheck the imported data. We’re using pandas, the imported data is saved in the all_datavariable. head(2)displays the two top rows of the table. Additionally, we have added three columns: Relevant, Notes, and Checked. We are going to make use of them to keep track of our progress.\n\n# Check the structure (and content) of the file\nall_data.head(2)\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0.2\nUnnamed: 0.1\nUnnamed: 0\nCites\nAuthors\nTitle\nYear\nSource\nPublisher\nArticleURL\n...\nAge\nAbstract\nFullTextURL\nRelatedURL\nbabbage_similarity\nbabbage_search\nsimilarities\nRelevant\nNotes\nChecked\n\n\n\n\n0\n0\n746\n844\n21\nFlorian Arendt\nSuicide on Instagram – Content Analysis of a G...\n2019.0\nCrisis\nHogrefe Publishing Group\nhttp://dx.doi.org/10.1027/0227-5910/a000529\n...\n3.0\nAbstract. Background: Suicide is the second le...\nhttps://econtent.hogrefe.com/doi/pdf/10.1027/0...\nNaN\n[-0.0018475924152880907, 0.022463073953986168,...\n[-0.014954154379665852, 0.026176564395427704, ...\n-1\nNaN\nNaN\nFalse\n\n\n1\n1\n770\n868\n4\nPaloma de H. Sánchez-Cobarro, Francisco-Jose M...\nThe Brand-Generated Content Interaction of Ins...\n2020.0\nJournal of Theoretical and Applied Electronic ...\nMDPI AG\nhttp://dx.doi.org/10.3390/jtaer16030031\n...\n2.0\nThe last decade has seen a considerable increa...\nhttps://www.mdpi.com/0718-1876/16/3/31/pdf\nNaN\n[-0.0029447057750076056, 0.01190990675240755, ...\n[-0.01012819167226553, 0.02539714053273201, -0...\n-1\nNaN\nNaN\nFalse\n\n\n\n\n\n2 rows × 35 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nIn the next step we are going to start our literature review:\n\nWe filter for the first unchecked row, ordered by the cite count.\nWe retrieve the abstract from CrossRef API using the DOI.\nWe display all information\nWe answer whether the paper appear to be relevant by entering y or n for yes or no.\n\nFor our session, the cell only runs through one row and finishes afterwards. For a real world application you’d probably like to add some kind of loop.\n\nfrom crossref_commons.retrieval import get_publication_as_json\nimport json\nimport openai\nimport textwrap\nimport IPython\nimport re\n\n# Get one row: Not checked, highest Citation count.\nhighest_cites_unchecked = all_data[all_data['Checked'] == False].sort_values(by=\"Cites\", ascending=False).iloc[0]\nindex = highest_cites_unchecked.name\n\n# Retrieve Abstract from Crossref\nresponse = get_publication_as_json(highest_cites_unchecked['DOI'])\nabstract = response.get(\"abstract\", \"\")\n\n# Remove XML\nabstract = re.sub(r'&lt;[^&gt;]+&gt;', '', abstract)\nall_data.loc[index, 'Abstract'] = abstract\n\n\n# Display all information\nIPython.display.clear_output(wait=True)\ntitle_disp = IPython.display.HTML(\"&lt;h2&gt;{}&lt;/h2&gt;\".format(highest_cites_unchecked['Title']))\nauthors_disp = IPython.display.HTML(\"&lt;p&gt;{}&lt;/p&gt;\".format(highest_cites_unchecked['Authors']))\ndoi_disp = IPython.display.HTML(\"&lt;p&gt;&lt;a target='_blank' href='https://doi.org/{}'&gt;{}&lt;/a&gt;&lt;/p&gt;\".format(highest_cites_unchecked['DOI'],highest_cites_unchecked['DOI']))\ndisplay(title_disp, authors_disp, doi_disp)\nprint(textwrap.fill(abstract, 80))\nrelevant_input = input('Relevant? (y/n): ').lower().strip() == 'y'\n\n# Save user input\nall_data.loc[index, 'Checked'] = True\nall_data.loc[index, 'Relevant'] = relevant_input\n\n\n\n\nFlorian Arendt\n\n\n10.1027/0227-5910/a000529\n\n\nAbstract. Background: Suicide is the second leading cause of death among\n15–29-year-olds globally. Unfortunately, the suicide-related content on\nInstagram, a popular social media platform for youth, has not received the\nscholarly attention it deserves. Method: The present study provides a content\nanalysis of posts tagged as #selbstmord, a German suicide-related hashtag. These\nposts were created between July 5 and July 11, 2017. Results: Approximately half\nof all posts included words or visuals related to suicide. Cutting was by far\nthe most prominent method. Although sadness was the dominant emotion, self-hate\nand loneliness also appeared regularly. Importantly, inconsistency – a gap\nbetween one's inner mental state (e.g., sadness) and one's overtly expressed\nbehavior (e.g., smiling) – was also a recurring theme. Conversely, help-seeking,\ndeath wishes, and professional awareness–intervention material were very rare.\nAn explorative analysis revealed that some videos relied on very fast cutting\ntechniques. We provide tentative evidence that users may be exposed to\npurposefully inserted suicide-related subliminal messages (i.e., exposure to\ncontent without the user's conscious awareness). Limitations: We only\ninvestigated the content of posts on one German hashtag, and the sample size was\nrather small. Conclusion: Suicide prevention organizations may consider posting\nmore awareness–intervention materials. Future research should investigate\nsuicide-related subliminal messages in social media video posts. Although\ntentative, this finding should raise a warning flag for suicide prevention\nscholars.\nRelevant? (y/n): y\n\n\nNext, we check whether our input has been saved:\n\n# Check the result\nall_data.iloc[index]\n\nUnnamed: 0.2                                                          0\nUnnamed: 0.1                                                        746\nUnnamed: 0                                                          844\nCites                                                                21\nAuthors                                                  Florian Arendt\nTitle                 Suicide on Instagram – Content Analysis of a G...\nYear                                                             2019.0\nSource                                                           Crisis\nPublisher                                      Hogrefe Publishing Group\nArticleURL                  http://dx.doi.org/10.1027/0227-5910/a000529\nCitesURL                                                            NaN\nGSRank                                                               26\nQueryDate                                           2022-09-08 10:44:44\nType                                                    journal-article\nDOI                                           10.1027/0227-5910/a000529\nISSN                                                          0227-5910\nCitationURL                                                         NaN\nVolume                                                             40.0\nIssue                                                               1.0\nStartPage                                                          36.0\nEndPage                                                            41.0\nECC                                                                  21\nCitesPerYear                                                        7.0\nCitesPerAuthor                                                       21\nAuthorCount                                                           1\nAge                                                                 3.0\nAbstract              Abstract. Background: Suicide is the second le...\nFullTextURL           https://econtent.hogrefe.com/doi/pdf/10.1027/0...\nRelatedURL                                                          NaN\nbabbage_similarity    [-0.0018475924152880907, 0.022463073953986168,...\nbabbage_search        [-0.014954154379665852, 0.026176564395427704, ...\nsimilarities                                                         -1\nRelevant                                                           True\nNotes                                                               NaN\nChecked                                                            True\nName: 0, dtype: object"
  },
  {
    "objectID": "getting-started/literature-review-assistant.html#using-gpt-to-extract-information-from-abstracts",
    "href": "getting-started/literature-review-assistant.html#using-gpt-to-extract-information-from-abstracts",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "Now for the fun part: Is it possible to use GPT to help us during the review process? We are going to try and extract text features automatically. For the moment we are going to use gpt3.5-turbo.\nNote: Please feel free to test different prompts and questions. The Promptingguide is a good resource to learn more about different prompting techniques. Use the ChatGPT interface to cheaply test prompts prior to using them with the API. Use the OpenAI Playground to optimize your prompts with a visual user interface for different settings and a prompting history (trust me, this can save your life!).\nPrompts: We’re going to use the system prompt for our instructions, and the user prompt to send our content.\n\n\n\n\n\n\nCaution\n\n\n\nA word of warning: You should not trust the quality of the GPT output at this stage. The prompt has not been evaluated, overall LLMs produce output that appears meaningful most of the times. Sometimes, however, it is Hallucinations. Thus, before using prompts and LLMs for production, we have to make sure we can trust their outputs. We will dive deeper into this topic in the classification sessions.\n\n\n\nsystem_prompt = \"\"\"\nYou're an advanced AI research assistant. Your task is to extract **research questions**, **operationalization**, **data sources**, **population**, and **scientific disciplines** from user input. Return \"None\" if you can't find the information in user input.\n\n**Formatting**\nReturn a markdown table, one row for each extracted feature: **research questions**, **operationalization**, **data sources**, **population**, and **scientific disciplines**.\n\"\"\"\n\nPlease enter your API-Code in the next code cell for the openai.api_key variable. We have changed the cell to include the gpt_prompt variable, which sends the title and abstract as a user prompt. We’re using the openai.ChatCompletion.create() method to send our request to the API. We expect the response in api_response['choices'][0]['message']['content'] to be markdown (see prompt above), as such we display the markdown in our notebook.\n\nfrom crossref_commons.retrieval import get_publication_as_json\nimport json\nimport openai\nimport textwrap\nimport IPython\nimport re\n\n# Enter OpenAI API-Code\nopenai.api_key = \"sk-XXXXXXXXX\"\n\n# Get one row: Not checked, highest Citation count.\nhighest_cites_unchecked = all_data[all_data['Checked'] == False].sort_values(by=\"Cites\", ascending=False).iloc[0]\nindex = highest_cites_unchecked.name\n\n# Retrieve Abstract from Crossref\nresponse = get_publication_as_json(highest_cites_unchecked['DOI'])\nabstract = response.get(\"abstract\", \"\")\n\n# Remove XML\nabstract = re.sub(r'&lt;[^&gt;]+&gt;', '', abstract)\n\nall_data.loc[index, 'Abstract'] = abstract\n\n# Display all information (before we send the request to OpenAI)\nIPython.display.clear_output(wait=True)\ntitle_disp = IPython.display.HTML(\"&lt;h2&gt;{}&lt;/h2&gt;\".format(highest_cites_unchecked['Title']))\nauthors_disp = IPython.display.HTML(\"&lt;p&gt;{}&lt;/p&gt;\".format(highest_cites_unchecked['Authors']))\ndoi_disp = IPython.display.HTML(\"&lt;p&gt;&lt;a target='_blank' href='https://doi.org/{}'&gt;{}&lt;/a&gt;&lt;/p&gt;\".format(highest_cites_unchecked['DOI'],highest_cites_unchecked['DOI']))\ndisplay(title_disp, authors_disp, doi_disp)\nprint(textwrap.fill(abstract, 80))\n\ngpt_prompt = f\"\"\"\n**Title**: {highest_cites_unchecked['Title']}\n**Abstract**: {abstract}\n\"\"\"\n\n# Sending request, takes a moment. In the meantime you may read the abstract.\nmessages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": abstract}\n]\n\ntry:\n  api_response = openai.ChatCompletion.create(\n      model=\"gpt-3.5-turbo\",\n      messages=messages,\n      temperature=0,\n      timeout=30\n    )\n\n  gpt_result = api_response['choices'][0]['message']['content']\n\n  # Display the GPT result\n  display(IPython.display.HTML(f\"&lt;h3&gt;GPT Extracted Data&lt;/h3&gt;\"))\n  display(IPython.display.Markdown(gpt_result))\nexcept:\n  print(\"GPT API Error\")\n\nrelevant_input = input('Relevant? (y/n): ').lower().strip() == 'y'\n\n# Save user input\nall_data.loc[index, 'Checked'] = True\nall_data.loc[index, 'Relevant'] = relevant_input\n\n\n\n\nPaloma de H. Sánchez-Cobarro, Francisco-Jose Molina-Castillo, Cristina Alcazar-Caceres\n\n\n10.3390/jtaer16030031\n\n\nThe last decade has seen a considerable increase in entertainment-oriented\ncommunication techniques. Likewise, the rise of social networks has evolved,\noffering different formats such as publication and stories. Hence, there has\nbeen a growing interest in knowing which strategies have the greatest social\nimpact to help position organizations in the mind of the consumer. This research\naims to analyze the different impact that stories and publications can have on\nthe Instagram social network as a tool for generating branded content. To this\nend, it analyses the impact of the different Instagram stories and publications\nin various sectors using a methodology of structural equations with composite\nconstructs. The results obtained, based on 800 stories and publications in four\ndifferent companies (retailers and manufacturers), show that the reach of the\nstory generally explains the interaction with Instagram stories. In contrast, in\nthe case of publications, impressions are of greater importance in explaining\nthe interaction with the publication. Among the main contributions of the work,\nwe find that traditional pull communication techniques have been losing\neffectiveness in front of new formats of brand content generation that have been\noccupying the time in the relationship between users and brands.\nRelevant? (y/n): y\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nValue\n\n\n\n\nResearch questions\n- What strategies have the greatest social impact on Instagram?- How do stories and publications on Instagram impact the consumer’s perception of brands?- What is the relationship between reach and interaction with Instagram stories?- What is the relationship between impressions and interaction with Instagram publications?\n\n\nOperationalization\n- Analyzing the impact of Instagram stories and publications in various sectors- Using a methodology of structural equations with composite constructs\n\n\nData sources\n- 800 stories and publications on Instagram\n\n\nPopulation\n- Four different companies (retailers and manufacturers)\n\n\nScientific disciplines\n- Marketing- Communication\n\n\n\n\n\n\nThe above output shows a formatted table listing all extracted features. In this short warm-up session on GPT we have seen one use case of the LLM: The extraction of text feautures. In future sessions we are going to dive deeper into this topic.\n\n\n\n\n\n\nNote\n\n\n\nDid you create an excellent prompt? Share it with us! Enter your prompt into this Excel Sheet"
  },
  {
    "objectID": "getting-started/literature-review-assistant.html#save-your-progress",
    "href": "getting-started/literature-review-assistant.html#save-your-progress",
    "title": "GPT Literature Review Assistant",
    "section": "",
    "text": "The following line saves all progress to file_name. If file_name is a path to Google Drive you will be able to pick up your work later on.\n\nall_data.to_csv(file_name)"
  },
  {
    "objectID": "evaluation/agreement.html",
    "href": "evaluation/agreement.html",
    "title": "Agreement & Evaluation",
    "section": "",
    "text": "The previous chapter focused on the creation of a Ground Truth dataset using human annotations. In this chapter we pick up on the annotated data and will first assess the quality of the annotations before adopting them as a gold standard. The integrity of the dataset directly influences the validity of our model evaluations. To this end, we take a look at two interrater agreement measures: Cohen’s Kappa and Krippendorff’s Alpha. These metrics are important for quantifying the level of agreement among annotators, thereby ensuring that our dataset is not only reliable but also representative of the diverse perspectives inherent in social media analysis. Once we established the quality of our annotations, we will use them as ground truth to determine how well our computational approach performs when applied to real-world data. The performance of machine learning models is typically assessed using a variety of metrics, each offering a different perspective on the model’s effectiveness. In this chapter, we will take a look at four fundamental metrics: Accuracy, Precision, Recall, and F1 Score.\nIn the first part of the chapter we will take a look at interrater agreements and machine learning evaluation measures. In the application part I provide the notebooks to:\nFinally, the optimization part of this page provides an outlook for how to use the evaluation metrics in order to tune your classification prompt."
  },
  {
    "objectID": "evaluation/agreement.html#interrater-agreement",
    "href": "evaluation/agreement.html#interrater-agreement",
    "title": "Agreement & Evaluation",
    "section": "Interrater Agreement",
    "text": "Interrater Agreement\n\nCohen’s \\(\\kappa\\)\nis a widely used statistic for measuring the agreement between two annotators, taking into account the agreement occurring by chance. This metric is particularly valuable when dealing with categorical data, as is often the case in text annotations. Cohen’s Kappa provides a more robust measure than simple percent agreement calculation because it considers the possibility of the agreement occurring randomly. The kappa score can range from -1 (complete disagreement) to 1 (complete agreement), with 0 indicating the level of agreement that can be expected from random chance.\nThe definition of \\(\\kappa\\) is:\n\\(\\kappa \\equiv \\frac{p_o - p_e}{1 - p_e} = 1- \\frac{1 - p_o}{1 - p_e}\\)\n“where \\(p_{0}\\) is the relative observed agreement among raters, and \\(p_{e}\\) is the hypothetical probability of chance agreement, using the observed data to calculate the probabilities of each observer randomly seeing each category.” (Source: Wikipedia)\n\n\nInteractive Example\n\n\nAdjust the disagreement level to see how it affects the agreement between two coders measured by Cohen’s Kappa. The plot below visualizes their codings.\n\n\nfunction drawCodingPlot(coder1, coder2) {\n    const svgWidth = coder1.length * 10 + 100; // Adjust the width based on the number of items and space for labels\n    const svgHeight = 50; // Fixed height, two rows\n    const svg = d3.create(\"svg\")\n                  .attr(\"width\", svgWidth)\n                  .attr(\"height\", svgHeight);\n\n    // Adding labels for Coders\n    svg.append(\"text\")\n       .attr(\"x\", 40)\n       .attr(\"y\", 20)\n       .text(\"Coder 1\")\n       .attr(\"font-size\", \"10px\")\n       .attr(\"text-anchor\", \"end\");\n\n    svg.append(\"text\")\n       .attr(\"x\", 40)\n       .attr(\"y\", 40)\n       .text(\"Coder 2\")\n       .attr(\"font-size\", \"10px\")\n       .attr(\"text-anchor\", \"end\");\n\n    // Drawing circles for codings\n    coder1.forEach((code, index) =&gt; {\n        svg.append(\"circle\")\n           .attr(\"cx\", 60 + 10 * index)\n           .attr(\"cy\", 15)\n           .attr(\"r\", 4)\n           .style(\"fill\", code === 1 ? \"black\" : \"none\")\n           .style(\"stroke\", \"black\");\n    });\n\n    coder2.forEach((code, index) =&gt; {\n        svg.append(\"circle\")\n           .attr(\"cx\", 60 + 10 * index)\n           .attr(\"cy\", 35)\n           .attr(\"r\", 4)\n           .style(\"fill\", code === 1 ? \"black\" : \"none\")\n           .style(\"stroke\", \"black\");\n    });\n\n    return svg.node();\n}\n\n\n// Function to generate controlled codings\nfunction generateControlledCoding(nItems, disagreementRate) {\n    let coder1 = Array.from({length: nItems}, () =&gt; Math.random() &lt; 0.5 ? 0 : 1);\n    let coder2 = [...coder1];\n    disagreementRate = disagreementRate / 100\n    let nDisagreements = Math.floor(nItems * disagreementRate);\n    for (let i = 0; i &lt; nDisagreements; i++) {\n        let index = Math.floor(Math.random() * nItems);\n        coder2[index] = 1 - coder2[index];\n    }\n    return [coder1, coder2];\n}\n\n// Function to calculate Cohen's Kappa\nfunction calculateCohensKappa(coder1, coder2) {\n    let totalItems = coder1.length;\n    let agree = 0;\n    let coder1Yes = 0;\n    let coder2Yes = 0;\n\n    for (let i = 0; i &lt; totalItems; i++) {\n        if (coder1[i] === coder2[i]) {\n            agree++;\n        }\n        if (coder1[i] === 1) {\n            coder1Yes++;\n        }\n        if (coder2[i] === 1) {\n            coder2Yes++;\n        }\n    }\n\n    let Po = agree / totalItems;\n    let Pe = (coder1Yes / totalItems) * (coder2Yes / totalItems) + \n             ((totalItems - coder1Yes) / totalItems) * ((totalItems - coder2Yes) / totalItems);\n\n    return (Po - Pe) / (1 - Pe);\n}\n\nviewof disagreement_rate = Inputs.range([0, 100], {step: 1.0, value: 10, label: \"Disagreement\"})\nviewof nItems = Inputs.range([11, 65], {step: 1.0, value: 65.0, label: \"n\"})\n\n// Main calculation and display\n{\n    const [coder1, coder2] = generateControlledCoding(nItems, disagreement_rate);\n    const kappa = calculateCohensKappa(coder1, coder2);\n\n    // Draw the coding plot\n    const codingPlot = drawCodingPlot(coder1, coder2);\n\n    return html`&lt;div&gt;Cohen's Kappa: ${kappa.toFixed(2)}&lt;/div&gt;\n                  &lt;div&gt;${codingPlot}&lt;/div&gt;`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing python we can easily calculate Cohen’s Kappa:\nfrom sklearn.metrics import cohen_kappa_score\n\n# Example annotations from two annotators\nannotator1 = [1, 2, 3, 4, 5]\nannotator2 = [2, 2, 3, 4, 4]\n\nkappa = cohen_kappa_score(annotator1, annotator2)\nprint(f\"Cohen's Kappa: {kappa}\")\n\n\nKrippendorff’s \\(\\alpha\\)\nWhile Cohen’s Kappa is ideal for pairwise annotation evaluation, Krippendorff’s Alpha is used when there are more than two annotators. This metric is versatile as it can handle various types of data, including nominal, ordinal, interval, or ratio-scaled. Krippendorff’s Alpha assesses the agreement among multiple annotators, accounting for the possibility of chance agreement. Its value also ranges from -1 to 1, with higher values indicating better reliability and 0 representing agreement equivalent to chance.\nThe definition of \\(\\alpha\\) is:\n\\(\\alpha = 1-\\frac{D_o}{D_e}\\)\n“where \\(D_o\\) is the disagreement observed and \\(D_e\\) is the disagreement expected by chance.” (Source: Wikipedia)\n\n\nStatic Example\n\n\nCalculating the Krippendorff Alpha is more complex than Cohen’s kappa. The example below is static, use the code below to calculate Krippendorff’s Alpha in your Jupyter Notebook.\n\n\n\n\nn: 65\nDisagreement: 10%\nKrippendorff's Alpha: 0.8164136622390892\n\n\n\n\n\nSource: -\n\nIn order to calculate Krippendorff’s Alpha using python we need to install the krippendorff package: pip install krippendorff. Calculating the \\(\\alpha\\) value using python is straightforward – as long as the codings are provided as integers.\nimport krippendorff\nimport numpy as np\n\n# Example annotations from three annotators\ndata = np.array([\n    [1, 2, 3, 4, 5],\n    [2, 2, 3, 4, 4],\n    [1, 2, 4, 4, 5]\n])\n\nalpha = krippendorff.alpha(data)\nprint(f\"Krippendorff's Alpha: {alpha}\")\nIn case of e.g. strings (categorical data), we need to encode the values first:\ndata_categorical = [\n    [\"yes\", \"no\", \"yes\", \"maybe\", \"no\"],\n    [\"no\", \"no\", \"yes\", \"maybe\", \"maybe\"],\n    [\"yes\", \"no\", \"maybe\", \"maybe\", \"no\"]\n]\n\n# Convert categorical data to numerical format\nlabel_encoding = {\"yes\": 0, \"no\": 1, \"maybe\": 2}\ndata_encoded = np.array([[label_encoding.get(item, np.nan) for item in row] for row in data_categorical])\n\nalpha = krippendorff.alpha(data_encoded)\nprint(f\"Krippendorff's Alpha: {alpha}\")"
  },
  {
    "objectID": "evaluation/agreement.html#machine-learning-evaluation-metrics",
    "href": "evaluation/agreement.html#machine-learning-evaluation-metrics",
    "title": "Agreement & Evaluation",
    "section": "Machine Learning Evaluation Metrics",
    "text": "Machine Learning Evaluation Metrics\nAfter establishing the reliability of our annotations, we now turn our attention to evaluating the performance of machine learning models using these validated datasets. This is crucial for understanding how well our computational approaches are performing in real-world scenarios. In this segment, we discuss four evaluation metrics: Accuracy, Precision, Recall, and F1 Score.\n\n\n\n\n\n\nWarning\n\n\n\nThis subchapter scratches the surface. Recommended reading: e.g. Haim (2023) pp. 246–252, or machine learning textbooks. Parts of this section have been generated using ChatGPT (e.g. examples).\n\n\n\nUnderstanding Confusion Matrix Components\nBefore diving into the metrics, it’s important to understand the components of a confusion matrix: True Positives, True Negatives, False Positives, and False Negatives. Here’s a brief explanation of each:\n\nTrue Positives (TP): These are cases where the model correctly predicts the positive class.\nTrue Negatives (TN): These are cases where the model correctly predicts the negative class.\nFalse Positives (FP): These are cases where the model incorrectly predicts the positive class (also known as a “Type I error”).\nFalse Negatives (FN): These are cases where the model incorrectly predicts the negative class (also known as a “Type II error”).\n\nThe following table summarizes these concepts:\n\n\n\n\nActual Positive\nActual Negative\n\n\n\n\nPredicted Positive\nTrue Positives (TP)\nFalse Positives (FP)\n\n\nPredicted Negative\nFalse Negatives (FN)\nTrue Negatives (TN)\n\n\n\n\nExample Scenario:\nConsider a social media sentiment analysis model that classifies posts as either “Positive” or “Negative.” In this context:\n\nA True Positive would be a post that is actually positive and the model also predicts it as positive.\nA True Negative would be a post that is actually negative and the model also predicts it as negative.\nA False Positive would occur if the model incorrectly classifies a negative post as positive.\nA False Negative would occur if the model incorrectly classifies a positive post as negative.\n\nUnderstanding these components is key to interpreting the subsequent metrics which are derived from the values in the confusion matrix. These metrics – Accuracy, Precision, Recall, and F1 Score – are applicable to both binary (as showcased above) and multi-class classification problems. The concept of True / False Positives / Negatives remains the same, but for multi-class scenarios, they are computed per class and then averaged to provide overall model performance.\nAccuracy: A General Overview\nAccuracy is the simplest and most straightforward metric. It represents the ratio of correctly predicted observations (both true positives and true negatives) to the total observations in the dataset.\n\\(\\text{Accuracy} = \\frac{\\text{True Positives (TP)} + \\text{True Negatives (TN)}}{\\text{Total Observations}}\\)\nAccuracy can be misleading, particularly in datasets where class distributions are imbalanced. In such cases, a model might appear to perform well simply by favoring the majority class, while failing to accurately predict the minority class.\nPrecision: Measuring Exactness\nPrecision reflects the accuracy of positive predictions. It shows how many of the items identified as positive are actually positive. This metric is vital when the costs of false positives are high.\n\\(\\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\\)\nHigh precision indicates a low rate of false positives, which is essential in scenarios where false alarms are costly or dangerous.\nRecall: Assessing Completeness\nRecall, or sensitivity, measures the model’s ability to identify all relevant instances. In other words, it shows how many of the actual positive cases were correctly identified by the model.\n\\(\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\\)\nHigh recall is crucial in situations where missing a positive instance has severe implications, like in medical diagnoses.\nF1 Score: Harmonizing Precision and Recall\nThe F1 Score is the harmonic mean of Precision and Recall, offering a balance between the two. It is particularly useful when you need a single metric to reflect a model’s performance, especially in cases of uneven class distribution.\n\\(\\text{F}_{1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\\)\nA high F1 Score suggests a robust model with a good balance between precision and recall.\n\n\n\n\n\n\nWarning\n\n\n\nWhile a high F1 Score is often seen as indicative of a model’s effectiveness, it’s important to approach this metric with caution. The F1 Score, being a harmonic mean of precision and recall, may not comprehensively represent the performance nuances in certain contexts, especially in imbalanced datasets where either false positives or false negatives are more consequential. Refer to the criticism section in the Wikipedia article on F1 Score or e.g. the paper “Performance Evaluation in Machine Learning: The Good, the Bad, the Ugly, and the Way Forward” by Flach (2019).\n\n\n\n\nMachine Learning Metrics Calculator\n\n\nAdjust the values of the confusion matrix to see how they affect accuracy, precision, and macro F1-score.\n\n\nhtml`&lt;style&gt;\n  .ml-metrics-widget {\n    border: 1px solid #ddd;\n    padding: 15px;\n    border-radius: 8px;\n    margin-bottom: 20px;\n  }\n  .ml-metrics-widget h4 {\n    margin-top: 0;\n  }\n  .confusion-matrix {\n    margin-top: 20px;\n    border-collapse: collapse;\n  }\n  .confusion-matrix td, .confusion-matrix th {\n    border: 1px solid #ddd;\n    padding: 8px;\n    text-align: center;\n  }\n  .heatmap {\n    margin-top: 20px;\n  }\n&lt;/style&gt;`;\n\n\n\n\n\n\n\nviewof tp = Inputs.range([0, 100], {step: 1, value: 50, label: \"True Positives (TP)\"})\nviewof fp = Inputs.range([0, 100], {step: 1, value: 10, label: \"False Positives (FP)\"})\nviewof tn = Inputs.range([0, 100], {step: 1, value: 50, label: \"True Negatives (TN)\"})\nviewof fn = Inputs.range([0, 100], {step: 1, value: 10, label: \"False Negatives (FN)\"})\n\n// Function to calculate metrics\nfunction calculateMetrics(tp, fp, tn, fn) {\n    let accuracy = (tp + tn) / (tp + fp + tn + fn);\n    let precision = tp / (tp + fp);\n    let recall = tp / (tp + fn); // Recall is the same as Sensitivity\n    let f1Score = 2 * (precision * recall) / (precision + recall);\n\n    // Check for NaN and return 0 in such cases\n    accuracy = isNaN(accuracy) ? 0 : accuracy;\n    precision = isNaN(precision) ? 0 : precision;\n    f1Score = isNaN(f1Score) ? 0 : f1Score;\n\n    return { accuracy, precision, f1Score };\n}\n\n// Function to draw the heatmap plot with adjusted labels\nfunction drawHeatmap(tp, fp, tn, fn) {\n    // Create an array to represent the confusion matrix\n    let matrix = [\n        [tp, fn],\n        [fp, tn]\n    ];\n\n    // Define dimensions and colors for the heatmap\n    let cellSize = 50; // Size of each cell in the heatmap\n    let labelSpace = 40; // Space for labels\n    let width = 2 * cellSize + labelSpace, height = 2 * cellSize + labelSpace;\n\n    let colors = d3.scaleSequential(d3.interpolateBlues).domain([0, Math.max(tp, fp, tn, fn)]);\n\n    // Create an SVG for the heatmap\n    let svg = d3.create(\"svg\")\n                .attr(\"width\", width)\n                .attr(\"height\", height)\n                .attr(\"class\", \"heatmap\");\n\n    // Create heatmap squares\n    svg.selectAll(\"rect\")\n       .data(matrix.flat())\n       .enter()\n       .append(\"rect\")\n       .attr(\"x\", (d, i) =&gt; labelSpace + cellSize * (i % 2))\n       .attr(\"y\", (d, i) =&gt; labelSpace + cellSize * Math.floor(i / 2))\n       .attr(\"width\", cellSize)\n       .attr(\"height\", cellSize)\n       .style(\"fill\", d =&gt; colors(d));\n\n    // Add category labels\n    const textAnchor = \"middle\";\n    svg.append(\"text\").text(\"Predicted Positive\").attr(\"x\", labelSpace + cellSize / 2).attr(\"y\", labelSpace / 2).attr(\"text-anchor\", textAnchor);\n    svg.append(\"text\").text(\"Predicted Negative\").attr(\"x\", labelSpace + 1.5 * cellSize).attr(\"y\", labelSpace / 2).attr(\"text-anchor\", textAnchor);\n    svg.append(\"text\").text(\"Actual Positive\").attr(\"x\", labelSpace / 2).attr(\"y\", labelSpace + cellSize / 2).attr(\"text-anchor\", textAnchor).attr(\"alignment-baseline\", \"central\");\n    svg.append(\"text\").text(\"Actual Negative\").attr(\"x\", labelSpace / 2).attr(\"y\", labelSpace + 1.5 * cellSize).attr(\"text-anchor\", textAnchor).attr(\"alignment-baseline\", \"central\");\n\n    return svg.node();\n}\n// Main calculation and display\n{\n    const metrics = calculateMetrics(tp, fp, tn, fn);\n\n    return html`&lt;hr /&gt;&lt;div style=\"display: flex; justify-content: space-around; width: 100%;\"&gt;\n                                  &lt;div&gt;\n                  &lt;h4&gt;Evaluation Metrics&lt;/h4&gt;\n                  &lt;table class=\"confusion-matrix\"&gt;\n                    &lt;tr&gt;\n                      &lt;th&gt;Accuracy:&lt;/th&gt;\n                      &lt;td&gt;${metrics.accuracy.toFixed(2)}&lt;/td&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                      &lt;th&gt;Precision:&lt;/th&gt;\n                      &lt;td&gt;${metrics.precision.toFixed(2)}&lt;/td&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                      &lt;th&gt;F1-Score:&lt;/th&gt;\n                      &lt;td&gt;${metrics.f1Score.toFixed(2)}&lt;/td&gt;\n                    &lt;/tr&gt;\n                  &lt;/table&gt;\n                  &lt;/div&gt;\n                &lt;div&gt;\n                  &lt;h4&gt;Confusion Matrix&lt;/h4&gt;\n                  &lt;table class=\"confusion-matrix\"&gt;\n                    &lt;tr&gt;\n                      &lt;th&gt;&lt;/th&gt;&lt;th&gt;Predicted Positive&lt;/th&gt;&lt;th&gt;Predicted Negative&lt;/th&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                      &lt;th&gt;Actual Positive&lt;/th&gt;&lt;td&gt;${tp}&lt;/td&gt;&lt;td&gt;${fn}&lt;/td&gt;\n                    &lt;/tr&gt;\n                    &lt;tr&gt;\n                      &lt;th&gt;Actual Negative&lt;/th&gt;&lt;td&gt;${fp}&lt;/td&gt;&lt;td&gt;${tn}&lt;/td&gt;\n                    &lt;/tr&gt;\n                  &lt;/table&gt;\n                  &lt;/div&gt;\n                &lt;/div&gt;`;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation Multi-Class Models\nWhen evaluating multi-class classification models, we often need to summarize the performance across all classes. This is where macro, micro, and weighted averages come into play. Each of these averages provides a different perspective on the model’s performance and is useful in various scenarios.\n\nThe macro average is calculated by taking the mean of the metrics, such as precision, recall, or F1 score, computed independently for each class. It treats all classes equally, giving equal weight to the performance on each class regardless of its frequency.\nThe micro average aggregates the contributions of all classes to compute the average metric. It calculates the metrics globally by counting the total true positives, false negatives, and false positives.\nThe weighted average calculates each metric for each class like the macro average but takes the size of the class into consideration when averaging. Therefore, it accounts for class imbalance by giving more weight to the metrics of larger classes.\n\nChoosing the Right Average:\n\nUse Macro Averages when you are dealing with imbalanced datasets or when you consider each class equally important.\nUse Weighted Averages when each class’s importance is proportional to its size and you want to weight your metric by class distribution.\nUse Micro Averages if you have a balanced dataset and want an easily understandable metric for overall performance regardless of the class.\n\nSee this medium article for an overview.\n\n\nReporting\nWhen presenting the results of a machine learning model’s performance, especially in the context of academic research, the method of reporting is critical. A confusion matrix, such as the one shown below, is a great visualization tool for both, single- and multi-class classification tasks, like in the example below, where I experimented with face recognition on social media images.\nThe confusion matrix visualizes the model’s predictions in comparison to the true labels, allowing for an immediate grasp of the model’s performance across various classes. It also succinctly illustrates the number of false positives, false negatives, true positives, and true negatives, providing a clear visual summary of the model’s predictive power.\n\n\n\nAn example of a confusion matrix for a complex classification task: Face Recognition on Social Media images. The matrix shows an abundance of false negatives, see right-hand Unknown column: The value shows for each row how many faces for a specific person have not been recognized.\n\n\nThe color intensity in each cell corresponds to the count, with darker cells indicating higher numbers. This visual gradation allows for quick identification of which classes are being predicted accurately and which are not.\nHowever, a confusion matrix is just one of the tools at our disposal for reporting performance metrics. In many cases, supplementing the confusion matrix with additional tables that break down key metrics like accuracy, precision, recall, and F1 score can provide a more nuanced understanding. For example, a table could list each class along with the corresponding precision and recall, giving a clear indication of where the model excels and where it may require further tuning.\n\nAn example for reporting the evaluation metrics of a multi-class classification model, e.g. for face recognition. (This table has been generated using ChatGPT for illustration. Don’t check the numbers.)\n\n\nClass/Category\nAccuracy\nPrecision\nRecall\nF1 Score\n\n\n\n\nAlice Weidel\n0.90\n0.88\n0.92\n0.90\n\n\nAnnalena Baerbock\n0.93\n0.94\n0.89\n0.91\n\n\nArmin Laschet\n0.85\n0.83\n0.88\n0.85\n\n\n…\n…\n…\n…\n…\n\n\nMacro Average\n0.92\n0.91\n0.90\n0.91\n\n\nMicro Average\n0.92\n0.92\n0.92\n0.92\n\n\nWeighted Average\n0.93\n0.92\n0.93\n0.93\n\n\n\nIn our projects reports, we will also include such tables and graphs to comprehensively present the model’s performance, ensuring that we communicate the most detailed insights to our readers."
  },
  {
    "objectID": "evaluation/agreement.html#annotation-export",
    "href": "evaluation/agreement.html#annotation-export",
    "title": "Agreement & Evaluation",
    "section": "Annotation Export",
    "text": "Annotation Export\nIn this section I will guide you step-by-step through the export of annotations from label studio, the calculation of interrater agreements, the process of deriving the gold standard, and finally the evaluation of your model (prompt).\nWe are going to use some sample data from one of my projects. The goal was to classify three content variables for social media texts. The content was either from captions, OCR, or transcribed audio. Three annotators were tasked to code each variable.\n\n\n\nThe annotation interface for the annotation of multiple binary variables.\n\n\nExporting the annotations is straightforward: On the dashboard of your project, click “Export”:\n\n\n\nClick on “Export” in the top-right corner.\n\n\nNext, choose “Create New Snapshot” (Step 1). When creating the snapshot we may keep the original settings, click “Create Snapshot”. The application takes you back to the previous screen. Now we’re ready to click “Download” (Step 3). Your browser starts downloading a JSON file. Depending on the amount of annotations, it may take a while to open the file.\n\n\n\nThe interface to create and download snapshots.\n\n\n\n\n\nCreate a snapshot. We can keep the default values for the moment.\n\n\nThe JSON file can be quite overwhelming. I’ve used this tool to illustrate as a graph for a better understanding:\n\n\n\n\nAn overview of one item with its annotations.\n\n\n\nThe annotations are a list of JSON objects. Each object deals with one item (e.g. one of the texts / images provided for annotation). Each object contains metadata about the annotated items, as well a list of annotation objects (in our case we expect three items).\n\n\n\n\nAn overview of one item with its annotations.\n\n\n\nEach of these annotation objects contains one object for each coding variable, e.g. “Positioning” or “Call to Action” in our example. The actual annotation (in this case for the checkbox interface) is contained in the coding object’s child element value.choices[0].\n\n\n\nAn overview of a singular coding.\n\n\nWith this structure in mind, we can start importing our annotations. The intention behind the following notebook is to work with one coding at a time. We want to create one dataframe per coding, with one row per item (=annotated text / image object), and one column per annnotator. Later on we will add another column for our computational classifications."
  },
  {
    "objectID": "evaluation/agreement.html#the-evaluation-notebook",
    "href": "evaluation/agreement.html#the-evaluation-notebook",
    "title": "Agreement & Evaluation",
    "section": "The Evaluation Notebook",
    "text": "The Evaluation Notebook\n\n\nRead the LabelStudio Annotations from file\nEnter the location (e.g. on Google Drive) of your exported json file and run this cell. It loads the annotations in a long format into the variable all_annotations_df.\n\n\n\n\n\n\nWarning\n\n\n\nThis version does not handle reviews!\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis version has been tested with binary classifications. Other types of nominal data should work out of the box for interrater agreement, model evaluation needs some refactoring!\n\n\n\nhuman_annotations_json = '/content/drive/MyDrive/2024-01-04-Text-Annotation-Sample.json' # @param {type:\"string\"}\n\nimport json\n\nwith open(human_annotations_json, 'r') as f:\n  j = f.read()\n  exported_annotations = json.loads(j)\n\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\ndef process_result(result, coder, md):\n    value_type = result.get('type', \"\")\n    metadata = {\n        **md,\n        \"coder\": coder,\n        \"from_name\": result.get('from_name', \"\")\n    }\n    annotations = []\n    if value_type == \"choices\":\n        choices = result['value'].get('choices', [])\n        for choice in choices:\n            r = {**metadata}\n            r['value'] = choice\n            annotations.append(r)\n    elif value_type == \"taxonomy\":\n        taxonomies = result['value'].get('taxonomy', [])\n        for taxonomy in taxonomies:\n            if len(taxonomy) &gt; 1:\n                taxonomy = \" &gt; \".join(taxonomy)\n            elif len(taxonomy) == 1:\n                taxonomy = taxonomy[0]\n            r = {**metadata}\n            r['value'] = taxonomy\n            annotations.append(r)\n    return annotations\n\nall_annotations = []\n\nfor data in tqdm(exported_annotations):\n    annotations = data.get(\"annotations\")\n    metadata = {\n        **data.get(\"data\")\n    }\n\n    for annotation in annotations:\n      coder = annotation['completed_by']['id']\n      results = annotation.get(\"result\")\n      if results:\n        for result in results:\n          all_annotations.extend(process_result(result, coder, metadata))\n      else:\n        print(\"Skipped Missing Result\")\n\n\nall_annotations_df = pd.DataFrame(all_annotations)\n\n\n\n\n\n# Check the dataframe\nall_annotations_df.head()\n\n\n  \n    \n\n\n\n\n\n\nText\nuuid\nFilename\nIdentifier\ncoder\nfrom_name\nvalue\n\n\n\n\n0\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nPositioning\nTrue\n\n\n1\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nCall to Action\nFalse\n\n\n2\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nDocumentation\nFalse\n\n\n3\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nOCR\nFalse\n\n\n4\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n7379\nPositioning\nTrue\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nContingency Table\nWe select one coding in this step (e.g. Positioning) and create a contingency table where each annotated item (text, image) occupies one row and each coder one column. The identifier should be set to a unique column, like uuid or Filename.\nEnter the from_name for the variable you’re interested in at the moment. (Refer to your LabelStudio Interface for the right from_name).\n\nimport pandas as pd\nimport numpy as np\n\nfrom_name = 'Positioning'\nidentifier = 'uuid'\n\nfiltered_df = all_annotations_df[all_annotations_df['from_name'].str.contains(from_name, case=False)]\n\ndef to_bool(val):\n  if isinstance(val, bool):\n    return val\n  if isinstance(val, str):\n    return val.lower() == \"true\"\n\n  return bool(val)\n\nvalues = filtered_df['value'].unique()\nidentifier_values = filtered_df[identifier].unique()\n\ncontingency_matrix = pd.crosstab(filtered_df[identifier], filtered_df['coder'], values=filtered_df['value'], aggfunc='first')\ncontingency_matrix = contingency_matrix.reindex(identifier_values)\n\n\n# Let's take a look at the contigency table. We refer to each coder using a pseudonymous number.\ncontingency_matrix.head()\n\n\n  \n    \n\n\n\n\n\ncoder\n7107\n7379\n10506\n13724\n\n\nuuid\n\n\n\n\n\n\n\n\n3733\nNaN\nTrue\nTrue\nTrue\n\n\n4185\nFalse\nTrue\nTrue\nNaN\n\n\n530\nNaN\nTrue\nFalse\nTrue\n\n\n2721\nNaN\nFalse\nFalse\nFalse\n\n\n3384\nNaN\nFalse\nFalse\nFalse\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nCalculate Pairwise \\(\\kappa\\)\nLet’s calculate Cohen’s Kappa for each coder pair.\n\nfrom sklearn.metrics import cohen_kappa_score\n\n# Function to calculate Cohen's Kappa for each pair of raters\ndef calculate_kappa(matrix):\n    raters = matrix.columns\n    kappa_scores = []\n    for i in range(len(raters)):\n        for j in range(i+1, len(raters)):\n            rater1, rater2 = raters[i], raters[j]\n            # Drop NA values for the pair of raters\n            pair_matrix = matrix[[rater1, rater2]].dropna()\n            # Skip pairs without overlaps\n            if len(pair_matrix) &gt; 0:\n              kappa = cohen_kappa_score(pair_matrix[rater1], pair_matrix[rater2])\n              kappa_scores.append({\n                  \"Coder 1\": rater1,\n                  \"Coder 2\": rater2,\n                  \"Kappa\": kappa,\n                  \"Overlap\": len(pair_matrix),\n                  \"Coding\": from_name\n                  })\n    return kappa_scores\n\nkappa_scores = calculate_kappa(contingency_matrix)\nkappa_scores_df = pd.DataFrame(kappa_scores)\n\n\n# Let's display the pairwise Kappa agreements.\nkappa_scores_df\n\n\n  \n    \n\n\n\n\n\n\nCoder 1\nCoder 2\nKappa\nOverlap\nCoding\n\n\n\n\n0\n7107\n7379\n0.469027\n20\nPositioning\n\n\n1\n7107\n10506\n0.782609\n20\nPositioning\n\n\n2\n7379\n10506\n0.669500\n50\nPositioning\n\n\n3\n7379\n13724\n0.888889\n30\nPositioning\n\n\n4\n10506\n13724\n0.714286\n30\nPositioning\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nOverall Agreement: Krippendorff’s \\(\\alpha\\)\nNext, we calculate the overall agreement using Krippendorffs Alpha. First we need to install the package.\n\n!pip install krippendorff\n\nCollecting krippendorff\n  Downloading krippendorff-0.6.1-py3-none-any.whl (18 kB)\nRequirement already satisfied: numpy&lt;2.0,&gt;=1.21 in /usr/local/lib/python3.10/dist-packages (from krippendorff) (1.23.5)\nInstalling collected packages: krippendorff\nSuccessfully installed krippendorff-0.6.1\n\n\n\nimport krippendorff\nimport pandas as pd\n\ndef convert_to_reliability_data(matrix):\n    transposed_matrix = matrix.T\n    reliability_data = []\n    for _, ratings in transposed_matrix.iterrows():\n        reliability_data.append(ratings.tolist())\n    return reliability_data\n\nreliability_data = convert_to_reliability_data(contingency_matrix)\n\n# Calculating Krippendorff's Alpha treating \"Unsure\" as a distinct category\nalpha = krippendorff.alpha(reliability_data=reliability_data, level_of_measurement='nominal')\n\nprint(\"Krippendorff's Alpha:\", alpha)\n\nKrippendorff's Alpha: 0.6977687626774848\n\n\n\n\nMajority Decision\nOne approach to assess the quality of machine labelled data is the comparison between machine-generated labels and human-generated labels, commonly known as “gold standard” labels. This process is called “label agreement” or “inter-rater agreement” and is widely used in various fields, including natural language processing, machine learning, and computational social science.\nWe are going to use create a majority_decision column using the human annotations: We have chosen an uneven number of annotators in order to find a majority for each label. First, we are going to create a contingency table (or matrix), then we can determine the majority decision.\n\nimport numpy as np\nimport pandas as pd\n\n# Each row represents an item, and each column a decision from a different annotator.\n\n# Step 1: Find the mode (most common decision) for each row\n# The mode is used as it represents the majority decision.\n# decisions will have the most frequent value in each row, handling ties by keeping all modes.\ndecisions = contingency_matrix.mode(axis=1)\n\n# Step 2: Extract the primary mode (first column after mode operation)\n# This represents the majority decision. If there's a tie, it takes the first one.\nmajority_decisions = decisions.iloc[:, 0]\n\n##########\n## Warning: This part needs some refactoring. Will be updated shortly.\n##########\n# Step 3: Count the number of non-NaN values (actual decisions) per row, excluding the first column\n# Use .iloc[:, 1:] to exclude the first column\n# row_non_nan_counts = contingency_matrix.iloc[:, 1:].notnull().sum(axis=1)\n\n# Step 4: Invalidate the majority decision where the number of decisions is insufficient or even\n# Majority decisions are only considered valid if there are more than 2 decisions and the number of decisions is odd.\n\n# Define a condition for invalidating rows\n# invalid_rows_condition = (row_non_nan_counts &lt; 3) | (row_non_nan_counts % 2 == 0)\n\n\n# Step 5: Append the majority decision as a new column in the contingency matrix\n# This column now represents the aggregated decision from the annotators per item.\ncontingency_matrix['Majority Decision'] = majority_decisions\n\n\ncontingency_matrix.head()\n\n\n  \n    \n\n\n\n\n\ncoder\n7107\n7379\n10506\n13724\nMajority Decision\n\n\nuuid\n\n\n\n\n\n\n\n\n\n3733\nNaN\nTrue\nTrue\nTrue\nTrue\n\n\n4185\nFalse\nTrue\nTrue\nNaN\nTrue\n\n\n530\nNaN\nTrue\nFalse\nTrue\nTrue\n\n\n2721\nNaN\nFalse\nFalse\nFalse\nFalse\n\n\n3384\nNaN\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nImport computational annotations Reading the GPT annotations. Enter the correct file path below. coding_column needs to point to the column with you computational annotations, annotated_identifier to an id / filename that has been passed to LabelStudio project. The annotations are merged with the classifications based on annotated_identifier, in my case uuid.\n\nannotated_file = '/content/drive/MyDrive/2024-01-04-Text-Annotation-Sample.csv'\ncoding_column = 'Positioning'\nannotated_identifier = 'uuid' \n\nannotated_df = pd.read_csv(annotated_file)\n\n\nannotated_df.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nText\nPost Type\nPositioning\nuuid\n\n\n\n\n0\n54\nGemeinsam als #eineUnion stehen wir für eine ...\nPost\nTrue\n54\n\n\n1\n200\nWir wünschen allen Schülerinnen und Schüler...\nPost\nTrue\n200\n\n\n2\n530\nFränkisches Essen gibt Kraft: Nach einem Mitt...\nPost\nFalse\n530\n\n\n3\n707\nKleines Zwischenfazit zum #TvTriell.\nPost\nFalse\n707\n\n\n4\n899\nIn einem paar Tagen sind Wahlen, wichtige Wahl...\nStory\nFalse\n899\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ncontingency_table = pd.merge(contingency_matrix, annotated_df[['uuid', coding_column]], left_on=identifier, right_on=annotated_identifier, how='left')\ncontingency_table.rename(columns={coding_column: \"Model\"}, inplace=True)\n\n\ncontingency_table.head()\n\n\n  \n    \n\n\n\n\n\n\nuuid\n7107\n7379\n10506\n13724\nMajority Decision\nModel\n\n\n\n\n0\n3733\nNaN\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n1\n4185\nFalse\nTrue\nTrue\nNaN\nTrue\nTrue\n\n\n2\n530\nNaN\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n3\n2721\nNaN\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\n3384\nNaN\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nLet’s suppose we’re dealing with binary data. We convert all value to binary, in order to be able to compare them correctly.\n\n\n\n\n\n\nNote\n\n\n\nThe cell below needs refactoring for different type of data. In case of nominal data inside strings it might be enough to skip the cell below. A custom solution is needed for more complex use cases. Additionally, make sure to adopt the majority decision cells to any changes down here and vice versa.\n\n\n\n# Function to convert a column to boolean if it's not already\ndef convert_to_bool(column):\n    if contingency_table[column].dtype != 'bool':\n        bool_map = {'True': True, 'False': False}\n        return contingency_table[column].map(bool_map)\n    return contingency_table[column]\n\n# Convert columns to boolean if they are not already\ncontingency_table['Majority Decision']= convert_to_bool('Majority Decision')\ncontingency_table['Model'] = convert_to_bool('Model')\n\nLet’s quickly check pairwise agreement between the Model and Majority Decision using Cohen’s Kappa:\n\nkappa_scores = calculate_kappa(contingency_table[['Majority Decision', 'Model']])\npd.DataFrame(kappa_scores).head()\n\n\n  \n    \n\n\n\n\n\n\nCoder 1\nCoder 2\nKappa\nOverlap\nCoding\n\n\n\n\n0\nMajority Decision\nModel\n0.831461\n50\nPositioning\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n    \n  \n\n\n\n\nMachine Learning Metrics\nFinally, let’s calculate Accuracy, Precision, and F1 Score and plot a confusion matrix.\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom IPython.display import display, Markdown\n\n\n# Calculating metrics\naccuracy = accuracy_score(contingency_table['Majority Decision'], contingency_table['Model'])\nprecision = precision_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\nrecall = recall_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\nf1 = f1_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\n\n# Creating a DataFrame for the metrics\nmetrics_df = pd.DataFrame({\n    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n    'Value': [accuracy, precision, recall, f1]\n})\n\n# Displaying the DataFrame as a table\ndisplay(metrics_df)\n\n\n  \n    \n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nAccuracy\n0.940000\n\n\n1\nPrecision\n1.000000\n\n\n2\nRecall\n0.769231\n\n\n3\nF1 Score\n0.869565\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\ncm = confusion_matrix(contingency_table['Majority Decision'], contingency_table['Model'])\n\n# Plotting the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['False', 'True'], yticklabels=['False', 'True'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()\n\n\n\n\n\nSource: Evaluation Notebook"
  },
  {
    "objectID": "evaluation/agreement.html#machine-learning-metrics",
    "href": "evaluation/agreement.html#machine-learning-metrics",
    "title": "Agreement & Evaluation",
    "section": "Machine Learning Metrics",
    "text": "Machine Learning Metrics\nFinally, let’s calculate Accuracy, Precision, and F1 Score and plot a confusion matrix.\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom IPython.display import display, Markdown\n\n\n# Calculating metrics\naccuracy = accuracy_score(contingency_table['Majority Decision'], contingency_table['Model'])\nprecision = precision_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\nrecall = recall_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\nf1 = f1_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\n\n# Creating a DataFrame for the metrics\nmetrics_df = pd.DataFrame({\n    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n    'Value': [accuracy, precision, recall, f1]\n})\n\n# Displaying the DataFrame as a table\ndisplay(metrics_df)\n\n\n  \n    \n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nAccuracy\n0.940000\n\n\n1\nPrecision\n1.000000\n\n\n2\nRecall\n0.769231\n\n\n3\nF1 Score\n0.869565\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\ncm = confusion_matrix(contingency_table['Majority Decision'], contingency_table['Model'])\n\n# Plotting the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['False', 'True'], yticklabels=['False', 'True'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()"
  },
  {
    "objectID": "evaluation/agreement.html#conclusion-prompt-optimization",
    "href": "evaluation/agreement.html#conclusion-prompt-optimization",
    "title": "Agreement & Evaluation",
    "section": "Conclusion: Prompt Optimization",
    "text": "Conclusion: Prompt Optimization\nThis chapter provided an overview of interrater agreement measures and machine learning model evaluation metrics. The last part of the chapter showcases the evaluation notebook, which we can use to import Label Studio annotations and calculate different types of metrics, with the ultimate goal of evaluating our model / prompt against the majority decision, our gold standard or ground truth data. The notebook can also be used throughout the prompting and classification process: Sample a smaller number of items and have each member of your group annotate them. Check the interrater agreement, and in case of reasonable agreement levels use this dataset as your training dataset in an iterative process:\n\nFilter your dataset to only include items with training annotations.\nRun the classification for all training rows.\nImport the training annotations and training classifications in the evaluation notebook.\nRun the evaluation, check the quality, especially the confusion matrix: Can you spot any problems? Is the F1-Score reasonable?\nOptionally take a qualitative look at mislabellings. Can you spot any patterns? Take another look at prompt design ideas, e.g. use the negative examples in a conversation with ChatGPT and try to improve the prompt.\nGo back to step 2., repeat until the classification quality stagnates.\n\n\n\n\n\n\n\nWarning\n\n\n\nThe term training data is possibly misleading. When training models using machine learning techinque we use sophisticated approaches to generate a training, a validation set, and a test dataset. The training dataset is used to train the model, the validation set to find the best model, and the test set to estimate the accuracy of your approach. See e.g. this medium article. Using Zero-Shot prompts for classification does not need any training data, when working with Few-Shot prompts we might consider the examples as training data as well.\nWhy did I chose such a misleading name? Because we need to be careful when evaluating our prompts: When optimizing the prompt following the loop above, we might possibly introduce a bias! Once the prompt has been optimized you should run a final evaluation using a larger test set to make sure that your prompt is not “overfitting”.\n\n\nThis chapter, in combination with the classification chapter, provides a solid foundation for computational analyses. The evaluation concept can also be applied to visual classifications: We can use Label Studio to collect the codings from our participants and evaluate them in the same fashion as shown in the evaluation notebook."
  },
  {
    "objectID": "evaluation/agreement.html#further-reading",
    "href": "evaluation/agreement.html#further-reading",
    "title": "Agreement & Evaluation",
    "section": "Further Reading",
    "text": "Further Reading\n\nResnik and Lin (2010): Evaluation of NLP Systems, in The Handbook of Computational Linguistics and Natural Language Processing."
  },
  {
    "objectID": "notebooks/2023_12_11_GPT_Text_Classification.html",
    "href": "notebooks/2023_12_11_GPT_Text_Classification.html",
    "title": "GPT Text Classification",
    "section": "",
    "text": "Let’s read last week’s Text DataFrame\n\nimport pandas as pd\n\ndf = pd.read_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\n\n\n\n\n0\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\n['1. Political parties:\\n- FREIEWÄHLER\\n- Aiwa...\n\n\n1\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\n['Landtagswahl']\n\n\n2\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\n['1. Wahlkampf und Wahlergebnis:\\n- Wahlkampf\\...\n\n\n3\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\n['Israel', 'Terrorismus', 'Hamas', 'Entwicklun...\n\n\n4\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\n['1. Wahlsieg und Parlamentseinstieg\\n- Wahlsi...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nSetup for GPT\n\n!pip install -q openai backoff gpt-cost-estimator\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 221.4/221.4 kB 3.2 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.0/75.0 kB 7.9 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 12.1 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.9/76.9 kB 7.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 6.2 MB/s eta 0:00:00\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllmx 0.0.15a0 requires cohere, which is not installed.\n\n\nWe’re using the new Colab Feature to store keys safely within the Colab Environment. Click on the key on the left to add your API key and enable it for this notebook. Enter the name of your API-Key in the api_key_name variable.\n\nimport openai\nfrom openai import OpenAI\nfrom google.colab import userdata\nimport backoff\nfrom gpt_cost_estimator import CostEstimator\n\napi_key_name = \"openai-lehrstuhl-api\"\napi_key = userdata.get(api_key_name)\n\n# Initialize OpenAI using the key\nclient = OpenAI(\n    api_key=api_key\n)\n\n@CostEstimator()\ndef query_openai(model, temperature, messages, mock=True, completion_tokens=10):\n    return client.chat.completions.create(\n                      model=model,\n                      temperature=temperature,\n                      messages=messages,\n                      max_tokens=600)\n\n# We define the run_request method to wrap it with the @backoff decorator\n@backoff.on_exception(backoff.expo, (openai.RateLimitError, openai.APIError))\ndef run_request(system_prompt, user_prompt, model, mock):\n  messages = [\n    {\"role\": \"system\", \"content\": system_prompt},\n    {\"role\": \"user\", \"content\": user_prompt}\n  ]\n\n  return query_openai(\n          model=model,\n          temperature=0.0,\n          messages=messages,\n          mock=mock\n        )\n\nNext, we create a system prompt describing what we want to classify. For further examples of prompts and advice on prompt engineering see e.g. the prompting guide and further resources linked at the bottom of the page.\nFor the moment we are going to use the prompt from the literature.\nDo not forget the Prompt Archive when experimenting. Share your successfull prompt with us!\n\nsystem_prompt = \"\"\"\nYou are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\n\"\"\"\n\n\nprompt = \"\"\"\nPlease classify the following social media comment into either ‘negative’, ‘neutral’, or ‘positive’. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase.\nText: [TEXT]\n\"\"\"\n\n\n\nRunning the request.\nThe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI! Make sure run_request and system_prompt (see Setup for GPT) are defined before this block by running the two blocks above!\nFill in the MOCK, RESET_COST, COLUMN, SAMPLE_SIZE, and MODEL variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\n\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n#@markdown What's the column name to save the results of the data extraction task to?\nCOLUMN = 'Sentiment' # @param {type: \"string\"}\n#@markdown Do you want to run the request on a smaller sample of the whole data? (Useful for testing). Enter 0 to run on the whole dataset.\nSAMPLE_SIZE = 25 # @param {type: \"number\", min: 0}\n\n#@markdown Which model do you want to use?\nMODEL = \"gpt-3.5-turbo-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n\n\n# Initializing the empty column\nif COLUMN not in df.columns:\n  df[COLUMN] = None\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nfiltered_df = df.copy()\n\n# Skip previously annotated rows\nfiltered_df = filtered_df[pd.isna(filtered_df[COLUMN])]\n\nif SAMPLE_SIZE &gt; 0:\n  filtered_df = filtered_df.sample(SAMPLE_SIZE)\n\nfor index, row in tqdm(filtered_df.iterrows(), total=len(filtered_df)):\n    try:\n        p = prompt.replace('[TEXT]', row['Text'])\n        response = run_request(system_prompt, p, MODEL, MOCK)\n\n        if not MOCK:\n          # Extract the response content\n          # Adjust the following line according to the structure of the response\n          r = response.choices[0].message.content\n\n          # Update the 'new_df' DataFrame\n          df.at[index, COLUMN] = r\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        # Optionally, handle the error (e.g., by logging or by setting a default value)\n\nprint()\n\nReset Cost Estimation\nCost: $0.0002 | Total: $0.0069\n\n\n\n\n\n\ndf[~pd.isna(df['Sentiment'])].head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nSentiment\n\n\n\n\n6\n6\nCyLt56wtNgV\nViele gemischte Gefühle waren das gestern Aben...\nCaption\n['Demokratie']\nnegative\n\n\n27\n27\nCyKwo3Ft6tp\nSwipe dich rückwärts durch die Kampagne ✨\\n\\n🤯...\nCaption\n['Soziale Gerechtigkeit']\npositive\n\n\n29\n29\nCyKwBKcqi31\n#FREIEWÄHLER jetzt zweite Kraft in Bayern! Gro...\nCaption\n['Stärkung der Demokratie', 'Sorgen der Bürger...\npositive\n\n\n66\n66\nCyIjC3QogWT\nIn einer gemeinsamen Erklärung der Parteivorsi...\nCaption\n['Israel']\npositive\n\n\n212\n212\nCyAmHU7qlVc\n#FREIEWÄHLER #Aiwanger\nCaption\nNaN\nneutral\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Save Results\ndf.to_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\nLet’s plot the result for a first big picture\n\n\nimport matplotlib.pyplot as plt\n\n# Count the occurrences of each sentiment\nsentiment_counts = df['Sentiment'].value_counts()\n\n# Create a bar chart\nsentiment_counts.plot(kind='bar')\n\n# Adding labels and title\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Sentiment Counts')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "notebooks/ocr-notebook.html",
    "href": "notebooks/ocr-notebook.html",
    "title": "Social Media Lab",
    "section": "",
    "text": "We’re using easyocr. See the documentation for more complex configurations. Using CPU only this process takes from minutes to hours (depends on the amount of images). OCR may also be outsourced (e.g. using Google Vision API), see future sessions (and Memespector) for this.\n\n!pip -q install easyocr\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 29.7 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 908.3/908.3 kB 57.5 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 29.6 MB/s eta 0:00:00\n\n\n\n# Imports for OCR\nimport easyocr\nreader = easyocr.Reader(['de','en'])\n\nWARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\nWARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\nWARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n\n\nProgress: |██████████████████████████████████████████████████| 100.0% CompleteProgress: |██████████████████████████████████████████████████| 100.0% Complete\n\n\nWe define a very simple method to receive one string for all text recognized: The readtextmethod returns a list of text areas, in this example we concatenate the string, therefore the order of words is sometimes not correct.\nAlso, we save the file to Google Drive to save our results.\n\ndef run_ocr(image_path):\n    ocr_result = reader.readtext(image_path, detail = 0)\n    ocr_text = \" \".join(ocr_result)\n    return ocr_text\n\ndf['ocr_text'] = df['image_file'].apply(run_ocr)\n\n# Saving Results to Drive\ndf.to_csv('/content/drive/MyDrive/2022-11-09-Stories-Exported.csv')\n\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0.1\nUnnamed: 0\nID\nTime of Posting\nType of Content\nvideo_url\nimage_url\nUsername\nVideo Length (s)\nExpiration\n...\nIs Verified\nStickers\nAccessibility Caption\nAttribution URL\nvideo_file\naudio_file\nduration\nsampling_rate\nimage_file\nocr_text\n\n\n\n\n0\n0\n0\n3234500408402516260_1383567706\n2023-11-12 15:21:53\nImage\nNaN\nNaN\nnews24\nNaN\n2023-11-13 15:21:53\n...\nTrue\n[]\nPhoto by News24 on November 12, 2023. May be a...\nhttps://www.threads.net/t/CzjB80Zqme0\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234500408402516260_1383567706.jpg\nKeee WEEKEND NEWS24 PLUS: TESTING FORDS RANGER...\n\n\n1\n1\n1\n3234502795095897337_8537434\n2023-11-12 15:26:39\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:26:39\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234502795095897337_8537434.jpg\nDieses Auto ist einfach der Horror Du glaubst ...\n\n\n2\n2\n2\n3234503046678453705_8537434\n2023-11-12 15:27:10\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:27:10\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234503046678453705_8537434.jpg\nTouchdown bei Taylor Swift und Travis Kelce De...\n\n\n3\n3\n3\n3234503930728728807_8537434\n2023-11-12 15:28:55\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:28:55\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234503930728728807_8537434.jpg\nHorror-Diagnose für Barton Cowperthwaite Netfl...\n\n\n4\n4\n4\n3234504185910204562_8537434\n2023-11-12 15:29:25\nImage\nNaN\nNaN\nbild\nNaN\n2023-11-13 15:29:25\n...\nTrue\n[]\nPhoto by BILD on November 12, 2023. May be an ...\nNaN\nNaN\nNaN\nNaN\nNaN\nmedia/images/3234504185910204562_8537434.jpg\n3v Bilde GG JJ Besorgniserregende Ufo-Aktivitä...\n\n\n\n\n\n5 rows × 21 columns"
  },
  {
    "objectID": "notebooks/2024_01_12_Visual_BERTopic_Bauernproteste.html",
    "href": "notebooks/2024_01_12_Visual_BERTopic_Bauernproteste.html",
    "title": "Visual Exploration",
    "section": "",
    "text": "For this notebook we use a 4CAT corpus collected from TikTok about the 2024 Farmers’ Protest in Germany. Let’s take a look at all relevant columns. We’re mostly dealing with the image_file column. Additionally, the images files should be extracted to the /content/media/images/ path. (See linked notebook for the conversion from the original 4CAT files).\ndf[['id', 'body', 'Transcript', 'image_file']].head()\n\n\n  \n    \n\n\n\n\n\n\nid\nbody\nTranscript\nimage_file\n\n\n\n\n0\n7321692663852404001\n#Fakten #mutzurwahrheit #ulrichsiegmund #AfD #...\nLiebe Freunde, schaut euch das an, das ist der...\n/content/media/images/7321692663852404001.jpg\n\n\n1\n7320593840212151584\nUnstoppable 🇩🇪 #deutschland #8januar2024 #baue...\nthe next, video!!\n/content/media/images/7320593840212151584.jpg\n\n\n2\n7321341957333060896\n08.01.2024 Streik - Hoss & Hopf #hossundhopf #...\nscheiß Bauern, die, was weiß ich, ich habe auc...\n/content/media/images/7321341957333060896.jpg\n\n\n3\n7321355364950117665\n#streik #2024 #bauernstreik2024 #deutschland #...\n😎😎😎😎😎😎😎😎😎\n/content/media/images/7321355364950117665.jpg\n\n\n4\n7321656341590789409\n#🌞❤️ #sunshineheart #sunshineheartforever #🇩🇪 ...\nNaN\n/content/media/images/7321656341590789409.jpg"
  },
  {
    "objectID": "notebooks/2024_01_12_Visual_BERTopic_Bauernproteste.html#bertopic",
    "href": "notebooks/2024_01_12_Visual_BERTopic_Bauernproteste.html#bertopic",
    "title": "Visual Exploration",
    "section": "BERTopic",
    "text": "BERTopic\nLet’s first install bertopic including the vision extensions.\n\n\n\n\n\n\nNote\n\n\n\nThe following code has been taken from the BERTopic documentation and was only slightly changed.\n\n\n\n!pip install bertopic[vision]\n\n\nImages Only\nNext, we prepare the pipeline for an image-only model: We want to fit the Topic Model on the image content only. We follow the BERTOpic Multimodal Manual, and generate image captions using the vit-gpt2-image-captioningpackage. The documentation offers a lot of different options, we can incorporate textual content for the topic modeling, or fit the model on textual information only and look for the best matching images for each cluster and display them.\nIn our example we focus on image-only topics models.\n\nfrom bertopic.representation import KeyBERTInspired, VisualRepresentation\nfrom bertopic.backend import MultiModalBackend\n\n# Image embedding model\nembedding_model = MultiModalBackend('clip-ViT-B-32', batch_size=32)\n\n# Image to text representation model\nrepresentation_model = {\n    \"Visual_Aspect\": VisualRepresentation(image_to_text_model=\"nlpconnect/vit-gpt2-image-captioning\")\n}\n\nNext, select the column with the path of your images files, in my example image_file. Convert it to a python list.\n\nimage_only_df = df.copy()\nimages = image_only_df['image_file'].to_list()\n\nNow it’s time to fit the model.\n\nfrom bertopic import BERTopic\n\n# Train our model with images only\ntopic_model = BERTopic(embedding_model=embedding_model, representation_model=representation_model, min_topic_size=5)\ntopics, probs = topic_model.fit_transform(documents=None, images=images)\n\n100%|██████████| 7/7 [02:33&lt;00:00, 21.88s/it]\n100%|██████████| 7/7 [00:02&lt;00:00,  2.99it/s]\n\n\nFinally let’s display the topics. Remember: Topic -1 is a collection of documenst that do not fit into any topic.\n\n# See linked notebook for code."
  },
  {
    "objectID": "notebooks/2023_12_14_Create_LabelStudio_Text_Evaluation.html",
    "href": "notebooks/2023_12_14_Create_LabelStudio_Text_Evaluation.html",
    "title": "Human Annotations",
    "section": "",
    "text": "Install the label-studio-sdk package for programmatic control of Label Studio:\n\n!pip -q install label-studio-sdk\n\nNext, let’s read the text master from the previous sessions\n\nimport pandas as pd\n\ndf = pd.read_csv('/content/drive/MyDrive/2023-12-01-Export-Posts-Text-Master.csv')\n\nIn my video on GPT text classification I mentioned the problem of the unique identifier, as we also need a unique identifier for the annotations. Use the code below in our text classification notebook when working with multidocument classifications!\n\ndf['identifier'] = df.apply(lambda x: f\"{x['shortcode']}-{x['Text Type']}\", axis=1)\n\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nshortcode\nText\nText Type\nPolicy Issues\nidentifier\n\n\n\n\n0\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\n['1. Political parties:\\n- FREIEWÄHLER\\n- Aiwa...\nCyMAe_tufcR-Caption\n\n\n1\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\n['Landtagswahl']\nCyL975vouHU-Caption\n\n\n2\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\n['1. Wahlkampf und Wahlergebnis:\\n- Wahlkampf\\...\nCyL8GWWJmci-Caption\n\n\n3\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\n['Israel', 'Terrorismus', 'Hamas', 'Entwicklun...\nCyL7wyJtTV5-Caption\n\n\n4\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\n['1. Wahlsieg und Parlamentseinstieg\\n- Wahlsi...\nCyLxwHuvR4Y-Caption\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nLabelStudio Setup\nPlease specify the the URL and API-Key for you LabelStudio Instance.\n\nimport json\nfrom google.colab import userdata\n\nlabelstudio_key_name = \"label2-key\"\nlabelstudio_key = userdata.get(labelstudio_key_name)\nlabelstudio_url = \"https://label2.digitalhumanities.io\"\n\n\n\nCreate LabelStudio Interface\nBefore creating the LabelStudio project you will need to define your labelling interface. Once the project is set up you will only be able to edit the interface in LabelStudio.\n\ninterface = \"\"\"\n&lt;View style=\"display:flex;\"&gt;\n  &lt;View style=\"flex:33%\"&gt;\n    &lt;Text name=\"Text\" value=\"$Text\"/&gt;\n  &lt;/View&gt;\n  &lt;View style=\"flex:66%\"&gt;\n\"\"\"\n\n\n\nAdd a simple coding interface\nDo you want add codes (Classification) to the images? Please name your coding instance and add options.  By running this cell multiple times you’re able to add multiple variables (not recommended)\nAdd the variable name to coding_name, the checkbox labels in coding_values, and define whether to expect single choice or multiple choice input for this variable in coding_choice.\n\ncoding_name = \"Sentiment\"\ncoding_values = \"Positive,Neutral,Negative\"\ncoding_choice = \"single\"\n\ncoding_interface = '&lt;Header value=\"{}\" /&gt;&lt;Choices name=\"{}\" choice=\"{}\" toName=\"Text\"&gt;'.format(coding_name, coding_name,coding_choice)\n\nfor value in coding_values.split(\",\"):\n  value = value.strip()\n  coding_interface += '&lt;Choice value=\"{}\" /&gt;'.format(value)\n\ncoding_interface += \"&lt;/Choices&gt;\"\n\ninterface += coding_interface\n\nprint(\"Added {}\".format(coding_name))\n\nFinally run the next line to close the XML of the annotation interface. Run this line even if you do not want to add any variables at the moment!\n\ninterface += \"\"\"\n        &lt;/View&gt;\n    &lt;/View&gt;\n    \"\"\"\n\n\n\nProject Upload\nThis final step creates a LabelStudio project and configures the interface. Define a project_name, select the text_column, and identifier_column. Additionally, you may define a sample_percentage for sampling, we start with \\(30\\%\\). When working with the Open Source version of Label Studio we need to create on project per annotator, enter the number of annotators in num_copies to create multiple copies at once.\n\nfrom label_studio_sdk import Client\nimport contextlib\nimport io\n\nproject_name = \"vSMA Test 1\" \ntext_column = \"Text\" \nidentifier_column = \"identifier\" \nsample_percentage = 30  \nnum_copies = 1 \n\nsample_size = round(len(df) * (sample_percentage / 100))\n\nls = Client(url=labelstudio_url, api_key=labelstudio_key)\n\ndf_tasks = df[[identifier_column, text_column]]\ndf_tasks = df_tasks.sample(sample_size)\ndf_tasks = df_tasks.fillna(\"\")\n\nfor i in range(0, num_copies):\n  project_name = f\"{project_name} #{i}\"\n  # Create the project\n  project = ls.start_project(\n      title=project_name,\n      label_config=interface,\n      sampling=\"Uniform sampling\"\n  )\n\n  with contextlib.redirect_stdout(io.StringIO()):\n    project.import_tasks(\n          df_tasks.to_dict('records')\n        )\n\n  print(f\"All done, created project #{i}! Visit {labelstudio_url}/projects/{project.id}/ and get started labelling!\")\n\nAll done, created project #0! Visit https://label2.digitalhumanities.io/projects/61/ and get started labelling!"
  },
  {
    "objectID": "notebooks/2024_01_12_Visualize_Mod_Classes.html",
    "href": "notebooks/2024_01_12_Visualize_Mod_Classes.html",
    "title": "Visual Exploration",
    "section": "",
    "text": "Unzip the image files, e.g. from your Drive.\n\n!zip -r /content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-09-Images-Clean.zip media\n\nImport the CSV-File exported from Gephi. Set sample_size to your desired number, I recommend a low number, e.g. 5.\n\nimport pandas as pd\n\ngephi_file = \"/content/drive/MyDrive/2024-01-09-Bauernproteste/2024-01-11-Google-Vision-Graph-w-modclasses.csv\"  #@param {type:\"string\"}\nsample_size = 5 \ngephi_df = pd.read_csv(gephi_file)\n\nRender the Sample: Hit run for the next cell to create an HTML view of image classifications. The HTML will also be saved to file, check the files in the left pane for a file named {formatted_date}-Gephi-Mod-Classes-Visualisation.html to download the document to your computer. The file includes the base64 encoded images.\n\n# See linked notebook for code."
  },
  {
    "objectID": "notebooks/2024_01_04_Evaluation_Kurs.html",
    "href": "notebooks/2024_01_04_Evaluation_Kurs.html",
    "title": "Agreement & Evaluation",
    "section": "",
    "text": "Enter the location (e.g. on Google Drive) of your exported json file and run this cell. It loads the annotations in a long format into the variable all_annotations_df.\n\n\n\n\n\n\nWarning\n\n\n\nThis version does not handle reviews!\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThis version has been tested with binary classifications. Other types of nominal data should work out of the box for interrater agreement, model evaluation needs some refactoring!\n\n\n\nhuman_annotations_json = '/content/drive/MyDrive/2024-01-04-Text-Annotation-Sample.json' # @param {type:\"string\"}\n\nimport json\n\nwith open(human_annotations_json, 'r') as f:\n  j = f.read()\n  exported_annotations = json.loads(j)\n\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\ndef process_result(result, coder, md):\n    value_type = result.get('type', \"\")\n    metadata = {\n        **md,\n        \"coder\": coder,\n        \"from_name\": result.get('from_name', \"\")\n    }\n    annotations = []\n    if value_type == \"choices\":\n        choices = result['value'].get('choices', [])\n        for choice in choices:\n            r = {**metadata}\n            r['value'] = choice\n            annotations.append(r)\n    elif value_type == \"taxonomy\":\n        taxonomies = result['value'].get('taxonomy', [])\n        for taxonomy in taxonomies:\n            if len(taxonomy) &gt; 1:\n                taxonomy = \" &gt; \".join(taxonomy)\n            elif len(taxonomy) == 1:\n                taxonomy = taxonomy[0]\n            r = {**metadata}\n            r['value'] = taxonomy\n            annotations.append(r)\n    return annotations\n\nall_annotations = []\n\nfor data in tqdm(exported_annotations):\n    annotations = data.get(\"annotations\")\n    metadata = {\n        **data.get(\"data\")\n    }\n\n    for annotation in annotations:\n      coder = annotation['completed_by']['id']\n      results = annotation.get(\"result\")\n      if results:\n        for result in results:\n          all_annotations.extend(process_result(result, coder, metadata))\n      else:\n        print(\"Skipped Missing Result\")\n\n\nall_annotations_df = pd.DataFrame(all_annotations)\n\n\n\n\n\n# Check the dataframe\nall_annotations_df.head()\n\n\n  \n    \n\n\n\n\n\n\nText\nuuid\nFilename\nIdentifier\ncoder\nfrom_name\nvalue\n\n\n\n\n0\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nPositioning\nTrue\n\n\n1\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nCall to Action\nFalse\n\n\n2\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nDocumentation\nFalse\n\n\n3\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n13724\nOCR\nFalse\n\n\n4\nCDU #SOFORTPROGRAMM MITTELSTANDSPAKET WIR MACH...\n3733\ncdu/2021-09-13_15-01-28_UTC.jpg\nCTxB6cMKe2U\n7379\nPositioning\nTrue"
  },
  {
    "objectID": "notebooks/2024_01_04_Evaluation_Kurs.html#machine-learning-metrics",
    "href": "notebooks/2024_01_04_Evaluation_Kurs.html#machine-learning-metrics",
    "title": "Agreement & Evaluation",
    "section": "Machine Learning Metrics",
    "text": "Machine Learning Metrics\nFinally, let’s calculate Accuracy, Precision, and F1 Score and plot a confusion matrix.\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom IPython.display import display, Markdown\n\n\n# Calculating metrics\naccuracy = accuracy_score(contingency_table['Majority Decision'], contingency_table['Model'])\nprecision = precision_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\nrecall = recall_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\nf1 = f1_score(contingency_table['Majority Decision'], contingency_table['Model'], average='binary')\n\n# Creating a DataFrame for the metrics\nmetrics_df = pd.DataFrame({\n    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n    'Value': [accuracy, precision, recall, f1]\n})\n\n# Displaying the DataFrame as a table\ndisplay(metrics_df)\n\n\n  \n    \n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nAccuracy\n0.940000\n\n\n1\nPrecision\n1.000000\n\n\n2\nRecall\n0.769231\n\n\n3\nF1 Score\n0.869565\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\ncm = confusion_matrix(contingency_table['Majority Decision'], contingency_table['Model'])\n\n# Plotting the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['False', 'True'], yticklabels=['False', 'True'])\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()"
  },
  {
    "objectID": "notebooks/firebase-interface-notebook.html",
    "href": "notebooks/firebase-interface-notebook.html",
    "title": "Project Creation",
    "section": "",
    "text": "The following lines of code assume that the firebase Credential File has been downloaded from GRIPS and uploaded to Colab / your Jupyter project path. First of all install the necessary packages:\n\n!pip -q install firebase-admin\n\nNext, we connect to our firebase project. Please update the credentials_path variable with the path to your credentials file (see above).\n\nimport firebase_admin\nfrom firebase_admin import credentials, firestore\n\ncredentials_path = '/content/XXXX-adminsdk-YYYYYY.json' \n\ncred = credentials.Certificate(credentials_path)\nfirebase_admin.initialize_app(cred)\ndb = firestore.client()\n\n\nProject Creation\nPlease provide an alert_email and project_name to create a new project on the backend. The backend checks hourly when the last stories have been uploaded to a project. If no story has been uploaded for more than 12 hours, an email alert will be triggered.\nRun the cell to create the new project on the backend. When successfull, the project id and api key will be displayed.\n\nfrom IPython.display import display, Markdown\nimport pandas as pd\n\nalert_email = 'michael@achmann.me'\nproject_name = 'Forschungsseminar23 Test'\n\n# Create Project\nimport uuid\n\n# Generate a UUID for the document\nproject_id = str(uuid.uuid4())\napi_key = str(uuid.uuid4())\n\n# Your data\ndata = {\n    \"api_key\": api_key,\n    \"email\": alert_email,\n    \"name\": project_name\n}\n\n# Add a new document with a UUID as the document name (ID)\ndoc_ref = db.collection('projects').document(project_id)\ndoc_ref.set(data)\n\ndisplay(Markdown(\"### Project Created:\"))\ndisplay(Markdown(f\"**Project Name:** {project_name}\"))\ndisplay(Markdown(f\"**Alert Email:** {alert_email}\"))\ndisplay(Markdown(f\"**Project ID:** {project_id}\"))\ndisplay(Markdown(f\"**API-Key:** {api_key}\"))\n\n\nProject Created:\nProject Name: Forschungsseminar23 Test\nAlert Email: michael@achmann.me\nProject ID: 959466fe-4088-4099-a6b2-3cbe058889d3\nAPI-Key: 554fbce8-fb15-44f1-bb4d-54cdc57554f2\n\n\n\nConfigure the Plugin\nConfigure Zeeschuimer-F using the above information after creating a project. In order to access the settings of Firefox plugins click on the puzzle tile on the top right of the browser. Click on Zeeschuimer F and the settings open.\n\n\n\nScreenshot of Firefox with open extensions menu\n\n\nFill in the Firebase Project field with the project id and aFirebase API Key with the api key provided after running the Project Creation. The Firebase Endopint URL will be provided via GRIPS (unless you’ve installed your own instance).\n\n\n\nScreenshot of the Settings for Zeeschuimer-F\n\n\n1) Turn the IG Stories Switch on, 2) restart your browser for the values to be loaded correctly. Once the browser has started again, you’re ready to collect you first stories! Open the Instagram website and open any story.\n\n\n\nScreenshot of the switch\n\n\nCheck the extension settings page to see whether it is collecting stories while browsing. The counter should increase with each story visit. The remote collection process can currently only be checked through the Firebase Interface notebook. Follow the next steps to download the collected data.\n\n\nProject Export\nThe following code downloads all stories in JSON format and saves it locally (i.e. on your colab instance). Provide the PROJECT_ID variable and an export_path to download all stories.\n\nfrom tqdm.auto import tqdm\nimport os\nimport json\n\nPROJECT_ID = '959466fe-4088-4099-a6b2-3cbe058889d3'\nexport_path = '/content/export' \n\n\ndef fetch_stories(project_id):\n    stories_ref = db.collection('projects').document(project_id).collection('stories')\n    docs = stories_ref.stream()\n\n    stories = []\n    for doc in docs:\n        stories.append(doc.to_dict())\n\n    return stories\n\ndb = fetch_stories(PROJECT_ID)\n\nif not os.path.exists('export'):\n    os.makedirs('export')\n\n# Iterate over each element in the database\nfor element in tqdm(db, desc='Exporting elements'):\n    # Serialize the element to JSON\n    element_json = json.dumps(element, indent=4)\n\n    # Write to a file named {id}.json\n    with open(os.path.join('export', f\"{element['id']}.json\"), 'w') as f:\n        f.write(element_json)\n\n\n\n\n\n\nConvert to DataFrame\nNext, we convert the exported JSON files to a pandas DataFrame and save the table as CSV. Provide the df_export_path variable for the location where to save the exported CSV file.\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nThe DataFrame in the current version has a different structure than the one we created when downloading Instagram Posts.. In order to compare stories with posts we will might want to use the same data structure.\n\n\n\n\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\n\ndf_export_path = '/content/2022-11-09-Stories-Exported.csv' \n\ndef process_instagram_story(data):\n\n    # Extract relevant information\n    story_info = {\n        'ID': data.get(\"id\"),\n        'Time of Posting': datetime.utcfromtimestamp(data['taken_at']).strftime('%Y-%m-%d %H:%M:%S'),\n        'Type of Content': 'Video' if 'video_duration' in data else 'Image',\n        'video_url': None,\n        'image_url': None,\n        'Username': data['user']['username'],\n        'Video Length (s)': data.get('video_duration', None),\n        'Expiration': (datetime.utcfromtimestamp(data['taken_at']) + timedelta(hours=24)).strftime('%Y-%m-%d %H:%M:%S'),\n        'Caption': data.get('caption', None),\n        'Is Verified': data['user']['is_verified'],\n        'Stickers': data.get('story_bloks_stickers', []),\n        'Accessibility Caption': data.get('accessibility_caption', ''),\n        'Attribution URL': data.get('attribution_content_url', '')\n    }\n\n    return story_info\n\nrows = []\nfor element in db:\n  rows.append(process_instagram_story(element))\n\ndf = pd.DataFrame(rows)\ndf.to_csv(df_export_path)\nprint(f\"Successfully exported {len(df)} rows as CSV.\")\n\nSuccessfully exported 22 rows as CSV.\n\n\nNow let’s take a look at the structure of the exported data:\n\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nID\nTime of Posting\nType of Content\nvideo_url\nimage_url\nUsername\nVideo Length (s)\nExpiration\nCaption\nIs Verified\nStickers\nAccessibility Caption\nAttribution URL\n\n\n\n\n0\n3231585718932790545_1483455177\n2023-11-08 14:50:59\nImage\n&lt;NA&gt;\nhttps://storage.googleapis.com/zeeschuimer-fb-...\nrmf24.pl\nNaN\n2023-11-09 14:50:59\nNone\nFalse\n[]\nPhoto by Fakty RMF FM | Rozmowy | Podcasty on ...\n\n\n\n1\n3231585778860997221_1483455177\n2023-11-08 14:51:06\nImage\n&lt;NA&gt;\nhttps://storage.googleapis.com/zeeschuimer-fb-...\nrmf24.pl\nNaN\n2023-11-09 14:51:06\nNone\nFalse\n[]\nPhoto by Fakty RMF FM | Rozmowy | Podcasty on ...\n\n\n\n2\n3231750838597692854_1349651722\n2023-11-08 20:19:00\nVideo\nhttps://storage.googleapis.com/zeeschuimer-fb-...\n&lt;NA&gt;\ntagesschau\n13.300\n2023-11-09 20:19:00\nNone\nTrue\n[]\n\n\n\n\n3\n3231750989408058657_1349651722\n2023-11-08 20:19:18\nVideo\nhttps://storage.googleapis.com/zeeschuimer-fb-...\n&lt;NA&gt;\ntagesschau\n15.267\n2023-11-09 20:19:18\nNone\nTrue\n[]\n\n\n\n\n4\n3231751135118088390_1349651722\n2023-11-08 20:19:35\nVideo\nhttps://storage.googleapis.com/zeeschuimer-fb-...\n&lt;NA&gt;\ntagesschau\n17.000\n2023-11-09 20:19:35\nNone\nTrue\n[]\n\n\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nDownload Images and Videos\nAll videos and images for our Instagram stories have been downloaded by our firebase backend. They are saved in a Cloud Bucket. The following cell helps with these two steps:\n\nCreate a signed link to each video and image\nDownload each file and saves it in the following structure: {media_export_path}/{image|video}/{username}/{ID.jpg|mp4}. It is important to keep a unique identifier (here ID) to map metadata and images for future data analysis.\n\nPlease provide a storage_bucket and media_export_path.\n\nstorage_bucket = \"XXXX.appspot.com\"  \nmedia_export_path =  '/content/media/'\n\nfrom firebase_admin import storage\nimport os\nimport requests\n\nbucket = storage.bucket(storage_bucket)\n\ndef generate_signed_url(username, content_id, file_type):\n    if file_type not in ['images', 'videos']:\n        raise ValueError(\"Invalid file type specified\")\n\n    ext = 'jpeg' if file_type == 'images' else 'mp4'\n    blob_path = f\"projects/{PROJECT_ID}/stories/{file_type}/{username}/{content_id}.{ext}\"\n    blob = bucket.blob(blob_path)\n    # Set the expiration of the link. Here, it's set to 24 hours.\n    return blob.generate_signed_url(expiration=timedelta(hours=24), method='GET')\n\n# Create a function to be applied across DataFrame rows\ndef apply_generate_signed_url(row):\n    image_url = generate_signed_url(row['Username'], row['ID'], 'images')\n    video_url = generate_signed_url(row['Username'], row['ID'], 'videos') if row['Type of Content'] == 'Video' else pd.NA\n    return pd.Series({'image_url': image_url, 'video_url': video_url})\n\n# Apply the function along the axis=1 (row-wise)\ndf[['image_url', 'video_url']] = df.apply(apply_generate_signed_url, axis=1)\n\n# Now, creating the lists for images and videos can be done more efficiently\ndata_images = df.loc[df['image_url'].notna(), ['ID', 'image_url', 'Username', 'Time of Posting']] \\\n               .rename(columns={'image_url': 'url', 'Time of Posting': 'datetime'}) \\\n               .to_dict('records')\n\ndata_videos = df.loc[df['video_url'].notna(), ['ID', 'video_url', 'Username', 'Time of Posting']] \\\n               .rename(columns={'video_url': 'url', 'Time of Posting': 'datetime'}) \\\n               .to_dict('records')\n\n\ndef create_directories(base_path, entries, subdir):\n    usernames = set(entry['Username'] for entry in entries)\n    for username in usernames:\n        os.makedirs(os.path.join(base_path, subdir, username), exist_ok=True)\n\ndef download_file(entry, media_type, media_export_path, session):\n    directory = os.path.join(media_export_path, media_type, entry['Username'])\n    ext = 'jpg' if media_type == 'images' else 'mp4'\n    filename = os.path.join(directory, f\"{entry['ID']}.{ext}\")\n\n    with session.get(entry['url'], stream=True) as response:\n        if response.status_code == 200:\n            with open(filename, 'wb') as file:\n                for chunk in response.iter_content(8192):\n                    file.write(chunk)\n        else:\n            print(f\"Failed to download {entry['url']}. Status code: {response.status_code}\")\n\nsession = requests.Session()\n# Pre-create directories\ncreate_directories(media_export_path, data_images, 'images')\ncreate_directories(media_export_path, data_videos, 'videos')\n\n# Download images\nfor entry in tqdm(data_images, desc=\"Downloading Images\", unit=\"file\"):\n    download_file(entry, 'images', media_export_path, session)\n\n# Download videos\nfor entry in tqdm(data_videos, desc=\"Downloading Videos\", unit=\"file\"):\n    download_file(entry, 'videos', media_export_path, session)\n\nprint(\"Download complete!\")\n\n\n\n\n\n\n\nDownload complete!\n\n\n\n\nPrepare Downloadable ZIP\nRun the following to ZIP all files. Optionally copy them to Google Drive.\n\n!zip -r 2023-11-09-Story-Media-Export.zip media/*\n\n\n!cp 2023-11-09-Story-Media-Export.zip /content/drive/MyDrive/"
  },
  {
    "objectID": "notebooks/2023_12_01_BERTopic.html",
    "href": "notebooks/2023_12_01_BERTopic.html",
    "title": "Import CrowdTangle Data",
    "section": "",
    "text": "For this example we import a CrowdTangle dataframe, which has been preprocessing using the OCR Notebook. We are only dealing with one image per post, there are no videos (= no transcriptions). In this example, we have up to two text columns per Post, Description which contains the caption, and ocr_text. When exploring the textual content of the posts, we see each of those columns as one document. Thus, we transform our table and create new_df as a Text Table that contains a reference to the post (shortcode), the actual Text, and a Text Type column.\nimport pandas as pd\n\ndf = pd.read_csv('/content/drive/MyDrive/2023-11-30-Export-Posts-Crowd-Tangle.csv')\nNext, we want to transform the DataFrame from one post per row, to one text document per row (Think tidydata!)\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nUnnamed: 0\nAccount\nUser Name\nFollowers at Posting\nPost Created\nPost Created Date\nPost Created Time\nType\nTotal Interactions\nLikes\n...\nPhoto\nTitle\nDescription\nImage Text\nSponsor Id\nSponsor Name\nOverperforming Score (weighted — Likes 1x Comments 1x )\nshortcode\nimage_file\nocr_text\n\n\n\n\n0\n0\nFREIE WÄHLER Bayern\nfw_bayern\n9138\n2023-10-09 20:10:19 CEST\n2023-10-09\n20:10:19\nPhoto\n566\n561\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t51...\nNaN\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nFREIE WAHLER 15,8 %\nNaN\nNaN\n2.95\nCyMAe_tufcR\nmedia/images/fw_bayern/CyMAe_tufcR.jpg\nFREIE WAHLER 15,8 %\n\n\n1\n1\nJunge Liberale JuLis Bayern\njulisbayern\n4902\n2023-10-09 19:48:02 CEST\n2023-10-09\n19:48:02\nAlbum\n320\n310\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t51...\nNaN\nDie Landtagswahl war für uns als Liberale hart...\nNaN\nNaN\nNaN\n1.41\nCyL975vouHU\nmedia/images/julisbayern/CyL975vouHU.jpg\nFreie EDP Demokraten BDB FDP FB FDP DANKE FÜR ...\n\n\n2\n2\nJunge Union Deutschlands\njunge_union\n44414\n2023-10-09 19:31:59 CEST\n2023-10-09\n19:31:59\nPhoto\n929\n925\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t39...\nNaN\nNach einem starken Wahlkampf ein verdientes Er...\nHERZLICHEN GLÜCKWUNSCH! Unsere JUler im bayris...\nNaN\nNaN\n1.17\nCyL8GWWJmci\nmedia/images/junge_union/CyL8GWWJmci.jpg\nHERZLICHEN GLÜCKWUNSCH! Unsere JUler im bayris...\n\n\n3\n3\nKatharina Schulze\nkathaschulze\n37161\n2023-10-09 19:29:02 CEST\n2023-10-09\n19:29:02\nPhoto\n1,074\n1009\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t51...\nNaN\nSo viele Menschen am Odeonsplatz heute mit ein...\nNaN\nNaN\nNaN\n1.61\nCyL7wyJtTV5\nmedia/images/kathaschulze/CyL7wyJtTV5.jpg\nJuo I W\n\n\n4\n4\nJunge Union Deutschlands\njunge_union\n44414\n2023-10-09 18:01:34 CEST\n2023-10-09\n18:01:34\nAlbum\n1,655\n1644\n...\nhttps://scontent-sea1-1.cdninstagram.com/v/t39...\nNaN\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nNaN\nNaN\nNaN\n2.34\nCyLxwHuvR4Y\nmedia/images/junge_union/CyLxwHuvR4Y.jpg\n12/12 der hessischen JU-Kandidaten ziehen in d...\n\n\n\n\n\n5 rows × 25 columns\nWe restructure df to focus on two key text-based columns: ‘Description’ and ‘ocr_text’. The goal is to create a streamlined DataFrame where each row corresponds to an individual text entry, either from the ‘Description’ or the ‘ocr_text’ fields. To achieve this, we first split the original DataFrame into two separate DataFrames, one for each of these columns. We then rename these columns to ‘Text’ for uniformity. Additionally, we introduce a new column, ‘Text Type’, to categorize each text entry as either ‘Caption’ (originating from ‘Description’) or ‘OCR’ (originating from ‘ocr_text’). The ‘shortcode’ column is retained as a unique identifier for each entry. Finally, we concatenate these two DataFrames into a single DataFrame, ensuring a clean and organized structure. This restructured DataFrame facilitates easier analysis and processing of the text data, segregating it by source while maintaining a link to its original post via the ‘shortcode’. The code also includes a step to remove any rows with empty or NaN values in the ‘Text’ column, ensuring data integrity and cleanliness.\nimport pandas as pd\n\n# Creating two separate dataframes\ndf_description = df[['shortcode', 'Description']].copy()\ndf_ocr_text = df[['shortcode', 'ocr_text']].copy()\n\n# Renaming columns\ndf_description.rename(columns={'Description': 'Text'}, inplace=True)\ndf_ocr_text.rename(columns={'ocr_text': 'Text'}, inplace=True)\n\n# Adding 'Text Type' column\ndf_description['Text Type'] = 'Caption'\ndf_ocr_text['Text Type'] = 'OCR'\n\n# Concatenating the dataframes\nnew_df = pd.concat([df_description, df_ocr_text])\n\n# Dropping any rows where 'Text' is NaN or empty\nnew_df.dropna(subset=['Text'], inplace=True)\nnew_df = new_df[new_df['Text'].str.strip() != '']\n\n# Resetting the index\nnew_df.reset_index(drop=True, inplace=True)\nnew_df.head()\n\n\n  \n    \n\n\n\n\n\n\nshortcode\nText\nText Type\n\n\n\n\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\n\n\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\n\n\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\n\n\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\n\n\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption"
  },
  {
    "objectID": "notebooks/2023_12_01_BERTopic.html#extracting-topics",
    "href": "notebooks/2023_12_01_BERTopic.html#extracting-topics",
    "title": "Import CrowdTangle Data",
    "section": "Extracting Topics",
    "text": "Extracting Topics\nAfter fitting our model, we can start by looking at the results. Typically, we look at the most frequent topics first as they best represent the collection of documents.\n\nfreq = topic_model.get_topic_info(); freq.head(5)\n\n\n  \n    \n\n\n\n\n\n\nTopic\nCount\nName\nRepresentation\nRepresentative_Docs\n\n\n\n\n0\n-1\n860\n-1_bayern_csu_uhr_mehr\n[bayern, csu, uhr, mehr, menschen, münchen, te...\n[Wir gehen mit #herzstatthetze in den Wahlkamp...\n\n\n1\n0\n137\n0_wählen_fdp_hessen_heute\n[wählen, fdp, hessen, heute, stimme, stimmen, ...\n[Unser Ministerpräsident @markus.soeder steigt...\n\n\n2\n1\n104\n1_energie_co2_klimaschutz_habeck\n[energie, co2, klimaschutz, habeck, wasserstof...\n[Habeck täuscht Öffentlichkeit mit Zensur: Rüc...\n\n\n3\n2\n103\n2_zuwanderung_migration_grenzpolizei_migration...\n[zuwanderung, migration, grenzpolizei, migrati...\n[Wir sagen Ja zu #Hilfe und #Arbeitsmigration,...\n\n\n4\n3\n89\n3_uhr_starke mitte_bayerns starke_bayerns\n[uhr, starke mitte, bayerns starke, bayerns, b...\n[\"Deutschland-Pakt\" aus Scholz der Krise komme...\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n-1 refers to all outliers and should typically be ignored. Next, let’s take a look at a frequent topic that were generated:\n\nlen(freq)\n\n52\n\n\nWe have a total of 52 topics\n\ntopic_model.get_topic(0)  # Select the most frequent topic\n\n[('wählen', 0.01628736425293884),\n ('fdp', 0.01626632927971954),\n ('hessen', 0.013634118460503969),\n ('heute', 0.013441948777152065),\n ('stimme', 0.011907460231710654),\n ('stimmen', 0.011505832701270827),\n ('landtagswahl', 0.011272934711858047),\n ('wahlkampf', 0.01059385752962746),\n ('sonntag', 0.01057520846171656),\n ('bayern', 0.010322807358750668)]\n\n\n\nVisualize Topics\nAfter having trained our BERTopic model, we can iteratively go through perhaps a hundred topic to get a good understanding of the topics that were extract. However, that takes quite some time and lacks a global representation. Instead, we can visualize the topics that were generated in a way very similar to LDAvis:\n\ntopic_model.visualize_topics()\n\n\n\n\nVisualize Terms\nWe can visualize the selected terms for a few topics by creating bar charts out of the c-TF-IDF scores for each topic representation. Insights can be gained from the relative c-TF-IDF scores between and within topics. Moreover, you can easily compare topic representations to each other.\n\ntopic_model.visualize_barchart(top_n_topics=15)\n\n\n\n\nTopic Reduction\nWe can also reduce the number of topics after having trained a BERTopic model. The advantage of doing so, is that you can decide the number of topics after knowing how many are actually created. It is difficult to predict before training your model how many topics that are in your documents and how many will be extracted. Instead, we can decide afterwards how many topics seems realistic:\n\ntopic_model.reduce_topics(docs, nr_topics=15)\n\n2023-12-01 08:53:07,148 - BERTopic - Topic reduction - Reducing number of topics\n2023-12-01 08:53:07,642 - BERTopic - Topic reduction - Reduced number of topics from 52 to 15\n\n\n&lt;bertopic._bertopic.BERTopic at 0x794041658ca0&gt;\n\n\n\n\nVisualize Terms After Reduction\n\ntopic_model.visualize_barchart(top_n_topics=15)\n\n\n\n\nSaving the model\nThe model and its internal settings can easily be saved. Note that the documents and embeddings will not be saved. However, UMAP and HDBSCAN will be saved.\n\n# Save model\ntopic_model.save(\"/content/drive/MyDrive/2023-12-01-LTW23-CrowdTangle-Posts-model\")\n\n2023-12-01 08:53:54,135 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same."
  },
  {
    "objectID": "notebooks/2023_12_11_GPT_Text_Classification3.html",
    "href": "notebooks/2023_12_11_GPT_Text_Classification3.html",
    "title": "Text Classification",
    "section": "",
    "text": "system_prompt = \"\"\"\nYou are an advanced classifying AI. Your task is to classify the sentiment of a text. Sentiment can be either ‘positive’, ‘negative’, or ‘neutral’.\n**Instructions**\n  1. Examine each row in the table under the 'Text' column.\n  2. For each row consisting of social media comments, classify the content into either ‘negative’, ‘neutral’, or ‘positive’.\n  3. Fill the 'Classification' column for the corresponding 'Text' row with your answer. Your answer MUST be one of [‘negative’, ‘neutral’, ‘positive’], and it should be presented in lowercase.\n**Formatting**\nReturn a markdown table with the columns \"shortcode\" and \"Classification\"\n\"\"\"\n\n\nFrom Documents to Markdown Tables\nWe use the tabulate python package to create markdown tables for as many tables as we manage to send within the model’s context window. Currently, the result_table token length (the mockup response) is calculated using the length of False. Replace the value if you expect longer classifications in this line:\ncurrent_result_table = tabulate(batched_data + [(row[meta], False)], headers=[meta, \"Classification\"], tablefmt=\"pipe\")\n\nfrom tabulate import tabulate\nfrom datetime import datetime\nfrom gpt_cost_estimator import num_tokens_from_messages\n\ndef batch_rows_for_tables(df, system_prompt, column, meta, model=\"gpt-3.5-turbo-0613\", **kwargs):\n    max_rows = kwargs.get(\"max_rows\", 999)\n    if model == \"gpt-4-0613\":\n      max_tokens = 8192\n\n    if model == \"gpt-4-1106-preview\":\n      max_tokens = 128000 # This model has not been tested with the multidocument approach. It is only capable of 4096 tokens output, therefore we might run into trouble\n\n    if model == \"gpt-3.5-turbo-0613\":\n      max_tokens = 4096\n\n    \"\"\"Batch rows from the dataframe to fit within token limits and return as a list of markdown tables.\"\"\"\n    tables = []\n\n    df[column] = df[column].astype(str)\n\n    pbar = tqdm(total=len(df))\n\n\n    while not df.empty:\n        current_tokens = 0\n        batched_data = []\n        batched_results = []\n\n        i = 0\n        for index, row in df.iterrows():\n            # Remove newline characters from the specific column\n            cleaned_data = row[column].replace('\\n', ' ')\n\n            # Construct the table for the current batch\n            current_table = tabulate(batched_data + [(row[meta], cleaned_data)], headers=[meta, \"Text\"], tablefmt=\"pipe\")\n            current_result_table = tabulate(batched_data + [(row[meta], False)], headers=[meta, \"Classification\"], tablefmt=\"pipe\")\n\n            message = [\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": current_table},\n                {\"role\": \"assistant\", \"content\": current_result_table}\n                ]\n\n            tokens_needed = num_tokens_from_messages(message, model=model)\n\n            if tokens_needed &lt;= max_tokens and i &lt; max_rows:\n                current_tokens = tokens_needed\n                batched_data.append((row[meta], cleaned_data))\n                batched_results.append((row[meta], False))\n                df.drop(index, inplace=True)\n                i += 1\n            else:\n                # Stop when you've reached close to the max token count\n                pbar.update(len(batched_data))\n                break\n\n        # Convert batched rows to a markdown table and store in tables list\n        markdown_table = tabulate(batched_data, headers=[meta, \"Text\"], tablefmt=\"pipe\")\n        tables.append(markdown_table)\n\n    pbar.close()\n\n    return tables\n\nThe next command uses the above function to generate all necessary markdown tables. The column parameter of batch_rows_for_tables expects the name of the text column, the meta parameter expects the name of the identifier column. Additionally, we pass the dataframe, system_prompt, and MODEL to the function. Fill in the TEXT_COLUMN, IDENTIFIER, MODEL, and MAX_ROWS variables as needed. See the comments above each variable for more information.\n\n#@markdown What's the column name of the text column?\nTEXT_COLUMN = 'Text' # @param {type: \"string\"}\n#@markdown What's the column name of the text column?\nIDENTIFIER = 'shortcode' # @param {type: \"string\"}\n#@markdown Which model do you want to use?\nMODEL = \"gpt-4-0613\" # @param [\"gpt-3.5-turbo-0613\", \"gpt-4-1106-preview\", \"gpt-4-0613\"] {allow-input: true}\n#@markdown Is there a maximum length of rows? (**Set a very high number, like 999, to disable this feature**)\nMAX_ROWS = 999 # @param {type: \"number\", min:0}\n\n# Create a copy of your df. This is important! The batching process removes processed rows from the df.\ndf_batch_copy = df.copy()\n\n# Batching the tables, takes a few seconds (~1 Minute)\ntables = batch_rows_for_tables(df_batch_copy, system_prompt, TEXT_COLUMN, IDENTIFIER, MODEL, max_rows=MAX_ROWS)\n\n\n\n\nLet’s inspect the table. This is one of many tables that will be sent to the model. (I set the MAX_ROWS to 5 to keep the example short. When working with this approach I usually use MAX_ROWS=999.)\n\nprint(tables[0])\n\n| shortcode   | Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n|:------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| CyMAe_tufcR | #Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Danke #Landtagswahl                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n| CyL975vouHU | Die Landtagswahl war für uns als Liberale hart. Wir haben alles gegeben, um die FDP wieder in den Landtag zu bringen, aber leider hat es nicht gereicht. Danke für euren Einsatz, egal ob beim Plakatieren, Flyern oder am Infostand. 💛  Wir Julis stehen für unsere Überzeugungen ein, auch wenn es gerade nicht gut läuft. Das macht uns aus! Das haben wir in diesem Wahlkampf gezeigt und das werden wir auch in der außerparlamentarischen Opposition zeigen. 💪  Du bist auch davon überzeugt, dass Freiheit und Eigenverantwortung eine Stimme in der Politik brauchen? Dann steh auch du jetzt für diese Überzeugung ein. Unter www.julis.de/mitglied-werden/ kannst du noch heute Mitglied der besten Jugendorganisation der Welt werden. 🚀  #freistart23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n| CyL8GWWJmci | Nach einem starken Wahlkampf ein verdientes Ergebnis! 💪 Herzlichen Glückwunsch an die CSU und unsere bayrischen JUler, die in der nächsten Legislaturperiode für ein sicheres und stabiles Bayern arbeiten werden. Wir wünschen euch viel Erfolg und alles Gute für das Landtagsmandat (v.l.n.r.): Manuel Knoll, Konrad Baur, Daniel Artmann, Kristan von Waldenfels.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| CyL7wyJtTV5 | So viele Menschen am Odeonsplatz heute mit einer klaren Botschaft: Wir stehen an der Seite Israels.   Die massiven und brutalen Angriffe der Terrororganisation Hamas sind abscheuliche Verbrechen an unschuldigen Männern, Frauen und Kindern. Die Bilder und Videos der barbarischen Morde zerreißen einem das Herz.   Der Terror der Hamas ist durch nichts zu rechtfertigen und muss sofort gestoppt werden. Israel hat ein völkerrechtlich verbrieftes Recht auf Selbstverteidigung.  Wir Gedenken den Toten. Wir trauern mit den Familien und Angehörigen. Und wir bangen und hoffen mit den verschleppten Israelis.   Es ist gut, dass die Bundesregierung die Entwicklungshilfe für die palestinensischen Gebiete eingefroren hat. Das ist richtig.   Nicht richtig ist, dass Menschen in Deutschland die Angriffe der Hamas auf Jüdinnen und Juden feiern. Das ist mit nichts zu rechtfertigen und wir verurteilen es aufs schärfste.   Wir hier in Deutschland und Bayern haben noch viel zu tun: Antisemitismus und auch israelbezogener Antisemitismus ist in der Mitte unserer Gesellschaft vorhanden. Es ist die Aufgabe des frisch gewählten Bayerischen Landtags noch mehr gegen Judenhass zu tun.   📸 @andreasgregor   #standwithisrael #israel #münchen #bayern |\n| CyLxwHuvR4Y | Herzlichen Glückwunsch zu diesem grandiosen Wahlsieg!  Mit allen 12 JU-Direktkandidaten seid ihr in den hessischen Landtag gezogen 🎉 Wir gratulieren euch und wünschen euch viel Erfolg für den Start und die nächsten fünf Jahre im Parlament (v.l.n.r.): Kim-Sarah Speer, Frederik Bouffier, Sebastian Sommer, Lucas Schmitz, Sebastian Müller, Christin Ziegler, Marie-Sophie Künkel, Maximilian Schimmel, Christoph Mikuschek, Patrick Appel, Maximilian Bathon und Dominik Leyh!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n\n\nWe can also inspect them using Markdown formatting in the notebooks:\n\nfrom IPython.display import Markdown, display\n\ndisplay(Markdown(tables[0]))\n\n\n\n\n\n\n\n\nshortcode\nText\n\n\n\n\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Danke #Landtagswahl\n\n\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart. Wir haben alles gegeben, um die FDP wieder in den Landtag zu bringen, aber leider hat es nicht gereicht. Danke für euren Einsatz, egal ob beim Plakatieren, Flyern oder am Infostand. 💛 Wir Julis stehen für unsere Überzeugungen ein, auch wenn es gerade nicht gut läuft. Das macht uns aus! Das haben wir in diesem Wahlkampf gezeigt und das werden wir auch in der außerparlamentarischen Opposition zeigen. 💪 Du bist auch davon überzeugt, dass Freiheit und Eigenverantwortung eine Stimme in der Politik brauchen? Dann steh auch du jetzt für diese Überzeugung ein. Unter www.julis.de/mitglied-werden/ kannst du noch heute Mitglied der besten Jugendorganisation der Welt werden. 🚀 #freistart23\n\n\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Ergebnis! 💪 Herzlichen Glückwunsch an die CSU und unsere bayrischen JUler, die in der nächsten Legislaturperiode für ein sicheres und stabiles Bayern arbeiten werden. Wir wünschen euch viel Erfolg und alles Gute für das Landtagsmandat (v.l.n.r.): Manuel Knoll, Konrad Baur, Daniel Artmann, Kristan von Waldenfels.\n\n\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit einer klaren Botschaft: Wir stehen an der Seite Israels. Die massiven und brutalen Angriffe der Terrororganisation Hamas sind abscheuliche Verbrechen an unschuldigen Männern, Frauen und Kindern. Die Bilder und Videos der barbarischen Morde zerreißen einem das Herz. Der Terror der Hamas ist durch nichts zu rechtfertigen und muss sofort gestoppt werden. Israel hat ein völkerrechtlich verbrieftes Recht auf Selbstverteidigung. Wir Gedenken den Toten. Wir trauern mit den Familien und Angehörigen. Und wir bangen und hoffen mit den verschleppten Israelis. Es ist gut, dass die Bundesregierung die Entwicklungshilfe für die palestinensischen Gebiete eingefroren hat. Das ist richtig. Nicht richtig ist, dass Menschen in Deutschland die Angriffe der Hamas auf Jüdinnen und Juden feiern. Das ist mit nichts zu rechtfertigen und wir verurteilen es aufs schärfste. Wir hier in Deutschland und Bayern haben noch viel zu tun: Antisemitismus und auch israelbezogener Antisemitismus ist in der Mitte unserer Gesellschaft vorhanden. Es ist die Aufgabe des frisch gewählten Bayerischen Landtags noch mehr gegen Judenhass zu tun. 📸 @andreasgregor #standwithisrael #israel #münchen #bayern\n\n\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wahlsieg! Mit allen 12 JU-Direktkandidaten seid ihr in den hessischen Landtag gezogen 🎉 Wir gratulieren euch und wünschen euch viel Erfolg für den Start und die nächsten fünf Jahre im Parlament (v.l.n.r.): Kim-Sarah Speer, Frederik Bouffier, Sebastian Sommer, Lucas Schmitz, Sebastian Müller, Christin Ziegler, Marie-Sophie Künkel, Maximilian Schimmel, Christoph Mikuschek, Patrick Appel, Maximilian Bathon und Dominik Leyh!\n\n\n\n\n\n\n\nRun the Multidocument Request\nhe following code snippet uses my gpt-cost-estimator package to simulate API requests and calculate a cost estimate. Please run the estimation whne possible to asses the price-tag before sending requests to OpenAI!\nFill in the MOCK, RESET_COST, SAMPLE_SIZE, CLASS_NAME, and FILE_NAME variables as needed (see comments above each variable.)\n\nfrom tqdm.auto import tqdm\nimport json\nimport ast\nfrom datetime import datetime\nfrom io import StringIO\n\n#@title Run the Multidocument Request\n#@markdown T\n#@markdown Do you want to mock the OpenAI request (dry run) to calculate the estimated price?\nMOCK = False # @param {type: \"boolean\"}\n#@markdown Do you want to reset the cost estimation when running the query?\nRESET_COST = True # @param {type: \"boolean\"}\n\n#@markdown How many **tables** do you want to send? Enter $0$ for all.\nSAMPLE_SIZE = 1 # @param {type: \"number\", min: 0}\n\n#@markdown Filename for the **new** table that only contains sentiments.\nFILE_NAME = '/content/drive/MyDrive/2023-12-08-Posts-LTW-Sentiment' # @param {type: \"string\"}\n\n#@markdown Name for the classification column\nCLASS_NAME = 'Sentiment' # @param {type: \"string\"}\n\n\ndef safe_literal_eval(value):\n    if isinstance(value, (str, bytes)):\n        try:\n            return ast.literal_eval(value)\n        except ValueError:\n            return value  # or handle the error in another way if you want\n    return value\n\ndef parse_response(response):\n    # Determine if the response is a list or markdown table\n    if ':' in response.split('\\n')[0]:\n        # List\n        lines = [line.strip() for line in response.strip().split('\\n')]\n        data = [(int(line.split(': ')[0]), line.split(': ')[1]) for line in lines]\n        # Convert the parsed data into a DataFrame\n        result_df = pd.DataFrame(data, columns=['uuid', 'Positioning'])\n    else:\n        # Markdown Table\n        csv_data = '\\n'.join([','.join(line.split('|')[1:-1]) for line in response.split('\\n') if line.strip() and not line.startswith('|:')])\n        result_df = pd.read_csv(StringIO(csv_data.strip()), sep=\",\", skipinitialspace=True)\n\n\n    # Striping Whitespaces\n    result_df.columns = [col.strip() for col in result_df.columns]\n    if 'Classification' in result_df.columns:\n        # Renaming the column to fit the rest of the project.\n        result_df = result_df.rename(columns={\"Classification\": CLASS_NAME})\n\n    result_df = result_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n\n    return result_df\n\n\ntry:\n    # Attempt to read the CSV file into a DataFrame\n    new_df = pd.read_csv(FILE_NAME)\nexcept FileNotFoundError:\n    # If the file is not found, create an empty DataFrame with the specified columns\n    new_df = pd.DataFrame(columns=[IDENTIFIER, CLASS_NAME])\n\n# Reset Estimates\nCostEstimator.reset()\nprint(\"Reset Cost Estimation\")\n\nif 0 &lt; SAMPLE_SIZE &lt;= len(tables):\n    filtered_tables = tables[:SAMPLE_SIZE]\nelse:\n    filtered_tables = tables\n\nfor table in tqdm(filtered_tables):\n    result = run_request(system_prompt, table, MODEL, MOCK)\n    if result and not MOCK:\n      # Parsing the data\n      result_df = parse_response(result.choices[0].message.content)\n\n      # Append it to master_df\n      new_df = pd.concat([new_df, result_df], ignore_index=True)\n\n      # Save Progress\n      new_df.to_csv(FILE_NAME, index=False)\n\nprint()\n\nif not MOCK:\n  print(f\"Saved {FILE_NAME}.\")\n\n  new_df = new_df.dropna(subset=[IDENTIFIER])\n  new_df[CLASS_NAME] = new_df[CLASS_NAME].apply(safe_literal_eval)\n  uuid_to_classification = new_df.set_index(IDENTIFIER)[CLASS_NAME].to_dict()\n  mask = df[IDENTIFIER].isin(uuid_to_classification.keys())\n  df.loc[mask, CLASS_NAME] = df.loc[mask, IDENTIFIER].replace(uuid_to_classification)\n\nprint()\n\nReset Cost Estimation\nCost: $0.1408 | Total: $0.1408\nSaved /content/drive/MyDrive/2023-12-08-Posts-LTW-Sentiment.\n\n\n\n\n\n\n\nnew_df.head()\n\n\n  \n    \n\n\n\n\n\n\nshortcode\nSentiment\n\n\n\n\n0\nCyMAe_tufcR\npositive\n\n\n1\nCyL975vouHU\nneutral\n\n\n2\nCyL8GWWJmci\npositive\n\n\n3\nCyL7wyJtTV5\nnegative\n\n\n4\nCyLxwHuvR4Y\npositive\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\nThe code above expects the GPT-API to return results in a markdown formatted table (see above). We keep appending the API responses to a new_df where we temporarily store the classifications. For each loop (i.e. each time received a classification), we store the results on Google Drive as a backup, since each result has a price tag. In case of error we can resume the operation later without the need to start all over again. The code above does not provide the necessary logic for that, but you should be able to quickly add it.\nOnce the loop finished, we use the shortcode column from the API response and join the classification data with df:\n\nAnd finally our df looks as follows. As outlined at the start of the text exploration chapter, we want to fill one dataframe piece by piece with more and more classifications.\n\ndf[mask][['shortcode', 'Text', 'Text Type', 'Sentiment']].head()\n\n\n  \n    \n\n\n\n\n\n\nshortcode\nText\nText Type\nSentiment\n\n\n\n\n0\nCyMAe_tufcR\n#Landtagswahl23 🤩🧡🙏 #FREIEWÄHLER #Aiwanger #Da...\nCaption\npositive\n\n\n1\nCyL975vouHU\nDie Landtagswahl war für uns als Liberale hart...\nCaption\nneutral\n\n\n2\nCyL8GWWJmci\nNach einem starken Wahlkampf ein verdientes Er...\nCaption\npositive\n\n\n3\nCyL7wyJtTV5\nSo viele Menschen am Odeonsplatz heute mit ein...\nCaption\nnegative\n\n\n4\nCyLxwHuvR4Y\nHerzlichen Glückwunsch zu diesem grandiosen Wa...\nCaption\npositive"
  }
]