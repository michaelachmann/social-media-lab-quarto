[
  {
    "objectID": "notebooks/ig-instaloader.html",
    "href": "notebooks/ig-instaloader.html",
    "title": "Instagram Posts",
    "section": "",
    "text": "In order to download posts and stories from Instagram, we use the package instaloader. You can install package for python using pip install &lt;package&gt;, the command -q minimizes the output.\n!pip -q install instaloader\n\n     |████████████████████████████████| 60 kB 3.0 MB/s eta 0:00:011\n  Building wheel for instaloader (setup.py) ... done\nOnce you install instaloader we log in using your username and password. Session information (not your credentials!) is stored in Google Drive to minimize the need for signing in.\nIn order to minimize the risk for your account to be disabled we suggest creating a new account on your phone before proceeding!\nusername = 'your.username'\n\n# We save the sessionfile to the following directory. Default is the new folder `.instaloader` in your google drive. (This is optional)\nsession_directory = '/content/drive/MyDrive/.instaloader/'\n\nimport instaloader\nfrom os.path import exists\nfrom pathlib import Path\n\n# Creating session directory, if it does not exists yet\nPath(session_directory).mkdir(parents=True, exist_ok=True)\n\nfilename = \"{}session-{}\".format(session_directory, username)\nsessionfile = Path(filename)\n\n\n# Get instance\nL = instaloader.Instaloader(compress_json=False)\n\n# Check if sessionfile exists. If so load session,\n# else login interactively\nif exists(sessionfile):\n  L.load_session_from_file(username, sessionfile)\n\nelse:\n  L.interactive_login(username)\n  L.save_session_to_file(sessionfile)\n\nLoaded session from /content/drive/MyDrive/.instaloader/session-mi_sm_lab05."
  },
  {
    "objectID": "notebooks/ig-instaloader.html#downloading-first-posts",
    "href": "notebooks/ig-instaloader.html#downloading-first-posts",
    "title": "Instagram Posts",
    "section": "Downloading first Posts",
    "text": "Downloading first Posts\nNext, we try to download all posts of a profile. Provide a username and folder:\n\ndest_username = 'some.profile' \ndest_dir = '/content/drive/MyDrive/insta-posts/' # Once more we save the files to Google Drive. Replace this with a local directory if necessary.\n\nt = Path(\"{}{}\".format(dest_dir, dest_username))\nt.mkdir(parents=True, exist_ok=True)\n\nprofile = instaloader.Profile.from_username(L.context, dest_username)\nfor post in profile.get_posts():\n    L.download_post(post, target=t)\n\nWell, you just downloaded your first posts! Open Google Drive and check the folder insta-posts/ (or whatever folder you chose above)! There should be three files for each post, the image, a .json file and a .txt file. The .txt includes the image caption, the .json lots of metadata about the post.\n\nDiving into the metadata\nThe next cell reads all .json files of the downloaded posts. Then we browse through some interesting data.\n\n# Reading the paths of all JSON files from dest_dir\nimport os\n\njson_files = []\n\nfor subdir, dirs, files in os.walk(t):\n    for file in files:\n        fullpath = os.path.join(subdir, file)\n        filename, file_extension = os.path.splitext(fullpath)\n        if file_extension == \".json\":\n          json_files.append(fullpath)\n\n\n# Reading all JSON files\nfrom tqdm.notebook import tqdm\nimport json\n\njson_data = []\n\nfor file in tqdm(json_files):\n  with open(file, 'r') as f:\n    data = json.load(f)\n    json_data.append(data)\n\n\n\n\nOk, now all metadata for all posts is saved to the variable json_data. Run the next line and copy its output to http://jsonviewer.stack.hu/. Your output should look similar, go ahead and play around to explore your data! What information can you extract?\n\nprint(json.dumps(json_data[0]))\n\n\n\nMetadata Preprocessing\nPosts contain plenty of data, like time and location of the post, the authoring user, a caption, tagged users and more. The following cells demonstrate how to normalize the data into a table format, which is useful when working with pandas. Nevertheless, this is optional!\n\n# Use booleans (True / False) values to select what type of data you'd like to analyse. \nusername = True #@param {type:\"boolean\"}\ntimestamp = True #@param {type:\"boolean\"}\ncaption = True #@param {type:\"boolean\"}\nlocation = True #@param {type:\"boolean\"}\nshortcode = True #@param {type:\"boolean\"}\nid = True #@param {type:\"boolean\"}\ntagged_users = True #@param {type:\"boolean\"}\n\nNext we loop through the data and create a new pandas DataFrame. The DataFrame will have one column for each variable selected above and one row for each downloaded posts.\nIf you are not yet familiar with the concept of dataframes have a look at YouTube, there’s plenty of introductory videos available.\n\nimport pandas as pd\n\nposts = []  # Initializing an empty list for all posts\nfor post in tqdm(json_data):\n  row = {} # Initializing an empty row for the post\n\n  node = post.get(\"node\")\n\n  if username:\n    owner = node.get(\"owner\")\n    row['username'] = owner.get(\"username\")\n\n  if timestamp:\n    row['timestamp'] = node.get(\"taken_at_timestamp\")\n\n  if location:\n    l = node.get(\"location\", None)\n    if l:\n      row['location'] = l.get(\"name\")\n\n  if shortcode:\n    row['shortcode'] = node.get(\"shortcode\")\n\n  if id:\n    row['id'] = node.get(\"id\")\n  \n  if tagged_users:\n    pass\n\n  if caption:\n    c = \"\"\n    emtc = node.get(\"edge_media_to_caption\")\n    edges = emtc.get(\"edges\")\n    for element in edges:\n      caption_node = element.get(\"node\")\n      c = c + caption_node.get(\"text\")\n    row['caption'] = c\n\n  # Finally add row to posts\n  posts.append(row)\n\n# After looping through all posts create data frame from list\nposts_df = pd.DataFrame.from_dict(posts)\n\nNow all information selected above is saved to the dataframe posts_df. Run the next cell and it will return a nicely formatted table. If your data is quite long, output will be cropped. Click the wand and after a few seconds you are able to browse through the data or filter by columns\n\nposts_df\n\nIn order to get a first impression of dataframes, the head() method is also useful. Run the next cell to see the result\n\nposts_df.head()\n\nThe dataframe is only saved in memory, thus when disconnecting and deleting the runtime, the dataframe is lost. Running the next cell saves the table to a CSV-file on your drive.\nNow the processed data may be recovered or used in another notebook.\n\nposts_df.to_csv('{}{}.csv'.format(dest_dir, username))"
  },
  {
    "objectID": "getting-started/theory.html",
    "href": "getting-started/theory.html",
    "title": "Introduction to SMA",
    "section": "",
    "text": "Social Media Analyses (SMA) are used both, in academia and in professional settings. Depending on the research agenda, different methodologies may be applied (Kanthawala et al. 2022; Rejeb et al. 2022). In our course, we focus on the academic exploration of Social Media. We place particular emphasis on questions related to media, politics, and society. This represents a confluence of communication science and political science, intertwined with computational methods."
  },
  {
    "objectID": "getting-started/theory.html#social-media-analyses-in-different-contexts",
    "href": "getting-started/theory.html#social-media-analyses-in-different-contexts",
    "title": "Introduction to SMA",
    "section": "Social Media Analyses in different contexts",
    "text": "Social Media Analyses in different contexts\nBridging this discussion, there are several disciplines pivotal to the academic analysis of social media data at this intersection: Lazer et al. (2009) outlined in an influencial article computational social science as an emerging field that built on the ability to collect and analyze vast amounts of data. The goal of the computational social science, according to this article, is to reveal patterns in human interactions, benefiting from various data sources such as emails, phone records, online social networks, and other digital traces left by individuals. We are going to concentrate on social media data, a type of data described by Quan-Haase and Sloan (2022a) as incidental, since the data exists and is being created, no matter the researchers observing them – or not. One special type of data, Instagram stories, even have an ephemeral character. 24 hours after posting the story expires – becoming invisible for followers and researchers alike (see also Leaver, Highfield, and Abidin 2020 on the importance of stories). Atteveldt and Peng (2018) noted a surge in the use of computational methods in communication science, attributing it to three primary factors: the availability of digital data, sophisticated data analysis tools, and the emergence of cost-effective, potent processing capabilities complemented by accessible computing infrastructure. Building on this perspective, Haim (2023) sees the computational communication science as a sub-discipline of communication science that addresses digitally altered objects of research, which require computational approaches to tackle to amount and complexity of this special type of data.\nIn the realm of digital humanities, computational approaches to text analysis have a long history, influenced by concepts such as distant reading (Moretti 2000) and macroanalysis (Jockers 2013). Manovich picks up these concepts in his cultural analytics, see below. Lately also distant viewing has been outlined, as “a methodological and theoretical framework for the study of large collections of visual materials” (Arnold and Tilton 2019). I see potential in integrating approaches and methods from the digital humanities into social media analysis. Vice versa, there’s also potential in utilizing methods used for social media analysis to address questions in the humanities.\nChallanges for social media analyses have been outlined by Quan-Haase and Sloan (2022a): the role of theory, representativeness of data, scale, multimodality, data accessability, and legal and ethical considerations. Through our semester we are going to work on several of those challanges: In the Operationalization session we are going to talk about data-driven approaches (bearing in mind Anderson et al. 2008), as well as theories as basis for your research questions and operationalizations. The representativeness of data will be the challenge for our data collection sessions: We will not just answer how to collect data, but also what data to collect. The two challenges left are at the centre of our seminar: Our answer for the challenge of scale is to apply computational methods for data analysis, to process data at scale. Multimodality is another key issues of this seminar: We want to computationally process visual (or multimodal) data. We will talk about accessability problems throughout our data collection classes, and talk about legal and ethical issues on this page.\nKeeping these introductory considerations in mind, we immerse into a short outline of two theories: Cultural Analytics and Digital Methods, as foundational elements for social media research. Subsequently, we’ll address the ethical and legal challenges associated with analyzing social media. We’ll conclude the chapter by presenting an array of methodologies. In the related work chapter, you’ll find an overview of research on Instagram and TikTok content, even extending beyond our primary topics of interest.\n\n\n\n\n\n\nNote\n\n\n\nThe intent of this article is to provide a brief introduction to the field of computational social media analysis, tailored for my Winter 2023/24 seminar. It offers only a cursory glance at various theories and methodologies. As such, please do not regard the content of this page as a definitive scientific piece. Instead, view it as a compass to guide and inspire your own research endeavors."
  },
  {
    "objectID": "getting-started/theory.html#cultural-analytics",
    "href": "getting-started/theory.html#cultural-analytics",
    "title": "Introduction to SMA",
    "section": "Cultural Analytics",
    "text": "Cultural Analytics\nCultural analytics, as explained in the introductory chapter of the book “Cultural Analytics” by Lev Manovich, is a field that uses computers to analyze and understand large amounts of cultural information or “big cultural data”. This might include exploring big collections of images, videos, or other media data to see patterns and trends that are happening in digital culture. Manovich talks about some key questions and challenges in cultural analytics. For example, one big question is whether we should focus on finding common themes and patterns in our data, or whether we should pay more attention to things that are unusual or rare. Also, while cultural analytics can be a powerful tool for understanding aspects of culture, especially in the digital world, Manovich tells us to be aware of its limits. He says that computers and data analysis can tell us a lot, but they can’t understand culture in the rich and deep way that humans can, especially when it comes to understanding things like aesthetics (beauty, style, etc.). So, while cultural analytics can help us see large scale patterns and trends in culture, Manovich advises us to also appreciate and be aware of what it can’t see or understand. The field of cultural analytics then becomes a space where we use computational tools to explore and question culture, while also being mindful of the limitations and challenges of using these tools (Manovich 2020)."
  },
  {
    "objectID": "getting-started/theory.html#digital-methods",
    "href": "getting-started/theory.html#digital-methods",
    "title": "Introduction to SMA",
    "section": "Digital Methods",
    "text": "Digital Methods\n“Digital Methods,” as introduced by Rogers (2013), proposes a paradigm wherein the internet is both a site and a source for research, especially for social media studies. Unlike conventional research approaches that see the internet merely as a tool or data source, Rogers advocates for a methodology that is intrinsically web-centric, understanding and employing the unique dynamics and mechanics of the digital medium itself. And example for a digital methods research project is understanding algorithmic operations, especially of search engines like Google, and comprehending their impact on digital culture, information accessibility, and user engagement. This perspective is important to explore the foundations of how information is organized, ranked, and accessed online. Studying the digital medium itself means to study web-native phenomena such as hyperlink networks, search engine behaviors, and social media activities to uncover patterns, tendencies, and hierarchical structures within digital cultures and societies.\nThe concepts of cultural analytics and digital methods will guide us through our semester and our projects: We borrow the idea to use computational methods in order to understand “big cultural data” form Manovich and the concept of studying the digital medium itself from Rogers. Throughout the semester will enrich our projects with more focused literature and theory based on the research interests. Beyond these foundations, we will borrow from i.e. the Computational Social Sciences (Lazer et al. 2009), the concept of Distant Viewing (Arnold and Tilton 2019), or Grammars of Action (Agre 1994; Gerlitz and Rieder 2018; Bainotti, Caliandro, and Gandini 2020; Omena, Rabello, and Mintz 2020), and Platform Vernaculars (Gibbs et al. 2015)."
  },
  {
    "objectID": "getting-started/theory.html#legal-ethical-challenges",
    "href": "getting-started/theory.html#legal-ethical-challenges",
    "title": "Introduction to SMA",
    "section": "Legal & Ethical Challenges",
    "text": "Legal & Ethical Challenges\n\n\n\n\n\n\nWarning\n\n\n\nThis subchapter scratches the surface. Recommended reading: Haim (2023) pp. 62–69; 126–128.\n\n\nWhen working with social media data we’re dealing with personal information. As such we need to take into account legal and ethical considerations. From the legal perspective we need to focus on two aspects: The ownership of the data, and – when dealing with personal data – the GDPR. For the latter we need to take into account consent and should think about pseudonymisation or anonymisation of our data (Haim 2023). Further, the German Urheberrecht, the equivalent of the anglo-saxon copyright law (there are important differences, see Bundeszentrale für politische Bildung for a synopsis), defines exceptions for scientific research: I recommend the publication by Rat für Sozial- und Wirtschaftsdaten (RatSWD) (2019) which takes a closer look at the database law and provides some practical guidance (more in our slides).\nThe importance of the legal perspective social media research grew recently: Following the Cambridge Analytica scandal Meta platforms (like Instagram) started closing down on APIs, which would have offered a legal and accepted (by the plattform) point of access for researchers. I recommend to read McCrow-Young’s (2021) article as she demonstrates how academic research may be interrupted by platform changes, like the closure of the Instagram-API in the wake of above incident. Post-API social media research found creative ways to access the data: Bainotti, Caliandro, and Gandini (2020), for example, took a unique approach for data collection by capturing Instagram content through YouTube videos. Recent publications on Instagram analyses, and most approaches in our future session, rely on crawling and scraping. Venturini and Rogers (2019) see a chance in the API-closure and argue that these techniques are “more than a ‘necessary evil’”, as it might force researchers to come back to (digital) field work.\nFinally a word about reserach ethics. While the GDPR provides a rigid legal framework for dealing with personal information, I’d like to recommend the article “But the Data is Already Public” by Zimmer (2010). The article documents how, in a matter of days, an anonymous dataset of 1700 facebook profiles became (partly) deanonymized. Based on this case study, the author compiles ethical concerns for future research, which we should also incorporate into our work."
  },
  {
    "objectID": "getting-started/theory.html#methodology",
    "href": "getting-started/theory.html#methodology",
    "title": "Introduction to SMA",
    "section": "Methodology",
    "text": "Methodology\nIn this chapter we are going to take a look at different methods for use with social media reserach, and particularily, with our projects. We are going to use (Visual) Content Analysis to understand the content of posts and stories. The concept of Plattform Affordances will help us understand these posts and stories as embedded in the platform and its available functions and options. Finally, the idea of Platform Vernaculars & Grammars will help us to wire everything up, to discover patterns and trends in how users communicate and engage on these platforms.\n\n(Visual) Content Analysis\nWe are going to apply quantitative content analyses to our corpora. For a quantitative approach we are going to operationalize our theory-based interests and questions using formal and / or content features. Next, we need to apply the operationalization to the documents, in form of human annotations or computational coding (see Döring and Bortz 2016). Döring and Bortz (2016) outline a general approach to content analysis, Rose (2016) in contrast concentrates on visual content analyses. She suggests four steps:\n\n\n“Finding your Images.\nDevising your categories for coding.\nCoding the images.\nAnalysing the results.” – (Rose 2016 ch. 5)\n\n\nThe challenge of the first step is the sampling: Even with computational approaches, is it feasible to collect everything? The cultural analytics approach suggests such a goal, e.g. in order to obtain data and traces of subcultures. Due to practical limitations also Manovich’s works use an approach to break the large amount of available data into a smaller portion (see Hochman and Manovich 2013). This approach is called sampling, Rose (2016) introduces several sampling approaches like random, stratified, systematic, or cluster sampling. Döring and Bortz (2016) provide a deeper look into sampling strategies.\nThe codes, for the second step, may be devised from a qualitative exploration of the data or theories and related work. On coding there exists another large body of literature, like the Grounded Theory Ergänze Zizazion and Ethnic Coding Approach Zitation. In context of our projects we are going to use both approaches: We will annotate a subset of our data as ground-truth while coding the total data using computational approaches.\nFor the final analysis we are going to apply statistical data analyses. For an initial understanding of our data we will start with some exploratory analyses, e.g. plotting the data. In combination with the two approaches below, the platform affordances and platform vernaculars & grammars we may discover patterns of social media use. In most cases, our projects will compare different groups: These groups might be different user types (e.g. Politician Accounts vs. Party Accounts), or different Posts types (e.g. Posts vs. Stories), or different platforms (e.g. Instagram vs. TikTok).\n\n\nPlatform Affordances\nBossetta (2018) provides an overview of the concept of affordances and their application in social media analyses. He traces the term back to boyd and Papacharissi & Yuan who argued “that digital communication tech- nologies provide structural affordances to agents” (p. 473 Bossetta 2018). There are two important take-aways from his work: 1) The concept of affordances is not used consistently, and 2) the platforms shape affordances and thereby how users interact with the platform. Bainotti, Caliandro, and Gandini (2020) used the “Instagram-specific digital objects” as codes for their analysis of stories, linking the concept of affordances in the context of Instagram to the use of stickers.\nIn the context of our seminar we might consider the following elements as platform affordances:\n\n\n\nTikTok\nIG – Posts\nIG – Stories\n\n\n\n\nLikes\nLikes\nSliders\n\n\nComments\nComments\nVotes\n\n\nShares\nViews\nQuestions\n\n\nMusic\nMentions\nMentions\n\n\nHashtags\nHashtags\nHashtags\n\n\n…\n…\nLocations\n\n\n\n\n…\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDid you spot the difference between some of the listed affordances? Likes and comments, for instance, are reactions to posts. Would you consider these features as affordances? Let’s discuss this is in class!\n\n\n\n\nPlatform Vernaculars & Grammars\nPrevious studies have looked into ‘grammars’ in Instagram stories. Originally linked to privacy (Agre 1994), grammars classify activities using specific types, making data collection and analysis easier. This helps reveal user behavior patterns, useful for things like advertising. This concept was first used (according to my knowledge) for social media data by Gerlitz and Rieder (2018) in a Twitter study.\nOmena, Rabello, and Mintz (2020) discussed a “grammar of hashtags”, referring to the rules of hashtag use and how they’re organized on platforms. They suggest that hashtags, content visibility, and the nature of the content itself are essential in understanding hashtag use. Meanwhile, Bainotti, Caliandro, and Gandini (2020) used grammars to understand Instagram Stories, focusing on visual elements and their cultural meanings.\nLastly, Gibbs et al. (2015) examined the unique styles and logics of social media, termed “platform vernaculars”. These are influenced both by platform features and user habits."
  },
  {
    "objectID": "getting-started/theory.html#summary",
    "href": "getting-started/theory.html#summary",
    "title": "Introduction to SMA",
    "section": "Summary",
    "text": "Summary\nIn this chapter we have positioned ourselfes between several disciplines: The computational social science, computational communication science, and digital humanities. In this position, we see social media data as trace data of human and social behaviour. The digitalness of our subject is, however, just one side of the coin: Follwing the theoretical frameworks of Digital Methods and Cultural Analytics, we want to conduct our analyses computationally with the aim to uncover patterns and trends of user behaviour on social media plattforms. Methodologically we can draw from quantitative content analysis, and the concept of platform affordances as features, and apply the concept of platform vernaculars and grammars to make sense of these feautures."
  },
  {
    "objectID": "getting-started/theory.html#additional-resources",
    "href": "getting-started/theory.html#additional-resources",
    "title": "Introduction to SMA",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nConferences\n\nInternational Conference on Social Media & Society\nIC²S² 2022\nICWSM\nAoIR\nWebSci\nInternational Conference on CMC and Social Media Corpora for the Humanities\n\n\n\nJournals\n\nNew Media & Society\nBig Data & Society\n\n\n\nTextbooks\n\nRose (2016): Visual Methodologies: An Introduction to Researching with Visual Materials.\nHaim (2023): Computational Communication Science: Eine Einführung.\nQuan-Haase and Sloan (2022b): The SAGE handbook of social media research methods.\n\n\n\nOnline Resources\n\nRichard Rogers: Social Media Research with Digital Methods (YouTube)\n\n\n\n\n\n\n\nNote\n\n\n\nDo you know of any ressources to be added to this list? Drop me a line: michael.achmann@ur.de.\n\n\n\n\n\nReferences\n\n\nAgre, Philip E. 1994. “Surveillance and capture: Two models of privacy.” The Information Society 10 (2): 101–27. https://doi.org/10.1080/01972243.1994.9960162.\n\n\nAnderson, Chris, Medea Giordano, Matt Jancer, Philip Ball, Will Knight, Sassafras Lowrey, and Laurence Scott. 2008. “The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.” Wired, June. https://www.wired.com/2008/06/pb-theory/.\n\n\nArnold, Taylor, and Lauren Tilton. 2019. “Distant viewing: analyzing large visual corpora.” Digital Scholarship in the Humanities 34 (Supplement_1): i3–16. https://doi.org/10.1093/llc/fqz013.\n\n\nAtteveldt, Wouter van, and Tai-Quan Peng. 2018. “When Communication Meets Computation: Opportunities, Challenges, and Pitfalls in Computational Communication Science.” Communication Methods and Measures 12 (2-3): 81–92. https://doi.org/10.1080/19312458.2018.1458084.\n\n\nBainotti, Lucia, Alessandro Caliandro, and Alessandro Gandini. 2020. “From archive cultures to ephemeral content, and back: Studying Instagram Stories with digital methods.” New Media & Society, September, 1461444820960071. https://doi.org/10.1177/1461444820960071.\n\n\nBossetta, Michael. 2018. “The Digital Architectures of Social Media: Comparing Political Campaigning on Facebook, Twitter, Instagram, and Snapchat in the 2016 U.S. Election.” Journalism & Mass Communication Quarterly 95 (2): 471–96. https://doi.org/10.1177/1077699018763307.\n\n\nDöring, Nicola, and Jürgen Bortz. 2016. Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-642-41089-5.\n\n\nGerlitz, and Rieder. 2018. “Tweets are not created equal: Investigating Twitter’s client ecosystem.” International Journal of Communication Systems, no. 12: 528–47. https://pure.uva.nl/ws/files/23266519/5974_30096_2_PB.pdf.\n\n\nGibbs, Martin, James Meese, Michael Arnold, Bjorn Nansen, and Marcus Carter. 2015. “#Funeral and Instagram: death, social media, and platform vernacular.” Information, Communication and Society 18 (3): 255–68. https://doi.org/10.1080/1369118X.2014.987152.\n\n\nHaim, Mario. 2023. Computational Communication Science: Eine Einführung. Springer Fachmedien Wiesbaden.\n\n\nHochman, Nadav, and Lev Manovich. 2013. “Zooming into an Instagram City: Reading the local through social media.” First Monday, June. https://doi.org/10.5210/fm.v18i7.4711.\n\n\nJockers, Matthew L. 2013. Macroanalysis: Digital Methods and Literary History. University of Illinois Press.\n\n\nKanthawala, Shaheen, Kelley Cotter, Kali Foyle, and J R Decook. 2022. Proceedings of the 55th Hawaii international conference on system sciences. Proceedings of the ... Annual Hawaii International Conference on System Sciences. Annual Hawaii International Conference on System Sciences. Hawaii International Conference on System Sciences. https://doi.org/10.24251/hicss.2022.000.\n\n\nLazer, David, Alex Pentland, Lada Adamic, Sinan Aral, Albert-Laszlo Barabasi, Devon Brewer, Nicholas Christakis, et al. 2009. “Social science. Computational social science.” Science 323 (5915): 721–23. https://doi.org/10.1126/science.1167742.\n\n\nLeaver, Tama, Tim Highfield, and Crystal Abidin. 2020. Instagram: Visual Social Media Cultures. John Wiley & Sons.\n\n\nManovich, Lev. 2020. Cultural Analytics. MIT Press.\n\n\nMcCrow-Young, Ally. 2021. “Approaching Instagram data: reflections on accessing, archiving and anonymising visual social media.” Communication Research and Practice 7 (1): 21–34. https://doi.org/10.1080/22041451.2020.1847820.\n\n\nMoretti, Franco. 2000. “Conjectures on World Literature.” New Left Review II (1): 54–68. https://newleftreview.org/issues/ii1/articles/franco-moretti-conjectures-on-world-literature.\n\n\nOmena, Janna Joceli, Elaine Teixeira Rabello, and André Goes Mintz. 2020. “Digital Methods for Hashtag Engagement Research.” Social Media + Society 6 (3): 2056305120940697. https://doi.org/10.1177/2056305120940697.\n\n\nQuan-Haase, Anabel, and Luke Sloan. 2022a. “Chapter 1: Introduction.” In The SAGE handbook of social media research methods, edited by Anabel Quan-Haase and Luke Sloan, 2nd ed., 1–9. London, England: SAGE Publications. https://doi.org/10.4135/9781529782943.\n\n\n———. 2022b. The SAGE handbook of social media research methods. Edited by Anabel Quan-Haase and Luke Sloan. 2nd ed. London, England: SAGE Publications. https://doi.org/10.4135/9781529782943.\n\n\nRat für Sozial- und Wirtschaftsdaten (RatSWD). 2019. “Big Data in den Sozial-, Verhaltens- und Wirtschaftswissenschaften: Datenzugang und Forschungsdatenmanagement - Mit Gutachten \"Web Scraping in der unabhängigen wissenschaftlichen Forschung\".” RatSWD Output. German Data Forum ( RatSWD). https://doi.org/10.17620/02671.39.\n\n\nRejeb, Abderahman, Karim Rejeb, Alireza Abdollahi, and Horst Treiblmaier. 2022. “The big picture on Instagram research: Insights from a bibliometric analysis.” Telematics and Informatics 73 (September): 101876. https://doi.org/10.1016/j.tele.2022.101876.\n\n\nRogers, Richard. 2013. Digital Methods. MIT Press.\n\n\nRose, Gillian. 2016. Visual Methodologies: An Introduction to Researching with Visual Materials. SAGE Publications.\n\n\nVenturini, Tommaso, and Richard Rogers. 2019. “‘API-Based Research’ or How can Digital Sociology and Journalism Studies Learn from the Facebook and Cambridge Analytica Data Breach.” Digital Journalism 7 (4): 532–40. https://doi.org/10.1080/21670811.2019.1591927.\n\n\nZimmer, Michael. 2010. “\"But the Data is Already Public\": On the Ethics of Research in Facebook.” Ethics and Information Technology 12 (4): 313–25. https://doi.org/10.1007/s10676-010-9227-5."
  },
  {
    "objectID": "getting-started/related-work.html",
    "href": "getting-started/related-work.html",
    "title": "Related Work",
    "section": "",
    "text": "While the two visual platforms Instagram and TikTok, are relatively new, plenty of research has already been published about both platforms. A naive search on google scholar for the term instagram analysis results in 4.180.000 results, for tiktok analysis in 54.800 results. We are going to take a look at current literature review studies, concentrating on Instagram. The goal for this chapter is to identify major research areas in (visual) social media research. Beyond themes, trends, and topics, review studies also offer methodological overviews on how to study social media platforms.\nAdditionally, we will explore tools like Publish or Perish that help in creating one’s own literature review. The Related Work section forms a pivotal foundation for high-quality scientific research, and a successful project report."
  },
  {
    "objectID": "getting-started/related-work.html#literature-reviews",
    "href": "getting-started/related-work.html#literature-reviews",
    "title": "Related Work",
    "section": "Literature Reviews",
    "text": "Literature Reviews\nRejeb et al. (2022) compiled a bibliometric analysis of 2,242 publications collected from the Web of Science1 database. They cover publications dated from 2013–2021 and outline 22 prior review studies, most of them concentrating on a smaller scope. Topics of these reviews include: Health, Psychology, Journalism, Mental Health, Body Image, and Marketing. Overall, their bibliographic study found similar themes in the current research: Some articles analyse the use of Instagram in the context of business, marketing, and travel. Others take a psychological angle and look into personality traits or health issues. They also found scholarly articles on privacy concerns and Instagram. Here’s some research interests they encountered in their review:\n\n\nHow does Instagram affect social and health issues, such as social comparison, eating disorders, addiction, and suicidal ideation?\nHow does Instagram facilitate and transform healthcare?\nWhat are the security and privacy concerns that result from the use of Instagram?\nHow does Instagram inter-relate with other social media platforms, such as Facebook and Twitter?\nWhat are the emerging research trends and frontiers in Instagram research?\n\n\nThey found researchers to use a multitude of methods, including surveys and questionnaires; content analysis to examine user-generated content; experimental designs to test the effects of Instagram use on users’ psychological states and behaviors; and qualitative methods, such as interviews and focus groups, to gain in-depth insights into users’ experiences with Instagram.\nInterestingly the bibliometric study seems to overlook a larger portion of research covering political communication on Instagram. Bast (2021) concentrates on this exact topic, she reviewed 37 studies on Instagram usage by politicians, parties, and governments. 30 studies were concerned with the Instagram use of political actors. They explored different aspects, like the self-presentation of politicians, mobilization and campaign information or whether they used Instagram to talk about political issues or interact with voters. Some of the studies use a comparative approach, e.g. comparing the Instagram activity of multiple actors, others compared the Instagram usage of political actors across different countries, political systems, or election/non-election periods (Bast 2021).\nFrom a methodological point of view the review of visual content analysis for image-based social media by Milanesi and Guercini (2020) is quite interesting: They included 29 articles in their study and explored the platforms, that have been invastigated as well as the approach, whether the analysis was manual or automated. Outstanding at first is the large share of projects that have been classified as using automated approaches. Upon closer inspection, they have also classified the use of qualitative data analysis software like NVivo, as automation. Few projects, however, have already been using deep learning and computer vision based approaches for image analysis. Finally, the paper suggests that a mixed methodology that combines a netnographic approach, a research methodology that adapts ethnographic research techniques to the study of online communities, for textual and visual data collection in online communities and textual and visual content analysis may provide new insights for branding or destination management research. Overall, they argue for a combined analysis of textual and visual data. It should be noted, that their review focuses on literature from marketing research.\nOverall, each of the outlined reviews has a different focus. Taken together, they display a large variety of different fields and questions, which Instagram content helps to answer. We can use these literature reviews in two way: We can identify patterns of how to approach social media content, how to operationalize, what questions to ask, what methods to use, and – looking at the future work sections of the reviews and the reviewed papers, where to pick up! Secondly, the literature review helps us to identify interesting literature for our own related work section and reading."
  },
  {
    "objectID": "getting-started/related-work.html#selected-articles",
    "href": "getting-started/related-work.html#selected-articles",
    "title": "Related Work",
    "section": "Selected Articles",
    "text": "Selected Articles\nThrought the next passages I’d like to introduce few interesting pieces. First, I’ll outline some of the first papers concerned with Instagram content. Thereafter we proceed to take a look at Instagram stories and ephemeral content in social media.\nOne of the first analyses of Instagram content was published in 2013: The article explores how the interfaces of social media platforms like Instagram shape user interactions and the creation and sharing of media. Through computational analysis and visualizations of Instagram content, the authors study social and cultural patterns. They compare visual data from 13 global cities and provide a detailed analysis of photos from Tel Aviv, Israel, showing how such visualizations can offer insights into social, cultural, and political activities in specific locales over time​ (Hochman and Manovich 2013).\n\n\n\nScreenshot of the phototrails website visualizing 50.000 images per city.\n\n\nShortly afterwards, in 2014, one of the most cited studies about Instagram was published. It provides a comprehensive analysis of Instagram photo content and user types, using computer vision techniques and clustering. The authors collected Instagram data using the Instagram API and developed a coding scheme for categorizing the photos. They identified eight popular photo categories and five distinct types of Instagram users in terms of their posted photos. They also found that a user’s audience (number of followers) is independent of their shared photos on Instagram. This study was the first in-depth analysis of content and users on Instagram (Hu, Manikonda, and Kambhampati 2014).\n\nInstagram Stories\nStories, as a special format due to their ephemeral nature, and have often been evaded academic research. The freature has been introducted of Instagram Stories in 2016 Leaver, Highfield, and Abidin (2020). An early analysis of stories is part of a master thesis on Snapchat and Instagram: Through qualitative content analysis, observation and in-depth interviews Amancio (2017) found four narrative elements used by Snapchat and Instagram storytellers to tell their stories and construct a narrative. Looking at Instagram specifically, Bainotti, Caliandro, and Gandini (2020) investigated 292 Stories by private users using an ethnographic coding approach. They claim to have identified specific grammars by matching the content and context-of-use, the two main ones are: “a grammar for documentation and a grammar for interaction”. Other areas of interest for stories were ephemeral journalism Vázquez-Herrero, Direito-Rebollal, and López-Garcı́a (2019) and Female Atheletes’ self-presentation Li et al. (2021). Finally, just recently Towner and Muñoz (2022) published a first analysis of political communication in Instagram Stories, studying the stories published by the two U.S. presidential candidates in the 2020 campaign. The authors took a marketing perspective, and identified several flaws of the campaign: missed opportunities to share user-generated content, and inconsistencies to communication norms of the ephemeral format.\nOverall, stories have been explored by researchers from different domains. The ephemeral character sticks out in a world where the effort for deleting photos may be more expensive than keeping them (Mayer-Schönberger 2011). Thus, I see potential for many different cultural and societal questions to be answered by looking at this type of content, and great potential for using stories in our semester projects. In contrast to most other social media content, stories need to be collected in real time. This is a challenge for research and limits our questions to material that we may collect throughout the seminar.\n\n\nTikTok\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nI have yet concentrated on literature about Instagram. An update for this section will be the outcome of our seminar!\n\n\n\n\nRecommended Reading\n\n\n\n\n\n\n\n\nReference\nTitle\nNote\n\n\n\n\nBainotti, Caliandro, and Gandini (2020)\nFrom archive cultures to ephemeral content, and back: Studying Instagram Stories with digital methods\nThis paper explores Instagram stories and their collection. The authors conduct a content analysis and derive different grammars for private Instagram stories.\n\n\nHaßler, Kümpel, and Keller (2021)\nInstagram and political campaigning in the 2017 German federal election. A quantitative content analysis of German top politicians’ and parliamentary parties’ posts\nA detailed analysis of the 2017 election campaign showcasing theory-driven operationalization and (manual) content analysis.\n\n\nOmena, Rabello, and Mintz (2020)\nDigital Methods for Hashtag Engagement Research\nIntroduction of a multilayer hashtags engagement research framework paired with the concept of grammars of action. Demonstrates an interesting concept of grouping users.\n\n\nRettberg (2018)\nSnapchat: Phatic Communication and Ephemeral Social Media\nOne of the first scholarly articles on ephemeral stories, originally introduced by Snapchat.\n\n\nSánchez-Querubı́n et al. (2023)\nPolitical TikTok: Playful performance, ambivalent critique and event-commentary\nAn interesting blueprint for doing research of political communication on TikTok; take a special look at the coding variables!\n\n\n…\nto be continued!\n…"
  },
  {
    "objectID": "getting-started/related-work.html#writing-the-related-work-section",
    "href": "getting-started/related-work.html#writing-the-related-work-section",
    "title": "Related Work",
    "section": "Writing the Related Work section",
    "text": "Writing the Related Work section\nThe aim of our project paper diverges somewhat from a comprehensive literature review, such as those that commonly serve as the start for dissertations. Nevertheless, the “Related Work” section of your paper is as an important element of your research project. The goal here is to showcase a thorough understanding of the existing literature in your field of study. This enables you to position your research within the broader academic context, highlighting its relevance and identifying gaps that your project seeks to address. It is important to discuss your findings in this section, offering insights into the methodologies, findings, and limitations of the studies you review. Here are some steps to follow:\n\nAsk yourself: What is your research interest?\n\nWrite down key-words for your research interest.\nUsing the key-words, start your initial search with e.g. the Quick and Dirty strategy. Using the first results, start an in-depth search based on other strategies.\nWrite notes to retain search terms and selected results. Tools like Obsidian or Notion are excelent tools for notes, Excel or Google Sheets are simple, yet efficient, tools to structure your searches and selected literature (and we can export the data as csv files to process them using Python). Publish or Perish is a great tool to help in this stage, as it retains a protocol of your searches and offers the data export of search results.\nConcentrate on reading the abstract in your initial searches. We have to work efficiently, the abstract should contain the most relevant information about a given article for a first evaluation of its importance for your project.\nUse literature management software like Paperpile, Zotero, or Citavi to organize your reading. You might start using the software already at the skimming and abstract reading stage, once the reading starts, however, I would absolutely recommend to add the read articles to the managment software: Keep the PDFs organized using the software, keep your annotations in there, keep your notes in there!\nAt the end of your literature search process, you should be able to write the related work section of your project report and methods section. The related work section is part of your introduction and should include a summary and analysis of the relevant studies and research that has been conducted on your topic. Furthermore, your method section should ideally contain references to previous studies that have used similar methods or approaches.\n\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nAs a warm-up with ChatGPT / GPT we will extract information from abstracts in out tools session. The notebook will be added shortly, you will be able to use this approach with Publish or Perish lists.\n\n\n\nPublish or Perish\nPublish or Perish is a neat piece of software, that helps documenting your literature review process. It provides a unified interface to a majority of databases. Each search can be saved, multiple searches can be organized into folders. Additionally, the results can be exported to different formats. Thus, Publish or Perish is also a good starting point for AI-Assisted literature reviews.\n\n\n\n\n\n\n\nConnected Papers\nConnected Papers is one of my favorite tools for literature reseraches. Paste any DOI into the search field and the tool will create a graph of the article, linking the cited literature as well as incorporating newer literature that cites the work that you’ve been looking for. Using colors and node sizes all data is visualised neatly.\n\n\n\nAI Tools\nOver the past months, several AI Literature Review tools have been released:\n\nPerplexity incorporates GPT-3 (GPT-4 and Claude-2 in the pro version) and offers a chat interface. You can ask any question, it starts answering your question based on sources which are provided in the interface.\nElicit works somewhat differently, it expects you to ask a research question and tries to answer you question based on papers and has the ability to extract different type of information from papers automatically. In my experience the system does not work that well for social science questions.\nChatPDF is one of many tools that allow to upload PDF files, process them, and allow to chat with their content. In my experience it works rather well. However, as with all AI tools, we should be careful to manually verify the responses. The tool returns a link to the text anchor it refers to for answers. Overall, I recommend this tool for refinding information in papers that you’ve already read, or as a companion for skimming papers – although you might miss out important information!\nLangChain and LlamaIndex are python package that help building applications like ChatPDF yourself.\n\n\n\n\nReferences\n\n\nAmancio, Marina. 2017. “‘Put it in your Story’: Digital Storytelling in Instagram and Snapchat Stories.” PhD thesis. https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1111663&dswid=-5700.\n\n\nBainotti, Lucia, Alessandro Caliandro, and Alessandro Gandini. 2020. “From archive cultures to ephemeral content, and back: Studying Instagram Stories with digital methods.” New Media & Society, September, 1461444820960071. https://doi.org/10.1177/1461444820960071.\n\n\nBast, Jennifer. 2021. “Politicians, Parties, and Government Representatives on Instagram: A Review of Research Approaches, Usage Patterns, and Effects.” Review of Communication Research 9 (July). https://www.rcommunicationr.org/index.php/rcr/article/view/108.\n\n\nHaßler, Jörg, Anna Sophie Kümpel, and Jessica Keller. 2021. “Instagram and political campaigning in the 2017 German federal election. A quantitative content analysis of German top politicians’ and parliamentary parties’ posts.” Information, Communication and Society, July, 1–21. https://doi.org/10.1080/1369118X.2021.1954974.\n\n\nHochman, Nadav, and Lev Manovich. 2013. “Zooming into an Instagram City: Reading the local through social media.” First Monday, June. https://doi.org/10.5210/fm.v18i7.4711.\n\n\nHu, Yuheng, Lydia Manikonda, and Subbarao Kambhampati. 2014. “What We Instagram: A First Analysis of Instagram Photo Content and User Types.” Proceedings of the International AAAI Conference on Web and Social Media 8 (1): 595–98. https://doi.org/10.1609/icwsm.v8i1.14578.\n\n\nLeaver, Tama, Tim Highfield, and Crystal Abidin. 2020. Instagram: Visual Social Media Cultures. John Wiley & Sons.\n\n\nLi, Bo, Olan K M Scott, Michael L Naraine, and Brody J Ruihley. 2021. “Tell Me a Story: Exploring Elite Female Athletes’ Self-Presentation via an Analysis of Instagram Stories.” Journal of Interactive Advertising 21 (2): 108–20. https://doi.org/10.1080/15252019.2020.1837038.\n\n\nMayer-Schönberger, Viktor. 2011. Delete: The Virtue of Forgetting in the Digital Age. Princeton University Press.\n\n\nMilanesi, Matilde, and Simone Guercini. 2020. “Image-based Social Media and Visual Content Analysis: Insights from a Literature Review.” Micro & Macro Marketing, no. 3: 537–58. https://ideas.repec.org/a/mul/jyf1hn/doi10.1431-97640y2020i3p537-558.html.\n\n\nOmena, Janna Joceli, Elaine Teixeira Rabello, and André Goes Mintz. 2020. “Digital Methods for Hashtag Engagement Research.” Social Media + Society 6 (3): 2056305120940697. https://doi.org/10.1177/2056305120940697.\n\n\nRejeb, Abderahman, Karim Rejeb, Alireza Abdollahi, and Horst Treiblmaier. 2022. “The big picture on Instagram research: Insights from a bibliometric analysis.” Telematics and Informatics 73 (September): 101876. https://doi.org/10.1016/j.tele.2022.101876.\n\n\nRettberg, Jill Walker. 2018. “Snapchat: Phatic Communication and Ephemeral Social Media.” In Appified: Culture in the Age of Apps, edited by Jeremy Wade Morris and Sarah Murray, 188–95. “University of Michigan Press.”\n\n\nSánchez-Querubı́n, Natalia, Shuaishuai Wang, Briar Dickey, and Andrea Benedetti. 2023. “Political TikTok: Playful performance, ambivalent critique and event-commentary.” In The Propagation of Misinformation in Social Media, edited by Richard Rogers, 187–206. A Cross-Platform Analysis. Amsterdam University Press. https://doi.org/10.2307/jj.1231864.12.\n\n\nTowner, Terri L, and Caroline Lego Muñoz. 2022. “A Long Story Short: An Analysis of Instagram Stories during the 2020 Campaigns.” Journal of Political Marketing, July, 1–14. https://doi.org/10.1080/15377857.2022.2099579.\n\n\nVázquez-Herrero, Jorge, Sabela Direito-Rebollal, and Xosé López-Garcı́a. 2019. “Ephemeral Journalism: News Distribution Through Instagram Stories.” Social Media + Society 5 (4): 2056305119888657. https://doi.org/10.1177/2056305119888657."
  },
  {
    "objectID": "getting-started/related-work.html#footnotes",
    "href": "getting-started/related-work.html#footnotes",
    "title": "Related Work",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAccessible via VPN / on campus (when connected to eduroam).↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes on Computational Social Media Research",
    "section": "",
    "text": "Welcome to this collection of notes on social media analysis with a special focus on computational methods. It is a work-in-progress website, created as part of my PhD project and teaching at the Media Informatics Group at the University of Regensburg, Germany. My name is Michael Achmann-Denkler and I’m currently experimenting with computational approaches for multimodal analysis of social media content, like Instagram posts and stories. My aim for this website is to develop a collection of notes exploring various methodologies, techniques, and tools for social media research. As a first milestone, the website will accompany my research seminar Computational Analysis of Visual Social Media in the 2023/24 winter semester.\nCode and notebooks will be published on GitHub, the repository is registered with zenodo, the README.md file provides detailed instructions for citing the provided code in academic work."
  },
  {
    "objectID": "processing/operationalization.html",
    "href": "processing/operationalization.html",
    "title": "Social Media Lab",
    "section": "",
    "text": "Was ich hier auf jeden Fall ansprechen sollte: Anderson, the End of Theory!"
  },
  {
    "objectID": "data-collection/ig-stories.html#zeeschuimer-f",
    "href": "data-collection/ig-stories.html#zeeschuimer-f",
    "title": "Instagram Stories",
    "section": "Zeeschuimer-F",
    "text": "Zeeschuimer-F"
  },
  {
    "objectID": "data-collection/index.html",
    "href": "data-collection/index.html",
    "title": "Overview",
    "section": "",
    "text": "Theoretical Knowledge\nPractical Knowledge"
  },
  {
    "objectID": "data-collection/index.html#what-to-expect",
    "href": "data-collection/index.html#what-to-expect",
    "title": "Overview",
    "section": "",
    "text": "Theoretical Knowledge\nPractical Knowledge"
  },
  {
    "objectID": "data-collection/ig-posts.html",
    "href": "data-collection/ig-posts.html",
    "title": "Instagram Posts",
    "section": "",
    "text": "Instagram offers two ways of image sharing: permanent posts and ephemeral stories. In this chapter I will offer three approaches for collecting posts: Instaloader, CrowdTangle, and Zeeschuimer.\nPosts are shaped by several affordances and contain different type of media: least one image or video, often paired with text (captions). Posts may also contain an album consisting of more than one image or video. Captions may contain hashtags and / or mentions. Hashtags are used to self-organize posts on the platform, users can subscribe to hashtags and search for them. Mentions are used to link a post to another profile. Moreover, users can like, share and comment posts. Some data-collection approaches, like CrowdTangle, offer access to one image and post metrics, like the comment and like count. Instaloader, offer access to all images / videos, while being the legally most questionable approach. And then there’s the middle ground: Zeeschuimer (optionally in connection with 4CAT).\nThrough the following subchapters I will try to illuminate the advantages of each collection methods. For each method I will provide a manual to follow in order to collect metadata and the actual media for Instagram posts."
  },
  {
    "objectID": "data-collection/ig-posts.html#instaloader",
    "href": "data-collection/ig-posts.html#instaloader",
    "title": "Instagram Posts",
    "section": "Instaloader",
    "text": "Instaloader\nInstaloader is a python package for downloading instagram pictures and videos along with their metadata. I have written a getting started tutorial on Medium. It is, together with the provided notebook, the basis for this chapter.\n\nIn order to download posts and stories from Instagram, we use the package instaloader. You can install package for python using pip install &lt;package&gt;, the command -q minimizes the output.\n\n!pip -q install instaloader\n\n     |████████████████████████████████| 60 kB 3.0 MB/s eta 0:00:011\n  Building wheel for instaloader (setup.py) ... done\n\n\nOnce you install instaloader we log in using your username and password. Session information (not your credentials!) is stored in Google Drive to minimize the need for signing in.\nIn order to minimize the risk for your account to be disabled we suggest creating a new account on your phone before proceeding!\n\nusername = 'your.username'\n\n# We save the sessionfile to the following directory. Default is the new folder `.instaloader` in your google drive. (This is optional)\nsession_directory = '/content/drive/MyDrive/.instaloader/'\n\nimport instaloader\nfrom os.path import exists\nfrom pathlib import Path\n\n# Creating session directory, if it does not exists yet\nPath(session_directory).mkdir(parents=True, exist_ok=True)\n\nfilename = \"{}session-{}\".format(session_directory, username)\nsessionfile = Path(filename)\n\n\n# Get instance\nL = instaloader.Instaloader(compress_json=False)\n\n# Check if sessionfile exists. If so load session,\n# else login interactively\nif exists(sessionfile):\n  L.load_session_from_file(username, sessionfile)\n\nelse:\n  L.interactive_login(username)\n  L.save_session_to_file(sessionfile)\n\nLoaded session from /content/drive/MyDrive/.instaloader/session-mi_sm_lab05.\n\n\n\nDownloading first Posts\nNext, we try to download all posts of a profile. Provide a username and folder:\n\ndest_username = 'some.profile' \ndest_dir = '/content/drive/MyDrive/insta-posts/' # Once more we save the files to Google Drive. Replace this with a local directory if necessary.\n\nt = Path(\"{}{}\".format(dest_dir, dest_username))\nt.mkdir(parents=True, exist_ok=True)\n\nprofile = instaloader.Profile.from_username(L.context, dest_username)\nfor post in profile.get_posts():\n    L.download_post(post, target=t)\n\nWell, you just downloaded your first posts! Open Google Drive and check the folder insta-posts/ (or whatever folder you chose above)! There should be three files for each post, the image, a .json file and a .txt file. The .txt includes the image caption, the .json lots of metadata about the post.\n\nDiving into the metadata\nThe next cell reads all .json files of the downloaded posts. Then we browse through some interesting data.\n\n# Reading the paths of all JSON files from dest_dir\nimport os\n\njson_files = []\n\nfor subdir, dirs, files in os.walk(t):\n    for file in files:\n        fullpath = os.path.join(subdir, file)\n        filename, file_extension = os.path.splitext(fullpath)\n        if file_extension == \".json\":\n          json_files.append(fullpath)\n\n\n# Reading all JSON files\nfrom tqdm.notebook import tqdm\nimport json\n\njson_data = []\n\nfor file in tqdm(json_files):\n  with open(file, 'r') as f:\n    data = json.load(f)\n    json_data.append(data)\n\n\n\n\nOk, now all metadata for all posts is saved to the variable json_data. Run the next line and copy its output to http://jsonviewer.stack.hu/. Your output should look similar, go ahead and play around to explore your data! What information can you extract?\n\nprint(json.dumps(json_data[0]))\n\n\n\nMetadata Preprocessing\nPosts contain plenty of data, like time and location of the post, the authoring user, a caption, tagged users and more. The following cells demonstrate how to normalize the data into a table format, which is useful when working with pandas. Nevertheless, this is optional!\n\n# Use booleans (True / False) values to select what type of data you'd like to analyse. \nusername = True #@param {type:\"boolean\"}\ntimestamp = True #@param {type:\"boolean\"}\ncaption = True #@param {type:\"boolean\"}\nlocation = True #@param {type:\"boolean\"}\nshortcode = True #@param {type:\"boolean\"}\nid = True #@param {type:\"boolean\"}\ntagged_users = True #@param {type:\"boolean\"}\n\nNext we loop through the data and create a new pandas DataFrame. The DataFrame will have one column for each variable selected above and one row for each downloaded posts.\nIf you are not yet familiar with the concept of dataframes have a look at YouTube, there’s plenty of introductory videos available.\n\nimport pandas as pd\n\nposts = []  # Initializing an empty list for all posts\nfor post in tqdm(json_data):\n  row = {} # Initializing an empty row for the post\n\n  node = post.get(\"node\")\n\n  if username:\n    owner = node.get(\"owner\")\n    row['username'] = owner.get(\"username\")\n\n  if timestamp:\n    row['timestamp'] = node.get(\"taken_at_timestamp\")\n\n  if location:\n    l = node.get(\"location\", None)\n    if l:\n      row['location'] = l.get(\"name\")\n\n  if shortcode:\n    row['shortcode'] = node.get(\"shortcode\")\n\n  if id:\n    row['id'] = node.get(\"id\")\n  \n  if tagged_users:\n    pass\n\n  if caption:\n    c = \"\"\n    emtc = node.get(\"edge_media_to_caption\")\n    edges = emtc.get(\"edges\")\n    for element in edges:\n      caption_node = element.get(\"node\")\n      c = c + caption_node.get(\"text\")\n    row['caption'] = c\n\n  # Finally add row to posts\n  posts.append(row)\n\n# After looping through all posts create data frame from list\nposts_df = pd.DataFrame.from_dict(posts)\n\nNow all information selected above is saved to the dataframe posts_df. Run the next cell and it will return a nicely formatted table. If your data is quite long, output will be cropped. Click the wand and after a few seconds you are able to browse through the data or filter by columns\n\nposts_df\n\nIn order to get a first impression of dataframes, the head() method is also useful. Run the next cell to see the result\n\nposts_df.head()\n\nThe dataframe is only saved in memory, thus when disconnecting and deleting the runtime, the dataframe is lost. Running the next cell saves the table to a CSV-file on your drive.\nNow the processed data may be recovered or used in another notebook.\n\nposts_df.to_csv('{}{}.csv'.format(dest_dir, username))\n\n\n\nSource: Collecting Posts with Instaloader"
  },
  {
    "objectID": "data-collection/ig-posts.html#downloading-first-posts",
    "href": "data-collection/ig-posts.html#downloading-first-posts",
    "title": "Instagram Posts",
    "section": "Downloading first Posts",
    "text": "Downloading first Posts\nNext, we try to download all posts of a profile. Provide a username and folder:\n\ndest_username = 'some.profile' \ndest_dir = '/content/drive/MyDrive/insta-posts/' # Once more we save the files to Google Drive. Replace this with a local directory if necessary.\n\nt = Path(\"{}{}\".format(dest_dir, dest_username))\nt.mkdir(parents=True, exist_ok=True)\n\nprofile = instaloader.Profile.from_username(L.context, dest_username)\nfor post in profile.get_posts():\n    L.download_post(post, target=t)\n\nWell, you just downloaded your first posts! Open Google Drive and check the folder insta-posts/ (or whatever folder you chose above)! There should be three files for each post, the image, a .json file and a .txt file. The .txt includes the image caption, the .json lots of metadata about the post.\n\nDiving into the metadata\nThe next cell reads all .json files of the downloaded posts. Then we browse through some interesting data.\n\n# Reading the paths of all JSON files from dest_dir\nimport os\n\njson_files = []\n\nfor subdir, dirs, files in os.walk(t):\n    for file in files:\n        fullpath = os.path.join(subdir, file)\n        filename, file_extension = os.path.splitext(fullpath)\n        if file_extension == \".json\":\n          json_files.append(fullpath)\n\n\n# Reading all JSON files\nfrom tqdm.notebook import tqdm\nimport json\n\njson_data = []\n\nfor file in tqdm(json_files):\n  with open(file, 'r') as f:\n    data = json.load(f)\n    json_data.append(data)\n\n\n\n\nOk, now all metadata for all posts is saved to the variable json_data. Run the next line and copy its output to http://jsonviewer.stack.hu/. Your output should look similar, go ahead and play around to explore your data! What information can you extract?\n\nprint(json.dumps(json_data[0]))\n\n\n\nMetadata Preprocessing\nPosts contain plenty of data, like time and location of the post, the authoring user, a caption, tagged users and more. The following cells demonstrate how to normalize the data into a table format, which is useful when working with pandas. Nevertheless, this is optional!\n\n# Use booleans (True / False) values to select what type of data you'd like to analyse. \nusername = True #@param {type:\"boolean\"}\ntimestamp = True #@param {type:\"boolean\"}\ncaption = True #@param {type:\"boolean\"}\nlocation = True #@param {type:\"boolean\"}\nshortcode = True #@param {type:\"boolean\"}\nid = True #@param {type:\"boolean\"}\ntagged_users = True #@param {type:\"boolean\"}\n\nNext we loop through the data and create a new pandas DataFrame. The DataFrame will have one column for each variable selected above and one row for each downloaded posts.\nIf you are not yet familiar with the concept of dataframes have a look at YouTube, there’s plenty of introductory videos available.\n\nimport pandas as pd\n\nposts = []  # Initializing an empty list for all posts\nfor post in tqdm(json_data):\n  row = {} # Initializing an empty row for the post\n\n  node = post.get(\"node\")\n\n  if username:\n    owner = node.get(\"owner\")\n    row['username'] = owner.get(\"username\")\n\n  if timestamp:\n    row['timestamp'] = node.get(\"taken_at_timestamp\")\n\n  if location:\n    l = node.get(\"location\", None)\n    if l:\n      row['location'] = l.get(\"name\")\n\n  if shortcode:\n    row['shortcode'] = node.get(\"shortcode\")\n\n  if id:\n    row['id'] = node.get(\"id\")\n  \n  if tagged_users:\n    pass\n\n  if caption:\n    c = \"\"\n    emtc = node.get(\"edge_media_to_caption\")\n    edges = emtc.get(\"edges\")\n    for element in edges:\n      caption_node = element.get(\"node\")\n      c = c + caption_node.get(\"text\")\n    row['caption'] = c\n\n  # Finally add row to posts\n  posts.append(row)\n\n# After looping through all posts create data frame from list\nposts_df = pd.DataFrame.from_dict(posts)\n\nNow all information selected above is saved to the dataframe posts_df. Run the next cell and it will return a nicely formatted table. If your data is quite long, output will be cropped. Click the wand and after a few seconds you are able to browse through the data or filter by columns\n\nposts_df\n\nIn order to get a first impression of dataframes, the head() method is also useful. Run the next cell to see the result\n\nposts_df.head()\n\nThe dataframe is only saved in memory, thus when disconnecting and deleting the runtime, the dataframe is lost. Running the next cell saves the table to a CSV-file on your drive.\nNow the processed data may be recovered or used in another notebook.\n\nposts_df.to_csv('{}{}.csv'.format(dest_dir, username))"
  },
  {
    "objectID": "data-collection/ig-posts.html#crowdtangle",
    "href": "data-collection/ig-posts.html#crowdtangle",
    "title": "Instagram Posts",
    "section": "CrowdTangle",
    "text": "CrowdTangle\n\n\n\nScreenshot of the CrowdTangle interface.\n\n\nCrowdTangle is the best option to collect IG posts – in theory. It provides legal access to Instagram data and offers several tools to export large amount of data. For a current project we’ve exported more than 500.000 public posts through a hashtag query. Unfortunately there are several restrictions: CrowdTangle is the best tool to export metadata of public posts, and captions. The abilty to collect images through the platform is limited: Image links expire after a certain amount of time, thus we need to use some makeshift approach to download the images. When we can download the images, it’s always just one per post, no matter if it’s a gallery or a single image. And let’s not talk about videos. I have written another Medium story with a step-by-step guide to CrowdTangle."
  },
  {
    "objectID": "data-collection/ig-posts.html#zeeschuimer-4cat",
    "href": "data-collection/ig-posts.html#zeeschuimer-4cat",
    "title": "Instagram Posts",
    "section": "Zeeschuimer & 4CAT",
    "text": "Zeeschuimer & 4CAT\nZeeschuimer (Peeters, n.d.) and 4CAT (Peeters, Hagen, and Wahl, n.d.) are two tools developed for the https://wiki.digitalmethods.net/. The first is a firefox plugin that captures traffic when browsing websites likes Instagram or TikTok. The second, 4CAT, is an analysis platform incorporating several steps of preprocessing and further analyses. For post collection we can use the original Zeeschuimer Firefox Plugin, download the latest release from GitHub and install it in Firefox.\n\n\n\n\n\n\nWork-In-Progress\n\n\n\nThe tutorial will be released for our data collection session on November, 6th."
  },
  {
    "objectID": "data-collection/ig-posts.html#references",
    "href": "data-collection/ig-posts.html#references",
    "title": "Instagram Posts",
    "section": "References",
    "text": "References\n\n\nPeeters, Stijn. n.d. “Zeeschuimer.” https://doi.org/10.5281/zenodo.8399900.\n\n\nPeeters, Stijn, Sal Hagen, and Dale Wahl. n.d. “4CAT Capture and Analysis Toolkit.” https://doi.org/10.5281/zenodo.8139174."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Starting in 2022, several student projects and bachelor and master theses have been exploring Social Media Analysis under my supervision. Each project approached the field with a unique research interest and questions, influenced by interdisciplinary questions and perspectives. On this page I keep track of past and current projects."
  },
  {
    "objectID": "projects/index.html#semester-projects",
    "href": "projects/index.html#semester-projects",
    "title": "Projects",
    "section": "Semester Projects",
    "text": "Semester Projects\n\nDigital Humanities – Winter 2022/2023\n\n“Trends in Visual Features of NFT Art from the Most Economically Successful Artists on OpenSea” (Ferah Noor, Mari McCarville)\n“Body Positivity auf Instagram – Eine qualitative Inhaltsanalyse” (Anna Ignjatovic, Adela Myslikova, Ronny Retschmeier)\n“Aktivismus oder Klimaterror? Die Kommentierung der Klimabewegung auf Twitter in der Analyse” (Marie Ederer, Sebastian Daniel)\n“Die Relevanz des Ukraine-Kriegs im nationalen Kontext BILD, SZ und Tagesschau im Vergleich” (Milena Bach, Tobias Ederer, Sebastian Mißler)\n“Die Verwendung naturverbundener Farben anhand ausgewählter Food-Influencerinnen” (Anna Zagel, Mona Meier-to-Krax, Chiara Rahe)\n“Instagram Beiträge zum Thema Ukraine von Nachrichtenkanälen aus verschiedenen Ländern (vor und während des Krieges im Vergleich)” (Philipp Pielmeier, Katharina Kampa, Johanna Grünler)\n“Die Vermarktung von ESN-Fitnessprodukten in den Stories auf der Plattform Instagram” (Kessler Julia, Nett Ellena, Ousseni Océane, Traßl-Wilterius Annika, Umbreit Janosch)\n“Politisches Posten im Rahmen des Krieges in der Ukraine” (Jakob Berg)\n\n\n\nComputational Analysis of Visual Social Media – Winter 2023/2024\nWork in Progress: We will form groups with a final set of topics on October, 30th. We organize our groups and topics on mural."
  },
  {
    "objectID": "projects/index.html#theses",
    "href": "projects/index.html#theses",
    "title": "Projects",
    "section": "Theses",
    "text": "Theses\n\nBachelor\n\n\n\n\n\n\n\n\n\nTitle\nAuthor\nStatus\nYear\n\n\n\n\nSocial Media Analyse von Instagram Stories am Beispiel politischer Akteure während der Bundestagswahl 2021\nLisa Hampel\nCompleted\n2021\n\n\nSammlung und Auswertung eines Social-Media-Korpus durch Entwicklung eines Browser-Plugins zur Annotation von Instagram Stories\nRuslan Asabidi\nCompleted\n2021\n\n\nClassification of Multimodal Social Media Crisis Data – Evaluation and Comparison of two Multimodal Machine Learning Models\nMarkus Weinberger\nCompleted\n2023\n\n\nReaktionen politischer Akteure auf den russischen Angriffskrieg in Instagram Stories & Videos\nFranka Heinlein\nCompleted\n2023\n\n\nPolitical stories – improving face recognition performance for political Instagram story analysis\nPhilip Pirkl\nCompleted\n2023\n\n\nData Donations and Ephemeral Content: Obtaining Instagram-Stories\nTobias Lanzl\nWork in Progress\n2023\n\n\nXu Hướng: An Analysis of Trending TikTok Videos in Vietnam\nThuy-Linh Nguyen\nWork in Progress\n2023\n\n\nEntwicklung eines interaktiven Dashboards zur Echtzeitauswertung der politischen Kommunikation auf Instagram im Landtagswahlkampf 2023\nJonas Ernst\nWork in Progress\n2023\n\n\n\n\n\nMaster\n\n\n\nTitle\nAuthor\nStatus\nYear\n\n\n\n\nUntersuchung der Telegram-Kanäle der “Querdenker”-Bewegung\nTheresa Strohmeier\nCompleted\n2022\n\n\nInvestigating African American Writing and Thought by comparison of two corpora via Distant Reading\nAenne Knierim\nCompleted\n2022\n\n\nSelbstoptimierung vs. Selbstliebe? Eine vergleichende Inhaltsanalyse von Fitspiration- und Bodypositivity-Bildern auf Instagram mit Methoden der automatischen Bildklassifikation\nJulia Glas\nCompleted\n2022\n\n\nAnalyse visueller und textueller Kommunikationsaspekte von deutschen Lifestyle-Influencern auf Instagram und deren Einfluss auf das User Engagement\nNina Dillinger\nCompleted\n2023"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Michael Achmann  Universitätsstr. 31  93053 Regensburg  Email: michael.achmann@informatik.uni-regensburg.de  Phone: 0941 / 943 5098"
  },
  {
    "objectID": "about.html#website-owner",
    "href": "about.html#website-owner",
    "title": "About",
    "section": "",
    "text": "Michael Achmann  Universitätsstr. 31  93053 Regensburg  Email: michael.achmann@informatik.uni-regensburg.de  Phone: 0941 / 943 5098"
  },
  {
    "objectID": "about.html#copyright-information",
    "href": "about.html#copyright-information",
    "title": "About",
    "section": "Copyright Information",
    "text": "Copyright Information\nCopyright © Michael Achmann 2023. The text-content and supplement materials are licensed unter GNU GPL 3.0.\n\nCitation\nCiting information for the website will follow soon."
  },
  {
    "objectID": "about.html#disclaimer",
    "href": "about.html#disclaimer",
    "title": "About",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe information contained on this website is for general informational purposes only. While we make every effort to keep the information up to date and accurate, we make no representations or warranties of any kind, express or implied, about the completeness, accuracy, reliability, suitability, or availability concerning the website or the information, products, services, or related graphics contained on the website for any purpose. Any reliance you place on such information is strictly at your own risk."
  },
  {
    "objectID": "about.html#links-to-third-party-websites",
    "href": "about.html#links-to-third-party-websites",
    "title": "About",
    "section": "Links to Third-Party Websites",
    "text": "Links to Third-Party Websites\nThis website may contain links to third-party websites. These links are provided solely for your convenience and do not imply any endorsement, sponsorship, or recommendation by us. We have no control over the content of these websites and assume no responsibility for their accuracy, legality, or content."
  },
  {
    "objectID": "about.html#data-protection",
    "href": "about.html#data-protection",
    "title": "About",
    "section": "Data Protection",
    "text": "Data Protection\nThis Quarto website is hosted on GitHub. While this website does not use any analytics software, GitHub may store cookies on your device. You can change the cookie preferences at any time."
  },
  {
    "objectID": "about.html#trademark-notice",
    "href": "about.html#trademark-notice",
    "title": "About",
    "section": "Trademark Notice",
    "text": "Trademark Notice\nAll trademarks and logos used on this website are the property of their respective owners."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About",
    "section": "Contact",
    "text": "Contact\nIf you have any questions or concerns regarding this impressum or our website, please contact us using the contact information provided above."
  },
  {
    "objectID": "getting-started/tools.html",
    "href": "getting-started/tools.html",
    "title": "Tools and Software",
    "section": "",
    "text": "Colab is a platform created by Google for collaborative work and research. It offers a preconfigured Python development environment with access to popular libraries and tools. It is based on Jupyter notebooks, which allows users to create and share documents that contain live code, equations, visualizations, and narrative text. Throughout the semester I am going to provide code for different applications as Jupyter notebooks, which can easily be accessed and run on Colab.\n\n\n\n\nA screenshot of Colab\n\n\n\nColab can be used for free, but it also offers a paid subscription plan called Colab Pro. The pro version offers, among other features, access to GPUs, which are often used for machine learning. We are probably going to use APIs and GPT throughout the semester, if we need to access GPUs we may use schlaubox."
  },
  {
    "objectID": "getting-started/tools.html#colab",
    "href": "getting-started/tools.html#colab",
    "title": "Tools and Software",
    "section": "",
    "text": "Colab is a platform created by Google for collaborative work and research. It offers a preconfigured Python development environment with access to popular libraries and tools. It is based on Jupyter notebooks, which allows users to create and share documents that contain live code, equations, visualizations, and narrative text. Throughout the semester I am going to provide code for different applications as Jupyter notebooks, which can easily be accessed and run on Colab.\n\n\n\n\nA screenshot of Colab\n\n\n\nColab can be used for free, but it also offers a paid subscription plan called Colab Pro. The pro version offers, among other features, access to GPUs, which are often used for machine learning. We are probably going to use APIs and GPT throughout the semester, if we need to access GPUs we may use schlaubox."
  },
  {
    "objectID": "getting-started/tools.html#git-github",
    "href": "getting-started/tools.html#git-github",
    "title": "Tools and Software",
    "section": "Git & GitHub",
    "text": "Git & GitHub"
  },
  {
    "objectID": "getting-started/tools.html#twitter-x",
    "href": "getting-started/tools.html#twitter-x",
    "title": "Tools and Software",
    "section": "Twitter (X)",
    "text": "Twitter (X)"
  },
  {
    "objectID": "getting-started/tools.html#open-research-project-documentation",
    "href": "getting-started/tools.html#open-research-project-documentation",
    "title": "Tools and Software",
    "section": "Open Research: Project Documentation",
    "text": "Open Research: Project Documentation"
  },
  {
    "objectID": "getting-started/tools.html#open-research-research-communication",
    "href": "getting-started/tools.html#open-research-research-communication",
    "title": "Tools and Software",
    "section": "Open Research: Research Communication",
    "text": "Open Research: Research Communication"
  },
  {
    "objectID": "getting-started/tools.html#figma",
    "href": "getting-started/tools.html#figma",
    "title": "Tools and Software",
    "section": "Figma",
    "text": "Figma"
  },
  {
    "objectID": "getting-started/tools.html#rawgraphs",
    "href": "getting-started/tools.html#rawgraphs",
    "title": "Tools and Software",
    "section": "Rawgraphs",
    "text": "Rawgraphs"
  },
  {
    "objectID": "getting-started/tools.html#imagej",
    "href": "getting-started/tools.html#imagej",
    "title": "Tools and Software",
    "section": "ImageJ",
    "text": "ImageJ"
  },
  {
    "objectID": "getting-started/tools.html#pixplot",
    "href": "getting-started/tools.html#pixplot",
    "title": "Tools and Software",
    "section": "PixPlot",
    "text": "PixPlot"
  },
  {
    "objectID": "getting-started/tools.html#memespector",
    "href": "getting-started/tools.html#memespector",
    "title": "Tools and Software",
    "section": "Memespector",
    "text": "Memespector"
  },
  {
    "objectID": "getting-started/index.html",
    "href": "getting-started/index.html",
    "title": "About the Seminar",
    "section": "",
    "text": "The research seminar Computational Analysis of Visual Social Media consists of project-centred work in groups, lectures on theory and practical sessions. Each group will follow their own research interests and datasets. Groups will be formed in the third session, together with preliminary topics. We have participants from different fields, the topics will mirror this interdisciplinarity, roughly drawn from the interesctions of media studies, political science, and communication science. The seminar aims at master students with first knowledge of at least one programming language.\n\n\nBy the end of the semester you should know more about:\n\nThe state of Social Media Research,\ninteresting questions to answer with social media data,\nethical and legal restrictions,\ndevelop operationalizations for visual and textual data,\n\n\n\n\nBy the end of the semester you will be able to:\n\nCollect Instagram stories, posts and TikTok videos,\napply OCR and automatically transcribe videos,\ncomputationally classify text and images using GPT and CLIP,\nevaluate and optimize your classifications using human annotations,\npresent your results.\n\n\n\n\nThe following expectations and criteria must be met to pass the course:\n\nIndependent familiarization with your own scientific topic: Literature research, formulation of research questions, and operationalization.\nWillingness to master new tools (supported by practical units and some provided Jupyter Notebooks).\nActive and regular team collaboration on the individual project.\nContinuous documentation of current progress through a project wiki.\nWriting a project report at the end of the semester.\n\n\n\n\n\nWe will openly document our project progress, incorporating a strong Open Science stance.\nThe project report template is a good starting point for your report and continuous documentation.\nThrough the semester we will come back to the draft and extend it towards the final report.\nThe goal is to publish the report on social-media-lab.net.\n\n\n\n\n\nThe project report will be handed in collaboratively,\nconsists of app. 20 pages,\nfollows the IMRAD1 principle,\nuses APA citation style,\nneeds to be handed in no later than 31.03.2024.\n\n\n\n\n\nSuggest your own project\nPossible Projects:\n\nLandtagswahl BY 2023\n\nIG Stories & Posts\nTikTok\nJugendorganisationen\n\nPolitische Influencer auf TikTok\nWar in Sozialen Medien:\n\nUkraine Invasion\nHamas Angriff auf Israel\n\nFalschinformationen & KI-Generierte Inhalte\n\n\n\n\n\n\nMost course material will be available on social-media-lab.net.\nAdditional material will be provided via GRIPS.\nWe will work collaboratively on the website through the semester.\nThe content is edited using Quarto and Markdown, you will need a GitHub Account.\nPlease provide your GitHub username to get access to the repository.\nAll content will be published under GPL-3."
  },
  {
    "objectID": "getting-started/index.html#what-to-expect-theoretical-skills",
    "href": "getting-started/index.html#what-to-expect-theoretical-skills",
    "title": "About the Seminar",
    "section": "",
    "text": "By the end of the semester you should know more about:\n\nThe state of Social Media Research,\ninteresting questions to answer with social media data,\nethical and legal restrictions,\ndevelop operationalizations for visual and textual data,"
  },
  {
    "objectID": "getting-started/index.html#what-to-expect-practical-skills",
    "href": "getting-started/index.html#what-to-expect-practical-skills",
    "title": "About the Seminar",
    "section": "",
    "text": "By the end of the semester you will be able to:\n\nCollect Instagram stories, posts and TikTok videos,\napply OCR and automatically transcribe videos,\ncomputationally classify text and images using GPT and CLIP,\nevaluate and optimize your classifications using human annotations,\npresent your results."
  },
  {
    "objectID": "getting-started/index.html#class-requirements",
    "href": "getting-started/index.html#class-requirements",
    "title": "About the Seminar",
    "section": "",
    "text": "The following expectations and criteria must be met to pass the course:\n\nIndependent familiarization with your own scientific topic: Literature research, formulation of research questions, and operationalization.\nWillingness to master new tools (supported by practical units and some provided Jupyter Notebooks).\nActive and regular team collaboration on the individual project.\nContinuous documentation of current progress through a project wiki.\nWriting a project report at the end of the semester."
  },
  {
    "objectID": "getting-started/index.html#project-documentation",
    "href": "getting-started/index.html#project-documentation",
    "title": "About the Seminar",
    "section": "",
    "text": "We will openly document our project progress, incorporating a strong Open Science stance.\nThe project report template is a good starting point for your report and continuous documentation.\nThrough the semester we will come back to the draft and extend it towards the final report.\nThe goal is to publish the report on social-media-lab.net."
  },
  {
    "objectID": "getting-started/index.html#project-report",
    "href": "getting-started/index.html#project-report",
    "title": "About the Seminar",
    "section": "",
    "text": "The project report will be handed in collaboratively,\nconsists of app. 20 pages,\nfollows the IMRAD1 principle,\nuses APA citation style,\nneeds to be handed in no later than 31.03.2024."
  },
  {
    "objectID": "getting-started/index.html#project-ideas",
    "href": "getting-started/index.html#project-ideas",
    "title": "About the Seminar",
    "section": "",
    "text": "Suggest your own project\nPossible Projects:\n\nLandtagswahl BY 2023\n\nIG Stories & Posts\nTikTok\nJugendorganisationen\n\nPolitische Influencer auf TikTok\nWar in Sozialen Medien:\n\nUkraine Invasion\nHamas Angriff auf Israel\n\nFalschinformationen & KI-Generierte Inhalte"
  },
  {
    "objectID": "getting-started/index.html#social-media-lab",
    "href": "getting-started/index.html#social-media-lab",
    "title": "About the Seminar",
    "section": "",
    "text": "Most course material will be available on social-media-lab.net.\nAdditional material will be provided via GRIPS.\nWe will work collaboratively on the website through the semester.\nThe content is edited using Quarto and Markdown, you will need a GitHub Account.\nPlease provide your GitHub username to get access to the repository.\nAll content will be published under GPL-3."
  },
  {
    "objectID": "getting-started/index.html#introduction-to-social-media-analysis",
    "href": "getting-started/index.html#introduction-to-social-media-analysis",
    "title": "About the Seminar",
    "section": "Introduction to Social Media Analysis",
    "text": "Introduction to Social Media Analysis\n\nOverview of social media studies\n\nWhich academic disciplines are interested in plattforms like Instagram?\nWhat is their interest, how do they study the user generated content?\nSpecial focus: Political Communication on Instagram\n\nHow to conduct your own literature review\nTheory: Digital Methods & Cultural Analytics\nA short word about ethics & laws"
  },
  {
    "objectID": "getting-started/index.html#getting-started-tools",
    "href": "getting-started/index.html#getting-started-tools",
    "title": "About the Seminar",
    "section": "Getting Started: Tools",
    "text": "Getting Started: Tools\n\nInstallation & Configuration of different tools.\n\nGoogle Colab / Jupyter Notebooks\nQuarto & Markdown for project documentation\nGit & GitHub\nFirefox Plugins\nFigma\nand more"
  },
  {
    "objectID": "getting-started/index.html#data-collection-ig-posts-stories",
    "href": "getting-started/index.html#data-collection-ig-posts-stories",
    "title": "About the Seminar",
    "section": "Data Collection: IG Posts & Stories",
    "text": "Data Collection: IG Posts & Stories\n\nPost types and platform affordances of Instagram\nHow to use Instaloader\nHow to use CrowdTangle2\nCollecting Stories using Zeeschuimer-F and the firebase backend.\nCollecting Posts using Zeeschuimer and 4CAT\n\n\n\n\nScreenshot of the CrowdTangle interface."
  },
  {
    "objectID": "getting-started/index.html#data-collection-tiktok",
    "href": "getting-started/index.html#data-collection-tiktok",
    "title": "About the Seminar",
    "section": "Data Collection: TikTok",
    "text": "Data Collection: TikTok\n\nPost types and platform affordances of TikTok\nCollecting TikToks using Zeeschuimer and 4CAT\n\n\n\n\nScreenshot of the Firebase Backend and Zeeschuimer-F."
  },
  {
    "objectID": "getting-started/index.html#data-preprocessing",
    "href": "getting-started/index.html#data-preprocessing",
    "title": "About the Seminar",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\n\nOCR\nWe are going to use easyocr to detect and recognize text embedded in images, such as posts and stories.\nWe will export the first frame of videos for OCR and further analyses.\nAutomated Transcription\n\nWe will extract any audio from collected videos.\nWe will use whisper to transcribe the audio content of videos"
  },
  {
    "objectID": "getting-started/index.html#textual-exploration",
    "href": "getting-started/index.html#textual-exploration",
    "title": "About the Seminar",
    "section": "Textual Exploration",
    "text": "Textual Exploration\n\nWe will first take a look at the textual data using simple frequency analyses and wordclouds.\nWe will use the GPT-API to explore the textual content of our data.\nOptional we might use BERTopic to explore our textual data."
  },
  {
    "objectID": "getting-started/index.html#operationalization-i",
    "href": "getting-started/index.html#operationalization-i",
    "title": "About the Seminar",
    "section": "Operationalization I",
    "text": "Operationalization I\n\nThis session depends on your own research: By december you should have developed an initial research request and explored related work in order to develop the first operationalization for content analysis.\nWe will learn more about content analysis in this session.\nBased on your research, and the explorations of the previous sesssion, we will develop the first annotation guide.\nThrough the session we will explore how to (efficiently) use GPT for text data annotation."
  },
  {
    "objectID": "getting-started/index.html#data-annotation",
    "href": "getting-started/index.html#data-annotation",
    "title": "About the Seminar",
    "section": "Data Annotation",
    "text": "Data Annotation\n\nIn this session we will import our data into LabelStudio and develop a final annotation manual.\nUsing the manuals and LabelStudio projects we will annotate the data.\nWe will shuffle annotators: Everyone will annotate for another group."
  },
  {
    "objectID": "getting-started/index.html#evaluation-i",
    "href": "getting-started/index.html#evaluation-i",
    "title": "About the Seminar",
    "section": "Evaluation I",
    "text": "Evaluation I\n\nUsing the human annotations we will evaluate the performance of our computational text annotations / information extractions.\nWe can fine-tune our prompts using the annotation data to improve the annotation quality.\nWe will learn how to present and visualize the quality of the model."
  },
  {
    "objectID": "getting-started/index.html#exploration-of-visual-data",
    "href": "getting-started/index.html#exploration-of-visual-data",
    "title": "About the Seminar",
    "section": "Exploration of Visual Data",
    "text": "Exploration of Visual Data\n\nWe will explore different tools to visualize images:\nImageJ\nPixPlot\nMemespector and Gephi3\nThe visualization forms the basis for image classification: In this stage we want to find similarities and differences.\n\n\n\n\nExample of image exploration using PixPlot."
  },
  {
    "objectID": "getting-started/index.html#operationalization-ii",
    "href": "getting-started/index.html#operationalization-ii",
    "title": "About the Seminar",
    "section": "Operationalization II",
    "text": "Operationalization II\n\nOnce more a dive in the literature: This time on visual content analysis.\nCombining the results of our exploration, reserach interest and related work with content analysis, we will develop an annotation manual for the images.\nWe will learn how to use CLIP for image classification\nBased on your previous experience you will create human annotations.\nWe will shuffle annotators: Everyone will annotate for another group.\n\n\n\n\nDecomposition of different layers in a Story by @gruenebayern during the 2023 Bavarian state elections."
  },
  {
    "objectID": "getting-started/index.html#evaluation-ii",
    "href": "getting-started/index.html#evaluation-ii",
    "title": "About the Seminar",
    "section": "Evaluation II",
    "text": "Evaluation II\n\nOnce more we will evaluate the quality of our model,\nand fine-tune our prompts.\nWork in Progress: We might organize this session differently on short notice, depending on the outcomes of my current research project.\nWaiting in Progress: In case of visual GPT being published we might have to adapt.\n\n\n\n\nExample of a visual inspection of classification results: Intermediary results of image types classifications using CLIP for the 2021 federal election. Two out of five stories posted by differnt parties have been misclassified."
  },
  {
    "objectID": "getting-started/index.html#data-wrangling-as-a-conversation",
    "href": "getting-started/index.html#data-wrangling-as-a-conversation",
    "title": "About the Seminar",
    "section": "Data Wrangling as a Conversation",
    "text": "Data Wrangling as a Conversation\n\nThe Advanced Data Analysis mode of ChatGPT is a powerful tool to (quickly) analyze metadata (and more) of social media data.\nWe will give it a shot with some simple analyses, like trends over time.\nExperimental in case we have enough time left, we might try to create a workflow with LangChain and LlamaIndex to chat with our data."
  },
  {
    "objectID": "getting-started/index.html#visual-presentation-of-your-data",
    "href": "getting-started/index.html#visual-presentation-of-your-data",
    "title": "About the Seminar",
    "section": "Visual Presentation of your Data",
    "text": "Visual Presentation of your Data\n\nOur last session of the semester will be all about telling a story with your data.\nWe will use Python (Jupyter Notebooks) to transform our data in CSV files.\nWe will import the data into RAWGraphs to create convincing plots\nWe will use Figma to collaboratively sketch the layout of your project report website."
  },
  {
    "objectID": "getting-started/index.html#footnotes",
    "href": "getting-started/index.html#footnotes",
    "title": "About the Seminar",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIntroduction, Method, Result, Analaysis, Discussion↩︎\nI will not be able to provide access to the tool. We can, however, export data for our projects from the platform and you will learn how to use the exported data.↩︎\nfollowing Omena’s concept for cloud vision labels, see related work.↩︎"
  }
]