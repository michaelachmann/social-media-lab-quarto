{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image classification using CLIP works by comparing a string of text with an image. If we compare multiple text-strings with the same image, we can determine the phrase with the highest similarity score and infer the classification. To make the classification work for my scenario, I created a dictionary, where each image type is mapped to multiple sentences describing how an image in this class would look like.\n",
        "\n",
        "![An overview of the CLIP-Classification process, starting with the creation of phrases describing the target content.](../images/CLIP-prozess.png){width=\"100%\"}\n",
        "\n",
        "My implementation is inspired by [this medium story](https://medium.com/@JettChenT/image-classification-with-openai-clip-3ab5f1c23e35)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gtB3g330Z9Z"
      },
      "outputs": [],
      "source": [
        "classification_dict = {\n",
        "    \"Collages\": [\n",
        "        \"A screenshot with multiple visual elements such as text, graphics, and images combined.\",\n",
        "    ],\n",
        "    \"Campaign Material\": [\n",
        "        \"An image primarily showcasing election-related flyers, brochures, or handouts.\",\n",
        "        \"A distinct promotional poster for a political event or campaign.\",\n",
        "        \"Visible printed material urging people to vote or join a political cause.\"\n",
        "    ],\n",
        "    \"Political Events\": [\n",
        "        \"An image distinctly capturing the essence of a political campaign event.\",\n",
        "        \"A location set for a political event, possibly without a crowd.\",\n",
        "        \"A large assembly of supporters or participants at an open-air political rally.\",\n",
        "        \"Clear visuals of a venue set for a significant political gathering or convention.\",\n",
        "        \"Focused visuals of attendees or participants of a political rally or event.\",\n",
        "        \"Inside ambiance of a political convention or major political conference.\",\n",
        "        \"Prominent figures or speakers on stage addressing a political audience.\",\n",
        "        \"A serene image primarily focused on landscapes, travel.\",\n",
        "        \"Food, beverages, or generic shots.\"\n",
        "    ],\n",
        "    \"Individual Contact\": [\n",
        "        \"A politician genuinely engaging or interacting with individuals or small groups.\",\n",
        "        \"A close-up or selfie, primarily showcasing an individual, possibly with political affiliations.\",\n",
        "        \"An informal or candid shot with emphasis on individual engagement, perhaps in a political setting.\"\n",
        "    ],\n",
        "    \"Interviews & Media\": [\n",
        "        \"An indoor setting, well-lit, designed for professional media interviews or broadcasts.\",\n",
        "        \"Clear visuals of an interviewee in a controlled studio environment.\",\n",
        "        \"Microphone or recording equipment predominantly in front of a speaker indoors.\",\n",
        "        \"Behind-the-scenes ambiance of a media setup or broadcast preparation.\",\n",
        "        \"Visuals from a TV or media broadcast, including distinct channel or media branding.\",\n",
        "        \"Significant media branding or logos evident, possibly during an interview or panel discussion.\",\n",
        "        \"Structured indoor setting of a press conference or media event with multiple participants.\"\n",
        "    ],\n",
        "    \"Social Media Moderation\": [\n",
        "        \"Face-centric visual with the individual addressing or connecting with the camera.\",\n",
        "        \"Emphasis on facial features, minimal background distractions, typical of online profiles.\",\n",
        "        \"Portrait-style close-up of a face, without discernible logos, graphics, or overlays.\"\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this dictionary, we can now compare the images to the strings using CLIP in a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnaq8qKI0m-3"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Assuming preprocess, clip model, and device are already initialized\n",
        "\n",
        "def classify_images_with_clip(image_files, classification_dict, column_name, BATCH_SIZE=500):\n",
        "    labels_map, flat_labels = flatten_classification_dict(classification_dict)\n",
        "    text = clip.tokenize(flat_labels).to(device)\n",
        "\n",
        "    results = []\n",
        "    for batch_start in tqdm(range(0, len(image_files), BATCH_SIZE)):\n",
        "        batch_end = batch_start + BATCH_SIZE\n",
        "        batch_files = image_files[batch_start:batch_end]\n",
        "        images = preprocess_images(batch_files)\n",
        "        if not images:\n",
        "            continue\n",
        "        image_input = torch.tensor(np.stack(images)).to(device)\n",
        "\n",
        "        logits_per_image = model_inference(image_input, text)\n",
        "        update_results(logits_per_image, batch_files, flat_labels, labels_map, results, column_name)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def flatten_classification_dict(classification_dict):\n",
        "    labels_map = {}\n",
        "    flat_labels = []\n",
        "    for category, phrases in classification_dict.items():\n",
        "        for phrase in phrases:\n",
        "            flat_labels.append(phrase)\n",
        "            labels_map[phrase] = category\n",
        "    return labels_map, flat_labels\n",
        "\n",
        "def preprocess_images(image_files):\n",
        "    images = []\n",
        "    for img_file in image_files:\n",
        "        try:\n",
        "            image = preprocess(Image.open(img_file))\n",
        "            images.append(image)\n",
        "        except IOError:\n",
        "            print(f\"Error loading image: {img_file}\")\n",
        "    return images\n",
        "\n",
        "def model_inference(image_input, text):\n",
        "    with torch.no_grad():\n",
        "        logits_per_image, _ = model(image_input, text)\n",
        "        return logits_per_image.softmax(dim=-1).cpu().numpy() * 100\n",
        "\n",
        "def update_results(logits_per_image, batch_files, flat_labels, labels_map, results, column_name):\n",
        "    max_indices = np.argsort(logits_per_image, axis=1)[:, -2:]\n",
        "    for idx, (file, top_indices) in enumerate(zip(batch_files, max_indices)):\n",
        "        result = {\"Image\": file}\n",
        "        for rank, label_idx in enumerate(top_indices[::-1], 1):\n",
        "            label = flat_labels[label_idx]\n",
        "            category = labels_map[label]\n",
        "            prob = logits_per_image[idx, label_idx].round(2)\n",
        "            result.update({\n",
        "                f\"{column_name}_{rank}\": category,\n",
        "                f\"{column_name}_label_{rank}\": label,\n",
        "                f\"{column_name}_prob_{rank}\": prob\n",
        "            })\n",
        "        results.append(result)\n",
        "\n",
        "def update_results(logits_per_image, batch_files, flat_labels, labels_map, results, column_name):\n",
        "    max_indices = np.argmax(logits_per_image, axis=1)\n",
        "    for idx, (file, top_index) in enumerate(zip(batch_files, max_indices)):\n",
        "        label = flat_labels[top_index]\n",
        "        category = labels_map[label]\n",
        "        prob = logits_per_image[idx, top_index].round(2)  # Fixed probability extraction\n",
        "\n",
        "        result = {\n",
        "            \"Image\": file,\n",
        "            f\"{column_name}\": category,\n",
        "            f\"{column_name} Label\": label,\n",
        "            f\"{column_name} Probability\": prob\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBeDxxHt7OmG",
        "outputId": "7894fc28-8d2f-4010-f465-cce2e7a608e1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "image_files = df['Image'].unique()\n",
        "\n",
        "# Perform the classification and get the results as a DataFrame\n",
        "classified_df = classify_images_with_clip(image_files, classification_dict, 'Classification')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `classified_df` contains the classification results. This implementation just saves the highest probability labels and classifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XsMWdYCc691z",
        "outputId": "0b49ef67-43de-4ce8-b570-f86cde94493b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b7933c0-d9be-4ea0-9de3-1192298bbb18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Classification</th>\n",
              "      <th>Classification Label</th>\n",
              "      <th>Classification Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/media/images/afd.bund/212537388606051...</td>\n",
              "      <td>Political Events</td>\n",
              "      <td>Focused visuals of attendees or participants o...</td>\n",
              "      <td>26.78125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/media/images/afd.bund/212537470102207...</td>\n",
              "      <td>Interviews &amp; Media</td>\n",
              "      <td>Visuals from a TV or media broadcast, includin...</td>\n",
              "      <td>71.31250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/media/images/afd.bund/249085122621717...</td>\n",
              "      <td>Social Media Moderation</td>\n",
              "      <td>Emphasis on facial features, minimal backgroun...</td>\n",
              "      <td>29.21875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/media/images/afd.bund/260084001188499...</td>\n",
              "      <td>Interviews &amp; Media</td>\n",
              "      <td>Clear visuals of an interviewee in a controlle...</td>\n",
              "      <td>79.62500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/media/images/afd.bund/260085279483160...</td>\n",
              "      <td>Interviews &amp; Media</td>\n",
              "      <td>Clear visuals of an interviewee in a controlle...</td>\n",
              "      <td>48.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b7933c0-d9be-4ea0-9de3-1192298bbb18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b7933c0-d9be-4ea0-9de3-1192298bbb18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b7933c0-d9be-4ea0-9de3-1192298bbb18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9bb8728d-dc40-4c1c-90a4-43135e476c27\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bb8728d-dc40-4c1c-90a4-43135e476c27')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9bb8728d-dc40-4c1c-90a4-43135e476c27 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Image           Classification  \\\n",
              "0  /content/media/images/afd.bund/212537388606051...         Political Events   \n",
              "1  /content/media/images/afd.bund/212537470102207...       Interviews & Media   \n",
              "2  /content/media/images/afd.bund/249085122621717...  Social Media Moderation   \n",
              "3  /content/media/images/afd.bund/260084001188499...       Interviews & Media   \n",
              "4  /content/media/images/afd.bund/260085279483160...       Interviews & Media   \n",
              "\n",
              "                                Classification Label  \\\n",
              "0  Focused visuals of attendees or participants o...   \n",
              "1  Visuals from a TV or media broadcast, includin...   \n",
              "2  Emphasis on facial features, minimal backgroun...   \n",
              "3  Clear visuals of an interviewee in a controlle...   \n",
              "4  Clear visuals of an interviewee in a controlle...   \n",
              "\n",
              "   Classification Probability  \n",
              "0                    26.78125  \n",
              "1                    71.31250  \n",
              "2                    29.21875  \n",
              "3                    79.62500  \n",
              "4                    48.00000  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classified_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Qualitative Evaluation** \n",
        "Running the last cells in the notebook creates a visual overview of the classification results. *n* images are sampled and displayed per group. The qualitative evaluation **does not replace proper external validation!**. Additionally, the overview is saved to `{current_date}-CLIP-Classification.html`. Download the file and open it in your browser for a better layout. The second validation cell creates a simple interface displaying on image and the classification result. Click on the \"Right\" or \"Wrong\" button to browse through multiple images and get a rough feeling of the classification qualities."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
